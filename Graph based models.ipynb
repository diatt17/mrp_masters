{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14b8616-ae1c-4191-ba8b-3f3ac50447f7",
   "metadata": {},
   "source": [
    "# Experimentation and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95904abf-f705-4e53-8bce-a6c3ecb6d93e",
   "metadata": {},
   "source": [
    "## Objective of the project \n",
    "\n",
    "This study seeks to conduct a thorough comparative analysis of these three models, focusing\n",
    "on their performance with regards to accuracy, computational complexity, scalability, and their\n",
    "effectiveness in handling data sparsity and dynamically changing environments. By evaluat-\n",
    "ing these aspects, the research aims to illuminate the operational strengths and weaknesses\n",
    "of each model, providing clear insights that could guide the development and deployment of\n",
    "future recommender systems. Through this comparative framework, we aspire to answer which\n",
    "model, under what conditions, provides the most reliable and robust recommendations, thereby\n",
    "significantly contributing to the optimization of digital services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec1c5afc-8ec3-4beb-9777-ef5cd6260e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter, defaultdict\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD, CoClustering, accuracy\n",
    "#from surprise.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.accuracy import rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d2f34e-8624-4280-9fb9-28ed84c78540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Links':    movieId  imdbId   tmdbId\n",
       " 0        1  114709    862.0\n",
       " 1        2  113497   8844.0\n",
       " 2        3  113228  15602.0\n",
       " 3        4  114885  31357.0\n",
       " 4        5  113041  11862.0,\n",
       " 'Movies':    movieId                               title  \\\n",
       " 0        1                    Toy Story (1995)   \n",
       " 1        2                      Jumanji (1995)   \n",
       " 2        3             Grumpier Old Men (1995)   \n",
       " 3        4            Waiting to Exhale (1995)   \n",
       " 4        5  Father of the Bride Part II (1995)   \n",
       " \n",
       "                                         genres  \n",
       " 0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       " 1                   Adventure|Children|Fantasy  \n",
       " 2                               Comedy|Romance  \n",
       " 3                         Comedy|Drama|Romance  \n",
       " 4                                       Comedy  ,\n",
       " 'Ratings':    userId  movieId  rating  timestamp\n",
       " 0       1        1     4.0  964982703\n",
       " 1       1        3     4.0  964981247\n",
       " 2       1        6     4.0  964982224\n",
       " 3       1       47     5.0  964983815\n",
       " 4       1       50     5.0  964982931,\n",
       " 'Tags':    userId  movieId              tag   timestamp\n",
       " 0       2    60756            funny  1445714994\n",
       " 1       2    60756  Highly quotable  1445714996\n",
       " 2       2    60756     will ferrell  1445714992\n",
       " 3       2    89774     Boxing story  1445715207\n",
       " 4       2    89774              MMA  1445715200}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_df = pd.read_csv('MovieLens_100k/links.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "tags_df = pd.read_csv('MovieLens_100k/tags.csv')\n",
    "\n",
    "datasets = {\n",
    "    \"Links\": links_df,\n",
    "    \"Movies\": movies_df,\n",
    "    \"Ratings\": ratings_df,\n",
    "    \"Tags\": tags_df\n",
    "}\n",
    "\n",
    "datasets_info = {name: df.head() for name, df in datasets.items()}\n",
    "datasets_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffed4e8-5b41-485b-8277-e2a6fba0e61b",
   "metadata": {},
   "source": [
    "## Dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862584cf-a7e4-415e-b6bc-ec7f894fb287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Links dataset:\n",
      "movieId    0\n",
      "imdbId     0\n",
      "tmdbId     8\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Movies dataset:\n",
      "movieId    0\n",
      "title      0\n",
      "genres     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Ratings dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Tags dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "tag          0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each dataset\n",
    "missing_values = {name: df.isnull().sum() for name, df in datasets.items()}\n",
    "\n",
    "# Print the information about missing values\n",
    "for name, missing in missing_values.items():\n",
    "    print(f\"Missing values in {name} dataset:\\n{missing}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713549fa-4fca-4d77-9bb7-7d1f73ef073d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Links DataFrame is: (9742, 3)\n",
      "The shape of the Movies DataFrame is: (9742, 3)\n",
      "The shape of the Ratings DataFrame is: (100836, 4)\n",
      "The shape of the Tags DataFrame is: (3683, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of each DataFrame\n",
    "for name, df in datasets.items():\n",
    "    print(f\"The shape of the {name} DataFrame is: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083bc746-5ced-4d3e-a934-90d141950572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.5</td>\n",
       "      <td>13136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>26818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.5</td>\n",
       "      <td>8551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  count\n",
       "0     0.5   1370\n",
       "1     1.0   2811\n",
       "2     1.5   1791\n",
       "3     2.0   7551\n",
       "4     2.5   5550\n",
       "5     3.0  20047\n",
       "6     3.5  13136\n",
       "7     4.0  26818\n",
       "8     4.5   8551\n",
       "9     5.0  13211"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_of_ratings = ratings_df.groupby('rating').size().reset_index(name='count')\n",
    "distribution_of_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcddd5-551b-4d64-a6cf-70163343775f",
   "metadata": {},
   "source": [
    "# Graph-based Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116c296-8d7b-4686-92b5-f027a19d01fe",
   "metadata": {},
   "source": [
    "### For the graph-based models, we have implemented 3 algorithms as well: LightGCN, Graph Attention Network, GraphSAGE\n",
    "Graph Construction: In the graph construction phase, nodes are created to represent both users\n",
    "and movies, while edges represent the interactions between these users and movies based on\n",
    "their ratings. To facilitate this, numpy is utilized for constructing the adjacency matrix, which\n",
    "captures the user-movie interaction graph in a structured form. This adjacency matrix serves\n",
    "as the foundation for various graph-based algorithms, allowing us to represent the relationships\n",
    "between users and movies effectively. Additionally, TensorFlow is employed to handle the graph\n",
    "representation and computation, leveraging its powerful capabilities for efficient processing and\n",
    "model training in subsequent stages. \n",
    "\n",
    "### In this first part of the code, we have implemented all the useful functions and code that all the 3 algorithms shared in commun to avoid code redundancy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32f6e04e-147e-4f54-aabe-f97d4192f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['user'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['item'] = item_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "num_users = ratings_df['user'].nunique()\n",
    "num_items = ratings_df['item'].nunique()\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_data, test_data, adj_matrix=None):\n",
    "    # Prepare the training data\n",
    "    user_indices = train_data['userId'].values\n",
    "    item_indices = train_data['movieId'].values\n",
    "    labels = train_data['rating'].values\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((user_indices, item_indices, labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(train_data)).batch(256)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()  \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(user_indices, item_indices, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            if adj_matrix is not None:\n",
    "                scores = model(user_indices, item_indices, adj_matrix)\n",
    "            else:\n",
    "                scores = model(user_indices, item_indices)\n",
    "            loss = loss_fn(labels, scores)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    num_epochs = 10\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataset:\n",
    "            user_indices_batch, item_indices_batch, labels_batch = batch\n",
    "            loss = train_step(user_indices_batch, item_indices_batch, labels_batch)\n",
    "        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluating the model\n",
    "    predictions = []\n",
    "\n",
    "    test_user_indices = test_data['user'].values\n",
    "    test_item_indices = test_data['item'].values\n",
    "    test_labels = test_data['rating'].values\n",
    "\n",
    "    for (user_index, item_index, label) in zip(test_user_indices, test_item_indices, test_labels):\n",
    "        user_index_tensor = tf.constant([user_index])\n",
    "        item_index_tensor = tf.constant([item_index])\n",
    "        if adj_matrix is not None:\n",
    "            score = model(user_index_tensor, item_index_tensor, adj_matrix).numpy()[0]\n",
    "        else:\n",
    "            score = model(user_index_tensor, item_index_tensor).numpy()[0]\n",
    "        predictions.append((user_index, item_index, label, score, 0))\n",
    "\n",
    "    return predictions, training_time\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    def get_top_n(predictions, n=10):\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "        return top_n\n",
    "\n",
    "    def precision_recall_at_k(predictions, k=10, threshold=0.7): \n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        return precisions, recalls\n",
    "\n",
    "    def compute_mse(predictions):\n",
    "        \"\"\"Compute Mean Squared Error (MSE).\"\"\"\n",
    "        mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "        return mse\n",
    "\n",
    "    \n",
    "    def compute_rmse(predictions):\n",
    "        \"\"\"Compute Root Mean Squared Error (RMSE).\"\"\"\n",
    "        mse = compute_mse(predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "\n",
    "    def compute_mae(predictions):\n",
    "        mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "        return mae\n",
    "\n",
    "    mse = compute_mse(predictions)\n",
    "    rmse = compute_rmse(predictions)\n",
    "    mae = compute_mae(predictions)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10)\n",
    "\n",
    "    precision_at_10 = np.mean(list(precisions.values()))\n",
    "    recall_at_10 = np.mean(list(recalls.values()))\n",
    "\n",
    "    return mse,rmse, mae, precision_at_10, recall_at_10\n",
    "\n",
    "# Function to run evaluation for each model and scenario\n",
    "def run_evaluation(model, model_name, train_data, test_data, adj_matrix=None):\n",
    "    predictions, training_time = evaluate_model(model, train_data, test_data, adj_matrix)\n",
    "    mse,rmse, mae, precision_at_10, recall_at_10 = compute_metrics(predictions)\n",
    "    results = pd.DataFrame({\n",
    "        \"Scenario\": [scenario],\n",
    "        \"Algorithm\": [model_name],\n",
    "        \"MSE\": [mse],\n",
    "        \"RMSE\": [rmse],\n",
    "        \"MAE\": [mae],\n",
    "        \"Precision@10\": [precision_at_10],\n",
    "        \"Recall@10\": [recall_at_10],\n",
    "        \"Running Time (s)\": [training_time]\n",
    "    })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d968f6c-ae5c-4988-80c2-2588ab4105b9",
   "metadata": {},
   "source": [
    "## LightGCN Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdbb08a5-654a-455a-a6bc-90feddde91de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 13.2447 - val_loss: 9.8584\n",
      "Epoch 2/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.6229 - val_loss: 2.7912\n",
      "Epoch 3/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9666 - val_loss: 1.9016\n",
      "Epoch 4/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1804 - val_loss: 1.6163\n",
      "Epoch 5/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.8587 - val_loss: 1.4916\n",
      "Epoch 6/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.7028 - val_loss: 1.4394\n",
      "Epoch 7/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.6087 - val_loss: 1.4152\n",
      "Epoch 8/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5412 - val_loss: 1.4058\n",
      "Epoch 9/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4819 - val_loss: 1.4033\n",
      "Epoch 10/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4406 - val_loss: 1.4041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:11:52.903066: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.0922755002975464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:11:54.316141: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.524085521697998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:11:55.744518: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.42562562227249146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:11:57.153378: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.5250903964042664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:11:58.923925: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.8019978404045105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:12:00.585689: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.22949157655239105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:12:02.031194: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.45636817812919617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:12:03.457016: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.19849999248981476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:12:05.989493: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.4597753882408142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:12:07.394507: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.2639344036579132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:13:16.936800: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:13:17.099273: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.30010613799095154\n",
      "Epoch 1, Loss: 0.18591414391994476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:13:17.264555: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:13:17.411207: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.13295550644397736\n",
      "Epoch 3, Loss: 0.10314126312732697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:13:17.568115: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:13:17.720397: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.08264755457639694\n",
      "Epoch 5, Loss: 0.11699971556663513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:13:17.860603: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:13:18.005621: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.06872354447841644\n",
      "Epoch 7, Loss: 0.08671410381793976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:13:18.159858: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:13:18.306919: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.05715125799179077\n",
      "Epoch 9, Loss: 0.06465554982423782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:23:31.950517: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.957898: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.964924: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.971387: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.979132: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.986603: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.994938: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:32.002107: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:32.009092: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:32.016952: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2316470891237259\n",
      "Epoch 1, Loss: 0.20376814901828766\n",
      "Epoch 2, Loss: 0.1803845763206482\n",
      "Epoch 3, Loss: 0.16075095534324646\n",
      "Epoch 4, Loss: 0.1441202163696289\n",
      "Epoch 5, Loss: 0.12986089289188385\n",
      "Epoch 6, Loss: 0.11745857447385788\n",
      "Epoch 7, Loss: 0.10649746656417847\n",
      "Epoch 8, Loss: 0.09666289389133453\n",
      "Epoch 9, Loss: 0.08773539960384369\n",
      "   Scenario Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
      "0    Normal  LightGCN  1.300472  1.140382  0.814420      0.749278   0.503184   \n",
      "1    Sparse  LightGCN  1.353399  1.163357  0.837602      0.750687   0.504528   \n",
      "2  New User  LightGCN  1.352309  1.162888  0.837188      0.751206   0.504964   \n",
      "\n",
      "   Running Time (s)  \n",
      "0         16.588426  \n",
      "1          2.137099  \n",
      "2          0.539947  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['user'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['item'] = item_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "num_users = ratings_df['user'].nunique()\n",
    "num_items = ratings_df['item'].nunique()\n",
    "\n",
    "def evaluate_model(model, train_data, test_data, adj_matrix=None):\n",
    "    # Prepare the training data\n",
    "    user_indices = train_data['user'].values\n",
    "    item_indices = train_data['item'].values\n",
    "    labels = train_data['rating'].values\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((user_indices, item_indices, labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(train_data)).batch(256)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()  \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(user_indices, item_indices, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            scores = model((user_indices, item_indices))\n",
    "            loss = loss_fn(labels, scores)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    num_epochs = 10\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataset:\n",
    "            user_indices_batch, item_indices_batch, labels_batch = batch\n",
    "            loss = train_step(user_indices_batch, item_indices_batch, labels_batch)\n",
    "        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluating the model\n",
    "    predictions = []\n",
    "\n",
    "    test_user_indices = test_data['user'].values\n",
    "    test_item_indices = test_data['item'].values\n",
    "    test_labels = test_data['rating'].values\n",
    "\n",
    "    for (user_index, item_index, label) in zip(test_user_indices, test_item_indices, test_labels):\n",
    "        user_index_tensor = tf.constant([user_index])\n",
    "        item_index_tensor = tf.constant([item_index])\n",
    "        score = model((user_index_tensor, item_index_tensor)).numpy()[0]\n",
    "        predictions.append((user_index, item_index, label, score, 0))\n",
    "\n",
    "    return predictions, training_time\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    def get_top_n(predictions, n=10):\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "        return top_n\n",
    "\n",
    "    def precision_recall_at_k(predictions, k=10, threshold=3.5): \n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        return precisions, recalls\n",
    "\n",
    "    def compute_mse(predictions):\n",
    "        \"\"\"Compute Mean Squared Error (MSE).\"\"\"\n",
    "        mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "        return mse\n",
    "\n",
    "    def compute_rmse(predictions):\n",
    "        \"\"\"Compute Root Mean Squared Error (RMSE).\"\"\"\n",
    "        mse = compute_mse(predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "\n",
    "    def compute_mae(predictions):\n",
    "        mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "        return mae\n",
    "\n",
    "    mse = compute_mse(predictions)\n",
    "    rmse = compute_rmse(predictions)\n",
    "    mae = compute_mae(predictions)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10)\n",
    "\n",
    "    precision_at_10 = np.mean(list(precisions.values()))\n",
    "    recall_at_10 = np.mean(list(recalls.values()))\n",
    "\n",
    "    return mse, rmse, mae, precision_at_10, recall_at_10\n",
    "\n",
    "# Function to run evaluation for each model and scenario\n",
    "def run_evaluation(model, model_name, train_data, test_data, adj_matrix=None):\n",
    "    predictions, training_time = evaluate_model(model, train_data, test_data, adj_matrix)\n",
    "    mse, rmse, mae, precision_at_10, recall_at_10 = compute_metrics(predictions)\n",
    "    results = pd.DataFrame({\n",
    "        \"Scenario\": [scenario],\n",
    "        \"Algorithm\": [model_name],\n",
    "        \"MSE\": [mse],\n",
    "        \"RMSE\": [rmse],\n",
    "        \"MAE\": [mae],\n",
    "        \"Precision@10\": [precision_at_10],\n",
    "        \"Recall@10\": [recall_at_10],\n",
    "        \"Running Time (s)\": [training_time]\n",
    "    })\n",
    "    return results\n",
    "\n",
    "# Evaluate LightGCN\n",
    "class LightGCN(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, **kwargs):\n",
    "        super(LightGCN, self).__init__(**kwargs)\n",
    "        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_indices, item_indices = inputs\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        scores = tf.reduce_sum(user_embeddings * item_embeddings, axis=1)\n",
    "        return scores\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(LightGCN, self).get_config()\n",
    "        config.update({\n",
    "            'num_users': self.num_users,\n",
    "            'num_items': self.num_items,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "embedding_dim = 64\n",
    "lightgcn_model = LightGCN(num_users, num_items, embedding_dim)\n",
    "\n",
    "# Step 1: Split the data into training and test sets (80% training, 20% testing)\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=0.20, random_state=42)\n",
    "\n",
    "# Callbacks for early stopping and model checkpointing\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "# Compile the model\n",
    "lightgcn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model with early stopping and model checkpointing\n",
    "history = lightgcn_model.fit(\n",
    "    x=(train_df['user'].values, train_df['item'].values),\n",
    "    y=train_df['rating'].values,\n",
    "    epochs=10,  \n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model('best_model.keras', custom_objects={'LightGCN': LightGCN})\n",
    "\n",
    "def get_sparse_data(ratings, frac=0.1):\n",
    "    # Placeholder function to get sparse data. Replace with actual logic.\n",
    "    return ratings.sample(frac=frac, random_state=42)\n",
    "\n",
    "def get_new_user_data(ratings, frac=0.1):\n",
    "    # Placeholder function to get new user data. Replace with actual logic.\n",
    "    new_user_indices = ratings['user'].drop_duplicates().sample(frac=frac, random_state=42).index\n",
    "    return ratings[ratings['user'].isin(new_user_indices)]\n",
    "\n",
    "# Evaluate normal scenario\n",
    "scenario = \"Normal\"\n",
    "results_lightGCN_normal = run_evaluation(best_model, \"LightGCN\", train_df, test_df)\n",
    "\n",
    "# Evaluate sparse scenario\n",
    "scenario = \"Sparse\"\n",
    "sparse_train_df = get_sparse_data(train_df, frac=0.1)\n",
    "results_lightGCN_sparse = run_evaluation(best_model, \"LightGCN\", sparse_train_df, test_df)\n",
    "\n",
    "# Evaluate new user scenario\n",
    "scenario = \"New User\"\n",
    "new_user_train_df = get_new_user_data(train_df, frac=0.1)\n",
    "results_lightGCN_new_user = run_evaluation(best_model, \"LightGCN\", new_user_train_df, test_df)\n",
    "\n",
    "# Combine LightGCN results into a single DataFrame\n",
    "results_lightGCN_combined = pd.concat([results_lightGCN_normal, results_lightGCN_sparse, results_lightGCN_new_user], ignore_index=True)\n",
    "\n",
    "# Display the combined results\n",
    "print(results_lightGCN_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "213f2a71-95e9-4551-bdda-9708052622dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>1.300472</td>\n",
       "      <td>1.140382</td>\n",
       "      <td>0.814420</td>\n",
       "      <td>0.749278</td>\n",
       "      <td>0.503184</td>\n",
       "      <td>16.588426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>1.353399</td>\n",
       "      <td>1.163357</td>\n",
       "      <td>0.837602</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.504528</td>\n",
       "      <td>2.137099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>1.352309</td>\n",
       "      <td>1.162888</td>\n",
       "      <td>0.837188</td>\n",
       "      <td>0.751206</td>\n",
       "      <td>0.504964</td>\n",
       "      <td>0.539947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal  LightGCN  1.300472  1.140382  0.814420      0.749278   0.503184   \n",
       "1    Sparse  LightGCN  1.353399  1.163357  0.837602      0.750687   0.504528   \n",
       "2  New User  LightGCN  1.352309  1.162888  0.837188      0.751206   0.504964   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         16.588426  \n",
       "1          2.137099  \n",
       "2          0.539947  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine LightGCN results into a single DataFrame\n",
    "results_lightGCN_combined = pd.concat([results_lightGCN_normal, results_lightGCN_sparse, results_lightGCN_new_user], ignore_index=True)\n",
    "results_lightGCN_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc96032-1d22-4171-9770-97ba4d3541e4",
   "metadata": {},
   "source": [
    "# Graph Attention Network (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91902bd9-d579-40fc-a596-937263cfec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 4.4186 - val_loss: 1.1508\n",
      "Epoch 2/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 1.1240 - val_loss: 1.1469\n",
      "Epoch 3/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 1.1112 - val_loss: 1.0692\n",
      "Epoch 4/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 1.0319 - val_loss: 1.0472\n",
      "Epoch 5/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.9298 - val_loss: 0.9864\n",
      "Epoch 6/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.9177 - val_loss: 1.0135\n",
      "Epoch 7/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.8428 - val_loss: 0.9277\n",
      "Epoch 8/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.8204 - val_loss: 0.9054\n",
      "Epoch 9/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.7728 - val_loss: 0.8885\n",
      "Epoch 10/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.7501 - val_loss: 0.8999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:730: UserWarning: Model 'gat_model_3' had a build config, but the model cannot be built automatically in `build_from_config(config)`. You should implement `def build_from_config(self, config)`, and you might also want to implement the method  that generates the config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the model (i.e. its variables) upon deserialization.\n",
      "  instance.build_from_config(build_config)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 6 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "2024-08-09 13:33:08.085953: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8535671234130859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:15.026881: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.791020929813385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:22.008986: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6955035328865051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:28.899304: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.5415529608726501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:35.857575: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.5138713717460632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:42.872480: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.6965969204902649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:53.050636: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.4879266917705536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:34:00.334246: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.5766206979751587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:34:08.420728: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.7400653958320618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:34:15.490516: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.819345235824585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:36.839548: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.681725263595581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:37.591673: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5210167169570923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:38.307332: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6364299654960632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:38.997344: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.5478856563568115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:39.727801: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.5958749055862427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:40.445690: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.5913105607032776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:41.186559: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.4851212501525879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:41.917518: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.645758330821991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:42.648162: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.5348884463310242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:43.371272: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.5008713603019714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:42:57.508671: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.524851: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.536148: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.547046: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.558032: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.569295: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.580212: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.591738: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.602860: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.613922: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5133550763130188\n",
      "Epoch 1, Loss: 0.4729280471801758\n",
      "Epoch 2, Loss: 0.5329741835594177\n",
      "Epoch 3, Loss: 0.32601064443588257\n",
      "Epoch 4, Loss: 0.2739917039871216\n",
      "Epoch 5, Loss: 0.3939181864261627\n",
      "Epoch 6, Loss: 0.3761257827281952\n",
      "Epoch 7, Loss: 0.27111342549324036\n",
      "Epoch 8, Loss: 0.24785055220127106\n",
      "Epoch 9, Loss: 0.29781031608581543\n",
      "   Scenario Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
      "0    Normal       GAT  5.279527  2.297722  1.813445      0.640868   0.339237   \n",
      "1    Sparse       GAT  9.903407  3.146968  2.508598      0.665226   0.375002   \n",
      "2  New User       GAT  8.366129  2.892426  2.294709      0.656693   0.358051   \n",
      "\n",
      "   Running Time (s)  \n",
      "0         76.762282  \n",
      "1          9.373171  \n",
      "2          2.174327  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['user'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['item'] = item_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "num_users = ratings_df['user'].nunique()\n",
    "num_items = ratings_df['item'].nunique()\n",
    "\n",
    "def evaluate_model(model, train_data, test_data):\n",
    "    # Prepare the training data\n",
    "    user_indices = train_data['user'].values\n",
    "    item_indices = train_data['item'].values\n",
    "    labels = train_data['rating'].values\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((user_indices, item_indices, labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(train_data)).batch(256)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()  \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(user_indices, item_indices, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            scores = model((user_indices, item_indices))\n",
    "            loss = loss_fn(labels, scores)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    num_epochs = 10\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataset:\n",
    "            user_indices_batch, item_indices_batch, labels_batch = batch\n",
    "            loss = train_step(user_indices_batch, item_indices_batch, labels_batch)\n",
    "        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluating the model\n",
    "    predictions = []\n",
    "\n",
    "    test_user_indices = test_data['user'].values\n",
    "    test_item_indices = test_data['item'].values\n",
    "    test_labels = test_data['rating'].values\n",
    "\n",
    "    for (user_index, item_index, label) in zip(test_user_indices, test_item_indices, test_labels):\n",
    "        user_index_tensor = tf.constant([user_index])\n",
    "        item_index_tensor = tf.constant([item_index])\n",
    "        score = model((user_index_tensor, item_index_tensor)).numpy()[0]\n",
    "        predictions.append((user_index, item_index, label, score, 0))\n",
    "\n",
    "    return predictions, training_time\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    def get_top_n(predictions, n=10):\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "        return top_n\n",
    "\n",
    "    def precision_recall_at_k(predictions, k=10, threshold=3.5): \n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        return precisions, recalls\n",
    "\n",
    "    def compute_mse(predictions):\n",
    "        \"\"\"Compute Mean Squared Error (MSE).\"\"\"\n",
    "        mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "        return mse\n",
    "\n",
    "    def compute_rmse(predictions):\n",
    "        \"\"\"Compute Root Mean Squared Error (RMSE).\"\"\"\n",
    "        mse = compute_mse(predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "\n",
    "    def compute_mae(predictions):\n",
    "        mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "        return mae\n",
    "\n",
    "    mse = compute_mse(predictions)\n",
    "    rmse = compute_rmse(predictions)\n",
    "    mae = compute_mae(predictions)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10)\n",
    "\n",
    "    precision_at_10 = np.mean(list(precisions.values()))\n",
    "    recall_at_10 = np.mean(list(recalls.values()))\n",
    "\n",
    "    return mse, rmse, mae, precision_at_10, recall_at_10\n",
    "\n",
    "# Function to run evaluation for each model and scenario\n",
    "def run_evaluation(model, model_name, train_data, test_data):\n",
    "    predictions, training_time = evaluate_model(model, train_data, test_data)\n",
    "    mse, rmse, mae, precision_at_10, recall_at_10 = compute_metrics(predictions)\n",
    "    results = pd.DataFrame({\n",
    "        \"Scenario\": [scenario],\n",
    "        \"Algorithm\": [model_name],\n",
    "        \"MSE\": [mse],\n",
    "        \"RMSE\": [rmse],\n",
    "        \"MAE\": [mae],\n",
    "        \"Precision@10\": [precision_at_10],\n",
    "        \"Recall@10\": [recall_at_10],\n",
    "        \"Running Time (s)\": [training_time]\n",
    "    })\n",
    "    return results\n",
    "\n",
    "# Evaluate GAT\n",
    "class GraphAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, attn_heads=1, dropout_rate=0.0, **kwargs):\n",
    "        super(GraphAttentionLayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.attn_heads = attn_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.attn_kernels = []\n",
    "        self.attn_self_kernels = []\n",
    "\n",
    "        for _ in range(attn_heads):\n",
    "            self.attn_kernels.append(tf.keras.layers.Dense(output_dim, use_bias=False))\n",
    "            self.attn_self_kernels.append(tf.keras.layers.Dense(1, use_bias=False))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features, adj_matrix = inputs\n",
    "        attn_outs = []\n",
    "\n",
    "        for kernel, self_kernel in zip(self.attn_kernels, self.attn_self_kernels):\n",
    "            attn_out = kernel(features)\n",
    "            attn_self = self_kernel(features)\n",
    "            attn_all = tf.add(attn_self, tf.transpose(attn_self))\n",
    "            attn_all = tf.nn.leaky_relu(attn_all)\n",
    "            attn_all = tf.nn.softmax(attn_all, axis=-1)\n",
    "            attn_all = self.dropout(attn_all)\n",
    "            node_features = tf.matmul(attn_all, attn_out)\n",
    "            attn_outs.append(node_features)\n",
    "\n",
    "        return tf.concat(attn_outs, axis=-1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GraphAttentionLayer, self).get_config()\n",
    "        config.update({\n",
    "            'output_dim': self.output_dim,\n",
    "            'attn_heads': self.attn_heads,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "class GATModel(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, attn_heads=1, dropout_rate=0.0, **kwargs):\n",
    "        super(GATModel, self).__init__(**kwargs)\n",
    "        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
    "        self.gat_layer = GraphAttentionLayer(embedding_dim, attn_heads, dropout_rate)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.attn_heads = attn_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.adj_matrix = None\n",
    "\n",
    "    def set_adj_matrix(self, adj_matrix):\n",
    "        self.adj_matrix = adj_matrix\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_indices, item_indices = inputs\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        all_embeddings = tf.concat([user_embeddings, item_embeddings], axis=0)\n",
    "        all_embeddings = self.gat_layer([all_embeddings, self.adj_matrix])\n",
    "        user_embeddings = all_embeddings[:tf.shape(user_indices)[0]]\n",
    "        item_embeddings = all_embeddings[tf.shape(user_indices)[0]:]\n",
    "        scores = tf.reduce_sum(user_embeddings * item_embeddings, axis=1)\n",
    "        return scores\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GATModel, self).get_config()\n",
    "        config.update({\n",
    "            'num_users': self.num_users,\n",
    "            'num_items': self.num_items,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "            'attn_heads': self.attn_heads,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "adj_matrix = np.zeros((num_users + num_items, num_users + num_items))\n",
    "for _, row in ratings_df.iterrows():\n",
    "    user_id = int(row['user'])\n",
    "    item_id = int(row['item']) + num_users\n",
    "    adj_matrix[user_id, item_id] = 1\n",
    "    adj_matrix[item_id, user_id] = 1\n",
    "\n",
    "adj_matrix = tf.convert_to_tensor(adj_matrix, dtype=tf.float32)\n",
    "\n",
    "embedding_dim = 64\n",
    "attn_heads = 4\n",
    "dropout_rate = 0.5\n",
    "gat_model = GATModel(num_users, num_items, embedding_dim, attn_heads, dropout_rate)\n",
    "gat_model.set_adj_matrix(adj_matrix)\n",
    "\n",
    "# Callbacks for early stopping and model checkpointing\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_gat_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "# Compile the model\n",
    "gat_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model with early stopping and model checkpointing\n",
    "history = gat_model.fit(\n",
    "    x=[train_df['user'].values, train_df['item'].values],\n",
    "    y=train_df['rating'].values,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "best_gat_model = tf.keras.models.load_model('best_gat_model.keras', custom_objects={'GATModel': GATModel, 'GraphAttentionLayer': GraphAttentionLayer})\n",
    "best_gat_model.set_adj_matrix(adj_matrix)\n",
    "\n",
    "\n",
    "# Evaluate normal scenario\n",
    "scenario = \"Normal\"\n",
    "results_GAT_normal = run_evaluation(best_gat_model, \"GAT\", train_df, test_df)\n",
    "\n",
    "# Evaluate sparse scenario\n",
    "scenario = \"Sparse\"\n",
    "sparse_train_df = get_sparse_data(train_df, frac=0.1)\n",
    "results_GAT_sparse = run_evaluation(best_gat_model, \"GAT\", sparse_train_df, test_df)\n",
    "\n",
    "# Evaluate new user scenario\n",
    "scenario = \"New User\"\n",
    "new_user_train_df = get_new_user_data(train_df, frac=0.1)\n",
    "results_GAT_new_user = run_evaluation(best_gat_model, \"GAT\", new_user_train_df, test_df)\n",
    "\n",
    "# Combine GAT results into a single DataFrame\n",
    "results_GAT_combined = pd.concat([results_GAT_normal, results_GAT_sparse, results_GAT_new_user], ignore_index=True)\n",
    "\n",
    "# Display the combined results\n",
    "print(results_GAT_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7ec1843-a850-4e9c-aecc-6bda789937e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>GAT</td>\n",
       "      <td>5.279527</td>\n",
       "      <td>2.297722</td>\n",
       "      <td>1.813445</td>\n",
       "      <td>0.640868</td>\n",
       "      <td>0.339237</td>\n",
       "      <td>76.762282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>GAT</td>\n",
       "      <td>9.903407</td>\n",
       "      <td>3.146968</td>\n",
       "      <td>2.508598</td>\n",
       "      <td>0.665226</td>\n",
       "      <td>0.375002</td>\n",
       "      <td>9.373171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>GAT</td>\n",
       "      <td>8.366129</td>\n",
       "      <td>2.892426</td>\n",
       "      <td>2.294709</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.358051</td>\n",
       "      <td>2.174327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal       GAT  5.279527  2.297722  1.813445      0.640868   0.339237   \n",
       "1    Sparse       GAT  9.903407  3.146968  2.508598      0.665226   0.375002   \n",
       "2  New User       GAT  8.366129  2.892426  2.294709      0.656693   0.358051   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         76.762282  \n",
       "1          9.373171  \n",
       "2          2.174327  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_GAT_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb63d5-b62b-4fbf-b57c-51a02556efbf",
   "metadata": {},
   "source": [
    "# GraphSAGE (SAmple and aggreGatE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb21c9c-5543-49af-a8a1-ffd870a89014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 3.2163 - val_loss: 1.5399\n",
      "Epoch 2/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 1.1261 - val_loss: 1.1178\n",
      "Epoch 3/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - loss: 0.8146 - val_loss: 1.0694\n",
      "Epoch 4/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 0.7007 - val_loss: 1.0774\n",
      "Epoch 5/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 0.6651 - val_loss: 1.1709\n",
      "Epoch 6/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - loss: 0.6228 - val_loss: 1.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:730: UserWarning: Model 'graph_sage_model_2' had a build config, but the model cannot be built automatically in `build_from_config(config)`. You should implement `def build_from_config(self, config)`, and you might also want to implement the method  that generates the config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the model (i.e. its variables) upon deserialization.\n",
      "  instance.build_from_config(build_config)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "2024-08-08 20:33:48.929446: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8244467973709106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:33:55.527243: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8825513124465942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:02.429511: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6544685363769531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:09.064167: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.7395923733711243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:15.658951: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.7510672211647034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:22.298359: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.5206165909767151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:29.336899: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.41095617413520813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:37.019341: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.2692623138427734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:44.164126: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.6173475980758667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:51.570223: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.24220798909664154\n",
      "  Scenario  Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
      "0   Normal  GraphSAGE  0.995274  0.997634  0.765923      0.737043   0.525224   \n",
      "\n",
      "   Running Time (s)  \n",
      "0         71.149196  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['user'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['item'] = item_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "num_users = ratings_df['user'].nunique()\n",
    "num_items = ratings_df['item'].nunique()\n",
    "\n",
    "# Adjacency Matrix Construction\n",
    "adj_matrix = lil_matrix((num_users + num_items, num_users + num_items))\n",
    "for _, row in ratings_df.iterrows():\n",
    "    user_id = int(row['user'])\n",
    "    item_id = int(row['item']) + num_users\n",
    "    adj_matrix[user_id, item_id] = 1\n",
    "    adj_matrix[item_id, user_id] = 1\n",
    "\n",
    "adj_matrix = csr_matrix(adj_matrix)\n",
    "\n",
    "# Convert to TensorFlow SparseTensor\n",
    "adj_matrix_indices = np.vstack((adj_matrix.nonzero()[0], adj_matrix.nonzero()[1])).T\n",
    "adj_matrix_values = adj_matrix.data\n",
    "adj_matrix_shape = adj_matrix.shape\n",
    "\n",
    "adj_matrix = tf.sparse.SparseTensor(\n",
    "    indices=adj_matrix_indices,\n",
    "    values=adj_matrix_values,\n",
    "    dense_shape=adj_matrix_shape\n",
    ")\n",
    "\n",
    "# Ensure the sparse tensor is properly ordered\n",
    "adj_matrix = tf.sparse.reorder(adj_matrix)\n",
    "\n",
    "class GraphSAGELayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, aggregator_type='mean', dropout_rate=0.0, **kwargs):\n",
    "        super(GraphSAGELayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.aggregator_type = aggregator_type\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dense_self = tf.keras.layers.Dense(output_dim, use_bias=False)\n",
    "        self.dense_neighbor = tf.keras.layers.Dense(output_dim, use_bias=False)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.act = tf.nn.relu\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features, adj_matrix = inputs\n",
    "        neighbor_features = tf.sparse.sparse_dense_matmul(adj_matrix, features)\n",
    "        node_features = self.dense_self(features) + self.dense_neighbor(neighbor_features)\n",
    "        node_features = self.act(node_features)\n",
    "        node_features = self.dropout(node_features)\n",
    "        return node_features\n",
    "\n",
    "class GraphSAGEModel(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, aggregator_type='mean', dropout_rate=0.0, **kwargs):\n",
    "        super(GraphSAGEModel, self).__init__(**kwargs)\n",
    "        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
    "        self.graphsage_layer = GraphSAGELayer(embedding_dim, aggregator_type, dropout_rate)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.aggregator_type = aggregator_type\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.adj_matrix = None\n",
    "\n",
    "    def set_adj_matrix(self, adj_matrix):\n",
    "        self.adj_matrix = adj_matrix\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_indices, item_indices = inputs\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        all_user_embeddings = self.user_embedding(tf.range(self.num_users))\n",
    "        all_item_embeddings = self.item_embedding(tf.range(self.num_items))\n",
    "        all_embeddings = tf.concat([all_user_embeddings, all_item_embeddings], axis=0)\n",
    "        all_embeddings = self.graphsage_layer([all_embeddings, self.adj_matrix])\n",
    "        user_embeddings = tf.gather(all_embeddings, user_indices)\n",
    "        item_embeddings = tf.gather(all_embeddings, item_indices + self.num_users)\n",
    "        scores = tf.reduce_sum(user_embeddings * item_embeddings, axis=1)\n",
    "        return scores\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GraphSAGEModel, self).get_config()\n",
    "        config.update({\n",
    "            'num_users': self.num_users,\n",
    "            'num_items': self.num_items,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "            'aggregator_type': self.aggregator_type,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Set the adjacency matrix\n",
    "embedding_dim = 64\n",
    "aggregator_type = 'mean'\n",
    "dropout_rate = 0.5\n",
    "graphsage_model = GraphSAGEModel(num_users, num_items, embedding_dim, aggregator_type, dropout_rate)\n",
    "graphsage_model.set_adj_matrix(adj_matrix)\n",
    "\n",
    "# Callbacks for early stopping and model checkpointing\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_graphsage_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "# Compile the model\n",
    "graphsage_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Prepare training and testing data (assuming train_df and test_df are predefined)\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with early stopping and model checkpointing\n",
    "history = graphsage_model.fit(\n",
    "    x=[train_df['user'].values, train_df['item'].values],\n",
    "    y=train_df['rating'].values,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "best_graphsage_model = tf.keras.models.load_model('best_graphsage_model.keras', custom_objects={'GraphSAGEModel': GraphSAGEModel, 'GraphSAGELayer': GraphSAGELayer})\n",
    "best_graphsage_model.set_adj_matrix(adj_matrix)\n",
    "\n",
    "# Evaluate normal scenario\n",
    "scenario = \"Normal\"\n",
    "results_SAGE_normal = run_evaluation(best_graphsage_model, \"GraphSAGE\", train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa051b3-0d87-4a79-bada-6085d57e1435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:40.752479: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5703974366188049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:41.434409: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.509819746017456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:42.130202: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.26427775621414185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:42.809304: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.296459823846817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:43.490807: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.3283613324165344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:44.196381: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.21200093626976013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:44.867099: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.25174692273139954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:45.545930: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.16219724714756012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:46.217347: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.21970874071121216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:46.920936: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.15669916570186615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:48:22.836179: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.862791: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.887528: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.914367: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.937209: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.959044: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.981578: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:23.005962: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:23.028798: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.44780388474464417\n",
      "Epoch 1, Loss: 3.4853625297546387\n",
      "Epoch 2, Loss: 0.2548128366470337\n",
      "Epoch 3, Loss: 0.9237936735153198\n",
      "Epoch 4, Loss: 1.4512138366699219\n",
      "Epoch 5, Loss: 1.2539323568344116\n",
      "Epoch 6, Loss: 0.6974046230316162\n",
      "Epoch 7, Loss: 0.308746874332428\n",
      "Epoch 8, Loss: 0.47734466195106506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:48:23.061360: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.7331115007400513\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NormalSparseNew User</td>\n",
       "      <td>GraphSAGEGraphSAGEGraphSAGE</td>\n",
       "      <td>4.539952</td>\n",
       "      <td>3.623258</td>\n",
       "      <td>2.8031</td>\n",
       "      <td>2.19935</td>\n",
       "      <td>1.495469</td>\n",
       "      <td>80.491525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Scenario                    Algorithm       MSE      RMSE  \\\n",
       "0  NormalSparseNew User  GraphSAGEGraphSAGEGraphSAGE  4.539952  3.623258   \n",
       "\n",
       "      MAE  Precision@10  Recall@10  Running Time (s)  \n",
       "0  2.8031       2.19935   1.495469         80.491525  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate sparse scenario\n",
    "scenario = \"Sparse\"\n",
    "sparse_train_df = get_sparse_data(train_df, frac=0.1)\n",
    "results_SAGE_sparse = run_evaluation(best_graphsage_model, \"GraphSAGE\", sparse_train_df, test_df)\n",
    "\n",
    "# Evaluate new user scenario\n",
    "scenario = \"New User\"\n",
    "new_user_train_df = get_new_user_data(train_df, frac=0.1)\n",
    "results_SAGE_new_user = run_evaluation(best_graphsage_model, \"GraphSAGE\", new_user_train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee3cb63e-c30d-4294-b14d-b9822188b7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>0.997634</td>\n",
       "      <td>0.765923</td>\n",
       "      <td>0.737043</td>\n",
       "      <td>0.525224</td>\n",
       "      <td>71.149196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>1.191938</td>\n",
       "      <td>1.091759</td>\n",
       "      <td>0.853637</td>\n",
       "      <td>0.729891</td>\n",
       "      <td>0.473050</td>\n",
       "      <td>8.101512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>2.352740</td>\n",
       "      <td>1.533864</td>\n",
       "      <td>1.183540</td>\n",
       "      <td>0.732416</td>\n",
       "      <td>0.497194</td>\n",
       "      <td>1.240817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario  Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal  GraphSAGE  0.995274  0.997634  0.765923      0.737043   0.525224   \n",
       "1    Sparse  GraphSAGE  1.191938  1.091759  0.853637      0.729891   0.473050   \n",
       "2  New User  GraphSAGE  2.352740  1.533864  1.183540      0.732416   0.497194   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         71.149196  \n",
       "1          8.101512  \n",
       "2          1.240817  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_SAGE_combined = pd.concat([results_SAGE_normal, results_SAGE_sparse, results_SAGE_new_user], ignore_index=True)\n",
    "results_SAGE_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a0c71-348e-4654-8787-236b1950368e",
   "metadata": {},
   "source": [
    "## Final Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aeb0823-942b-4a12-84e8-4cc806306534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>1.300472</td>\n",
       "      <td>1.140382</td>\n",
       "      <td>0.814420</td>\n",
       "      <td>0.749278</td>\n",
       "      <td>0.503184</td>\n",
       "      <td>16.588426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>1.353399</td>\n",
       "      <td>1.163357</td>\n",
       "      <td>0.837602</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.504528</td>\n",
       "      <td>2.137099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>1.352309</td>\n",
       "      <td>1.162888</td>\n",
       "      <td>0.837188</td>\n",
       "      <td>0.751206</td>\n",
       "      <td>0.504964</td>\n",
       "      <td>0.539947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>GAT</td>\n",
       "      <td>5.279527</td>\n",
       "      <td>2.297722</td>\n",
       "      <td>1.813445</td>\n",
       "      <td>0.640868</td>\n",
       "      <td>0.339237</td>\n",
       "      <td>76.762282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>GAT</td>\n",
       "      <td>9.903407</td>\n",
       "      <td>3.146968</td>\n",
       "      <td>2.508598</td>\n",
       "      <td>0.665226</td>\n",
       "      <td>0.375002</td>\n",
       "      <td>9.373171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New User</td>\n",
       "      <td>GAT</td>\n",
       "      <td>8.366129</td>\n",
       "      <td>2.892426</td>\n",
       "      <td>2.294709</td>\n",
       "      <td>0.656693</td>\n",
       "      <td>0.358051</td>\n",
       "      <td>2.174327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Normal</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>0.997634</td>\n",
       "      <td>0.765923</td>\n",
       "      <td>0.737043</td>\n",
       "      <td>0.525224</td>\n",
       "      <td>71.149196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>1.191938</td>\n",
       "      <td>1.091759</td>\n",
       "      <td>0.853637</td>\n",
       "      <td>0.729891</td>\n",
       "      <td>0.473050</td>\n",
       "      <td>8.101512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New User</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>2.352740</td>\n",
       "      <td>1.533864</td>\n",
       "      <td>1.183540</td>\n",
       "      <td>0.732416</td>\n",
       "      <td>0.497194</td>\n",
       "      <td>1.240817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario  Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal   LightGCN  1.300472  1.140382  0.814420      0.749278   0.503184   \n",
       "1    Sparse   LightGCN  1.353399  1.163357  0.837602      0.750687   0.504528   \n",
       "2  New User   LightGCN  1.352309  1.162888  0.837188      0.751206   0.504964   \n",
       "3    Normal        GAT  5.279527  2.297722  1.813445      0.640868   0.339237   \n",
       "4    Sparse        GAT  9.903407  3.146968  2.508598      0.665226   0.375002   \n",
       "5  New User        GAT  8.366129  2.892426  2.294709      0.656693   0.358051   \n",
       "6    Normal  GraphSAGE  0.995274  0.997634  0.765923      0.737043   0.525224   \n",
       "7    Sparse  GraphSAGE  1.191938  1.091759  0.853637      0.729891   0.473050   \n",
       "8  New User  GraphSAGE  2.352740  1.533864  1.183540      0.732416   0.497194   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         16.588426  \n",
       "1          2.137099  \n",
       "2          0.539947  \n",
       "3         76.762282  \n",
       "4          9.373171  \n",
       "5          2.174327  \n",
       "6         71.149196  \n",
       "7          8.101512  \n",
       "8          1.240817  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results = pd.concat([results_LightGCN_combined, results_GAT_combined, results_GraphSAGE_combined], ignore_index=True)\n",
    "combined_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd21ebd-473f-4215-815b-9a2d8b242e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
