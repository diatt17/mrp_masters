{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14b8616-ae1c-4191-ba8b-3f3ac50447f7",
   "metadata": {},
   "source": [
    "# Experimentation and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95904abf-f705-4e53-8bce-a6c3ecb6d93e",
   "metadata": {},
   "source": [
    "## Objective of the project \n",
    "\n",
    "This study seeks to conduct a thorough comparative analysis of these three models, focusing\n",
    "on their performance with regards to accuracy, computational complexity, scalability, and their\n",
    "effectiveness in handling data sparsity and dynamically changing environments. By evaluat-\n",
    "ing these aspects, the research aims to illuminate the operational strengths and weaknesses\n",
    "of each model, providing clear insights that could guide the development and deployment of\n",
    "future recommender systems. Through this comparative framework, we aspire to answer which\n",
    "model, under what conditions, provides the most reliable and robust recommendations, thereby\n",
    "significantly contributing to the optimization of digital services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec1c5afc-8ec3-4beb-9777-ef5cd6260e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter, defaultdict\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD, CoClustering, accuracy\n",
    "#from surprise.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.accuracy import rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d2f34e-8624-4280-9fb9-28ed84c78540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Links':    movieId  imdbId   tmdbId\n",
       " 0        1  114709    862.0\n",
       " 1        2  113497   8844.0\n",
       " 2        3  113228  15602.0\n",
       " 3        4  114885  31357.0\n",
       " 4        5  113041  11862.0,\n",
       " 'Movies':    movieId                               title  \\\n",
       " 0        1                    Toy Story (1995)   \n",
       " 1        2                      Jumanji (1995)   \n",
       " 2        3             Grumpier Old Men (1995)   \n",
       " 3        4            Waiting to Exhale (1995)   \n",
       " 4        5  Father of the Bride Part II (1995)   \n",
       " \n",
       "                                         genres  \n",
       " 0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       " 1                   Adventure|Children|Fantasy  \n",
       " 2                               Comedy|Romance  \n",
       " 3                         Comedy|Drama|Romance  \n",
       " 4                                       Comedy  ,\n",
       " 'Ratings':    userId  movieId  rating  timestamp\n",
       " 0       1        1     4.0  964982703\n",
       " 1       1        3     4.0  964981247\n",
       " 2       1        6     4.0  964982224\n",
       " 3       1       47     5.0  964983815\n",
       " 4       1       50     5.0  964982931,\n",
       " 'Tags':    userId  movieId              tag   timestamp\n",
       " 0       2    60756            funny  1445714994\n",
       " 1       2    60756  Highly quotable  1445714996\n",
       " 2       2    60756     will ferrell  1445714992\n",
       " 3       2    89774     Boxing story  1445715207\n",
       " 4       2    89774              MMA  1445715200}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_df = pd.read_csv('MovieLens_100k/links.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "tags_df = pd.read_csv('MovieLens_100k/tags.csv')\n",
    "\n",
    "datasets = {\n",
    "    \"Links\": links_df,\n",
    "    \"Movies\": movies_df,\n",
    "    \"Ratings\": ratings_df,\n",
    "    \"Tags\": tags_df\n",
    "}\n",
    "\n",
    "datasets_info = {name: df.head() for name, df in datasets.items()}\n",
    "datasets_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffed4e8-5b41-485b-8277-e2a6fba0e61b",
   "metadata": {},
   "source": [
    "## Dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862584cf-a7e4-415e-b6bc-ec7f894fb287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Links dataset:\n",
      "movieId    0\n",
      "imdbId     0\n",
      "tmdbId     8\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Movies dataset:\n",
      "movieId    0\n",
      "title      0\n",
      "genres     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Ratings dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Tags dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "tag          0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each dataset\n",
    "missing_values = {name: df.isnull().sum() for name, df in datasets.items()}\n",
    "\n",
    "# Print the information about missing values\n",
    "for name, missing in missing_values.items():\n",
    "    print(f\"Missing values in {name} dataset:\\n{missing}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713549fa-4fca-4d77-9bb7-7d1f73ef073d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Links DataFrame is: (9742, 3)\n",
      "The shape of the Movies DataFrame is: (9742, 3)\n",
      "The shape of the Ratings DataFrame is: (100836, 4)\n",
      "The shape of the Tags DataFrame is: (3683, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of each DataFrame\n",
    "for name, df in datasets.items():\n",
    "    print(f\"The shape of the {name} DataFrame is: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083bc746-5ced-4d3e-a934-90d141950572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.5</td>\n",
       "      <td>13136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>26818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.5</td>\n",
       "      <td>8551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  count\n",
       "0     0.5   1370\n",
       "1     1.0   2811\n",
       "2     1.5   1791\n",
       "3     2.0   7551\n",
       "4     2.5   5550\n",
       "5     3.0  20047\n",
       "6     3.5  13136\n",
       "7     4.0  26818\n",
       "8     4.5   8551\n",
       "9     5.0  13211"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_of_ratings = ratings_df.groupby('rating').size().reset_index(name='count')\n",
    "distribution_of_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a6200-e172-4221-a145-5f3f9dd4936c",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f3cda-6102-4105-b4b9-a9b9179845b7",
   "metadata": {},
   "source": [
    "### For the collaborative filtering, we have implemented 3 algorithms liisted below: \n",
    "\n",
    "### a. KNNBasic (K-Nearest Neighbors)\n",
    "The KNNBasic algorithm leverages the k-nearest neighbors technique to predict user ratings\n",
    "based on the weighted average of ratings from similar users or items. For KNN, we have chosen 3 different similarity measures to test: Pearson, Pearson baseline and Mean squared difference. Refer to the technical report for more detail. \n",
    "\n",
    "### b. SVD (Singular Value Decomposition)\n",
    "SVD: SVD is a matrix factorization technique that decomposes the user-item rating matrix into\n",
    "latent factors, enabling the prediction of ratings through these latent factors.\n",
    "\n",
    "### c. CoClustering\n",
    "CoClustering: CoClustering simultaneously clusters users and items to uncover hidden re-\n",
    "lationships in the data, facilitating more accurate rating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f052626-a527-4413-a248-c93e56285302",
   "metadata": {},
   "source": [
    "### Useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7402410-d7e1-4228-ad03-d46ab4685c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\"\"\"\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Map the predictions to only the top N items\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def get_top_n_recommendations(user_id, n=10):\n",
    "    # Get a list of all movies in the dataset\n",
    "    all_movies = movies_df['movieId'].unique()\n",
    "    \n",
    "    # Get movies that the user has already rated\n",
    "    rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].tolist()\n",
    "    \n",
    "    # Predict ratings for all movies the user hasn't rated yet\n",
    "    predictions = []\n",
    "    for movie_id in set(all_movies) - set(rated_movies):\n",
    "        pred = model.predict(uid=user_id, iid=movie_id)\n",
    "        predictions.append((movie_id, pred.est))\n",
    "    \n",
    "    # Sort the predictions by estimated rating in descending order and select the top N\n",
    "    top_n = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    # Map the movie IDs back to titles\n",
    "    top_n_movies = [(movies_df[movies_df['movieId'] == mid]['title'].values[0], est) for mid, est in top_n]\n",
    "    \n",
    "    return top_n_movies\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=0.7):  \n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        return precisions, recalls\n",
    "\n",
    "def compute_mse(predictions):\n",
    "    \"\"\"Compute Mean Squared Error (MSE).\"\"\"\n",
    "    mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "    return mse\n",
    "\n",
    "def compute_rmse(predictions):\n",
    "    \"\"\"Compute Root Mean Squared Error (RMSE).\"\"\"\n",
    "    mse = compute_mse(predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def compute_mae(predictions):\n",
    "    \"\"\"Compute Mean Absolute Error (MAE).\"\"\"\n",
    "    mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "    return mae\n",
    "\n",
    "def get_sparse_data(ratings, frac=0.1):\n",
    "    sparse_ratings_df = ratings.sample(frac=frac, random_state=42)  \n",
    "    return sparse_ratings_df\n",
    "\n",
    "def get_new_user_data(ratings, frac=0.1):\n",
    "    new_user_ratings_df = ratings[ratings['userId'].isin(ratings['userId'].sample(frac=frac, random_state=42))]\n",
    "    return new_user_ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955f9e0-cb6e-4303-8d90-591853dd4fa5",
   "metadata": {},
   "source": [
    "### In this part, we use the Surprise library, renowned for its robust implementation of various collaborative filtering algorithms, to evaluate different recommendation system models. Specifically, we implement KNNBasic, SVD, and CoClustering algorithms, chosen for their widespread recognition and effectiveness in collaborative filtering tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b30382f7-3538-4805-b956-cc2b95cb3c28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to evaluate a model with a given algorithm and similarity measure\n",
    "def evaluate_algorithm(algo_name, similarity_measure, train_set, test_set, user_based=True):\n",
    "    if algo_name == 'KNNBasic':\n",
    "        sim_options = {\n",
    "            'name': similarity_measure,\n",
    "            'user_based': user_based\n",
    "        }\n",
    "        model = KNNBasic(sim_options=sim_options)\n",
    "    elif algo_name == 'SVD':\n",
    "        model = SVD()\n",
    "    elif algo_name == 'CoClustering':\n",
    "        model = CoClustering()\n",
    "\n",
    "    # Measure start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_set)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = model.test(test_set)\n",
    "\n",
    "    # Measure end time\n",
    "    end_time = time.time()\n",
    "    # Calculate running time\n",
    "    running_time = end_time - start_time\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    mse_score = accuracy.mse(predictions, verbose=False)\n",
    "    rmse_score = accuracy.rmse(predictions, verbose=False)\n",
    "    mae_score = accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "    # mse_score= compute_mse(predictions)\n",
    "    # rmse_score= compute_rmse(predictions)\n",
    "    # mae_score= compute_mae(predictions)\n",
    "    \n",
    "    # Compute precision and recall\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=0.7)\n",
    "    precision_avg = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall_avg = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    return algo_name, similarity_measure, user_based, mse_score, rmse_score, mae_score, precision_avg, recall_avg, running_time\n",
    "\n",
    "# Function to evaluate all scenarios\n",
    "def evaluate_all_scenarios(train_set, test_set, scenario_name):\n",
    "    results_combined = []\n",
    "    for algo_name, similarity_measure in algorithms:\n",
    "        for user_based in [True, False]:\n",
    "            algo_name, similarity_measure, user_based, mse_score, rmse_score, mae_score, precision_avg, recall_avg, running_time = evaluate_algorithm(algo_name, similarity_measure, train_set, test_set, user_based)\n",
    "            results_combined.append({\n",
    "                'Scenario': scenario_name,\n",
    "                'Algorithm': algo_name,\n",
    "                'Similarity Measure': similarity_measure if similarity_measure else 'N/A',\n",
    "                'User-Based': user_based,\n",
    "                'MSE': mse_score,\n",
    "                'RMSE': rmse_score,\n",
    "                'MAE': mae_score,\n",
    "                'Precision@10': precision_avg,\n",
    "                'Recall@10': recall_avg,\n",
    "                'Running Time (s)': running_time\n",
    "            })\n",
    "    return results_combined\n",
    "\n",
    "\n",
    "reader = Reader(rating_scale=(ratings_df['rating'].min(), ratings_df['rating'].max()))\n",
    "\n",
    "# Step 1: Split the data into training and test sets (80% training, 20% testing)\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=0.20, random_state=42)\n",
    "\n",
    "# Convert the training set into a Surprise dataset\n",
    "train_data = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']], reader)\n",
    "train_set = train_data.build_full_trainset()\n",
    "\n",
    "# Convert the test set into a Surprise dataset for later use\n",
    "test_data = Dataset.load_from_df(test_df[['userId', 'movieId', 'rating']], reader)\n",
    "test_set = test_data.build_full_trainset().build_testset()\n",
    "\n",
    "# Step 2: Create the sparse training set from the 80% training data\n",
    "sparse_train_df = get_sparse_data(train_df, frac=0.1)\n",
    "sparse_data = Dataset.load_from_df(sparse_train_df[['userId', 'movieId', 'rating']], reader)\n",
    "sparse_train_set = sparse_data.build_full_trainset()\n",
    "\n",
    "# Step 3: Create the new user training set from the 80% training data\n",
    "new_user_train_df = get_new_user_data(train_df, frac=0.1)\n",
    "new_user_data = Dataset.load_from_df(new_user_train_df[['userId', 'movieId', 'rating']], reader)\n",
    "new_user_train_set = new_user_data.build_full_trainset()\n",
    "\n",
    "\n",
    "# Output to check\n",
    "train_set.n_ratings, len(test_set)\n",
    "\n",
    "# List of algorithms and their similarity measures to evaluate\n",
    "algorithms = [\n",
    "    ('KNNBasic', 'pearson'),\n",
    "    ('KNNBasic', 'pearson_baseline'),\n",
    "    ('KNNBasic', 'msd'),\n",
    "    ('SVD', None),  # SVD does not use similarity measures\n",
    "    ('CoClustering', None)  # CoClustering does not use similarity measures\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da453d1f-4ba9-4b9e-8041-3e8acccc1c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Similarity Measure</th>\n",
       "      <th>User-Based</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.217433</td>\n",
       "      <td>0.167403</td>\n",
       "      <td>0.681419</td>\n",
       "      <td>0.482391</td>\n",
       "      <td>1.577275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.214941</td>\n",
       "      <td>0.166982</td>\n",
       "      <td>0.517631</td>\n",
       "      <td>0.389731</td>\n",
       "      <td>14.983212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.217501</td>\n",
       "      <td>0.167079</td>\n",
       "      <td>0.676271</td>\n",
       "      <td>0.487729</td>\n",
       "      <td>1.601246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.204038</td>\n",
       "      <td>0.154259</td>\n",
       "      <td>0.609774</td>\n",
       "      <td>0.461591</td>\n",
       "      <td>12.312512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.213605</td>\n",
       "      <td>0.163704</td>\n",
       "      <td>0.672722</td>\n",
       "      <td>0.488166</td>\n",
       "      <td>1.281166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.202160</td>\n",
       "      <td>0.155620</td>\n",
       "      <td>0.522313</td>\n",
       "      <td>0.417250</td>\n",
       "      <td>10.443120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Normal</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.199440</td>\n",
       "      <td>0.153197</td>\n",
       "      <td>0.636856</td>\n",
       "      <td>0.450793</td>\n",
       "      <td>1.219783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Normal</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.199464</td>\n",
       "      <td>0.153466</td>\n",
       "      <td>0.636138</td>\n",
       "      <td>0.449077</td>\n",
       "      <td>1.084938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Normal</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.558738</td>\n",
       "      <td>0.512389</td>\n",
       "      <td>0.111245</td>\n",
       "      <td>0.032385</td>\n",
       "      <td>2.333833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Normal</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.561689</td>\n",
       "      <td>0.513963</td>\n",
       "      <td>0.144278</td>\n",
       "      <td>0.042020</td>\n",
       "      <td>2.316910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.237807</td>\n",
       "      <td>0.188140</td>\n",
       "      <td>0.119334</td>\n",
       "      <td>0.057817</td>\n",
       "      <td>0.037749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.235729</td>\n",
       "      <td>0.186501</td>\n",
       "      <td>0.082593</td>\n",
       "      <td>0.038550</td>\n",
       "      <td>0.524907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.238456</td>\n",
       "      <td>0.187579</td>\n",
       "      <td>0.144836</td>\n",
       "      <td>0.076237</td>\n",
       "      <td>0.047723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.236430</td>\n",
       "      <td>0.186289</td>\n",
       "      <td>0.121704</td>\n",
       "      <td>0.059102</td>\n",
       "      <td>0.238681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.244304</td>\n",
       "      <td>0.189860</td>\n",
       "      <td>0.333362</td>\n",
       "      <td>0.252445</td>\n",
       "      <td>0.024163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.239449</td>\n",
       "      <td>0.185353</td>\n",
       "      <td>0.321258</td>\n",
       "      <td>0.253624</td>\n",
       "      <td>0.161412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.216410</td>\n",
       "      <td>0.169533</td>\n",
       "      <td>0.448187</td>\n",
       "      <td>0.406446</td>\n",
       "      <td>0.127224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.220187</td>\n",
       "      <td>0.172711</td>\n",
       "      <td>0.438220</td>\n",
       "      <td>0.394566</td>\n",
       "      <td>0.113744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.519440</td>\n",
       "      <td>0.448089</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.062898</td>\n",
       "      <td>0.422259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.521285</td>\n",
       "      <td>0.449601</td>\n",
       "      <td>0.112222</td>\n",
       "      <td>0.059269</td>\n",
       "      <td>0.418421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.216375</td>\n",
       "      <td>0.167251</td>\n",
       "      <td>0.684808</td>\n",
       "      <td>0.465282</td>\n",
       "      <td>1.402579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.214508</td>\n",
       "      <td>0.166308</td>\n",
       "      <td>0.534035</td>\n",
       "      <td>0.396585</td>\n",
       "      <td>14.104410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.216124</td>\n",
       "      <td>0.166519</td>\n",
       "      <td>0.692850</td>\n",
       "      <td>0.480907</td>\n",
       "      <td>1.580747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.203326</td>\n",
       "      <td>0.153958</td>\n",
       "      <td>0.627913</td>\n",
       "      <td>0.475188</td>\n",
       "      <td>12.432336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.212011</td>\n",
       "      <td>0.163236</td>\n",
       "      <td>0.689563</td>\n",
       "      <td>0.481867</td>\n",
       "      <td>1.274559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.201419</td>\n",
       "      <td>0.154856</td>\n",
       "      <td>0.516358</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>10.612801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New User</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.198844</td>\n",
       "      <td>0.153150</td>\n",
       "      <td>0.635569</td>\n",
       "      <td>0.438056</td>\n",
       "      <td>1.214717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New User</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.199565</td>\n",
       "      <td>0.153569</td>\n",
       "      <td>0.633467</td>\n",
       "      <td>0.437789</td>\n",
       "      <td>1.104816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New User</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.564291</td>\n",
       "      <td>0.516131</td>\n",
       "      <td>0.158539</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>2.394291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New User</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.561599</td>\n",
       "      <td>0.515394</td>\n",
       "      <td>0.119774</td>\n",
       "      <td>0.033225</td>\n",
       "      <td>2.355567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Scenario     Algorithm Similarity Measure  User-Based      RMSE       MAE  \\\n",
       "0     Normal      KNNBasic            pearson        True  0.217433  0.167403   \n",
       "1     Normal      KNNBasic            pearson       False  0.214941  0.166982   \n",
       "2     Normal      KNNBasic   pearson_baseline        True  0.217501  0.167079   \n",
       "3     Normal      KNNBasic   pearson_baseline       False  0.204038  0.154259   \n",
       "4     Normal      KNNBasic                msd        True  0.213605  0.163704   \n",
       "5     Normal      KNNBasic                msd       False  0.202160  0.155620   \n",
       "6     Normal           SVD                N/A        True  0.199440  0.153197   \n",
       "7     Normal           SVD                N/A       False  0.199464  0.153466   \n",
       "8     Normal  CoClustering                N/A        True  0.558738  0.512389   \n",
       "9     Normal  CoClustering                N/A       False  0.561689  0.513963   \n",
       "10    Sparse      KNNBasic            pearson        True  0.237807  0.188140   \n",
       "11    Sparse      KNNBasic            pearson       False  0.235729  0.186501   \n",
       "12    Sparse      KNNBasic   pearson_baseline        True  0.238456  0.187579   \n",
       "13    Sparse      KNNBasic   pearson_baseline       False  0.236430  0.186289   \n",
       "14    Sparse      KNNBasic                msd        True  0.244304  0.189860   \n",
       "15    Sparse      KNNBasic                msd       False  0.239449  0.185353   \n",
       "16    Sparse           SVD                N/A        True  0.216410  0.169533   \n",
       "17    Sparse           SVD                N/A       False  0.220187  0.172711   \n",
       "18    Sparse  CoClustering                N/A        True  0.519440  0.448089   \n",
       "19    Sparse  CoClustering                N/A       False  0.521285  0.449601   \n",
       "20  New User      KNNBasic            pearson        True  0.216375  0.167251   \n",
       "21  New User      KNNBasic            pearson       False  0.214508  0.166308   \n",
       "22  New User      KNNBasic   pearson_baseline        True  0.216124  0.166519   \n",
       "23  New User      KNNBasic   pearson_baseline       False  0.203326  0.153958   \n",
       "24  New User      KNNBasic                msd        True  0.212011  0.163236   \n",
       "25  New User      KNNBasic                msd       False  0.201419  0.154856   \n",
       "26  New User           SVD                N/A        True  0.198844  0.153150   \n",
       "27  New User           SVD                N/A       False  0.199565  0.153569   \n",
       "28  New User  CoClustering                N/A        True  0.564291  0.516131   \n",
       "29  New User  CoClustering                N/A       False  0.561599  0.515394   \n",
       "\n",
       "    Precision@10  Recall@10  Running Time (s)  \n",
       "0       0.681419   0.482391          1.577275  \n",
       "1       0.517631   0.389731         14.983212  \n",
       "2       0.676271   0.487729          1.601246  \n",
       "3       0.609774   0.461591         12.312512  \n",
       "4       0.672722   0.488166          1.281166  \n",
       "5       0.522313   0.417250         10.443120  \n",
       "6       0.636856   0.450793          1.219783  \n",
       "7       0.636138   0.449077          1.084938  \n",
       "8       0.111245   0.032385          2.333833  \n",
       "9       0.144278   0.042020          2.316910  \n",
       "10      0.119334   0.057817          0.037749  \n",
       "11      0.082593   0.038550          0.524907  \n",
       "12      0.144836   0.076237          0.047723  \n",
       "13      0.121704   0.059102          0.238681  \n",
       "14      0.333362   0.252445          0.024163  \n",
       "15      0.321258   0.253624          0.161412  \n",
       "16      0.448187   0.406446          0.127224  \n",
       "17      0.438220   0.394566          0.113744  \n",
       "18      0.118889   0.062898          0.422259  \n",
       "19      0.112222   0.059269          0.418421  \n",
       "20      0.684808   0.465282          1.402579  \n",
       "21      0.534035   0.396585         14.104410  \n",
       "22      0.692850   0.480907          1.580747  \n",
       "23      0.627913   0.475188         12.432336  \n",
       "24      0.689563   0.481867          1.274559  \n",
       "25      0.516358   0.406667         10.612801  \n",
       "26      0.635569   0.438056          1.214717  \n",
       "27      0.633467   0.437789          1.104816  \n",
       "28      0.158539   0.041992          2.394291  \n",
       "29      0.119774   0.033225          2.355567  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_CF= pd.DataFrame(results_normal + results_sparse + results_new_user)\n",
    "results_CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c16696e-7b49-4294-bd9b-c9af3f8c25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate normal scenario\n",
    "results_normal = evaluate_all_scenarios(train_set, test_set, \"Normal\")\n",
    "\n",
    "# Evaluate sparse data scenario\n",
    "results_sparse = evaluate_all_scenarios(sparse_train_set, test_set, \"Sparse\")\n",
    "\n",
    "# Evaluate new user data scenario\n",
    "results_new_user = evaluate_all_scenarios(new_user_train_set, test_set, \"New User\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee916ab8-7eb9-467f-b827-34db3b283d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Similarity Measure</th>\n",
       "      <th>User-Based</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047447</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.168082</td>\n",
       "      <td>0.689299</td>\n",
       "      <td>0.492621</td>\n",
       "      <td>1.529102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.217295</td>\n",
       "      <td>0.168717</td>\n",
       "      <td>0.517611</td>\n",
       "      <td>0.398195</td>\n",
       "      <td>18.764348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047433</td>\n",
       "      <td>0.217790</td>\n",
       "      <td>0.167656</td>\n",
       "      <td>0.688259</td>\n",
       "      <td>0.496251</td>\n",
       "      <td>1.583247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041960</td>\n",
       "      <td>0.204842</td>\n",
       "      <td>0.155043</td>\n",
       "      <td>0.625488</td>\n",
       "      <td>0.474030</td>\n",
       "      <td>11.467633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.046086</td>\n",
       "      <td>0.214677</td>\n",
       "      <td>0.164979</td>\n",
       "      <td>0.679926</td>\n",
       "      <td>0.499211</td>\n",
       "      <td>1.255274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041458</td>\n",
       "      <td>0.203612</td>\n",
       "      <td>0.156361</td>\n",
       "      <td>0.531894</td>\n",
       "      <td>0.413416</td>\n",
       "      <td>9.768819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Normal</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.041005</td>\n",
       "      <td>0.202497</td>\n",
       "      <td>0.155352</td>\n",
       "      <td>0.647672</td>\n",
       "      <td>0.459548</td>\n",
       "      <td>1.190404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Normal</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041094</td>\n",
       "      <td>0.202715</td>\n",
       "      <td>0.155254</td>\n",
       "      <td>0.626419</td>\n",
       "      <td>0.453290</td>\n",
       "      <td>1.149808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Normal</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.313754</td>\n",
       "      <td>0.560137</td>\n",
       "      <td>0.511696</td>\n",
       "      <td>0.175363</td>\n",
       "      <td>0.044782</td>\n",
       "      <td>2.664798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Normal</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.310585</td>\n",
       "      <td>0.557301</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>0.131653</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>2.510326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.057388</td>\n",
       "      <td>0.239559</td>\n",
       "      <td>0.188667</td>\n",
       "      <td>0.204090</td>\n",
       "      <td>0.035612</td>\n",
       "      <td>0.158362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.235625</td>\n",
       "      <td>0.185655</td>\n",
       "      <td>0.270563</td>\n",
       "      <td>0.037605</td>\n",
       "      <td>1.022089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.058104</td>\n",
       "      <td>0.241047</td>\n",
       "      <td>0.189540</td>\n",
       "      <td>0.233902</td>\n",
       "      <td>0.043686</td>\n",
       "      <td>0.326732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.056063</td>\n",
       "      <td>0.236777</td>\n",
       "      <td>0.186087</td>\n",
       "      <td>0.313862</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.735174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.062009</td>\n",
       "      <td>0.249017</td>\n",
       "      <td>0.192169</td>\n",
       "      <td>0.525922</td>\n",
       "      <td>0.229263</td>\n",
       "      <td>0.160648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.058758</td>\n",
       "      <td>0.242401</td>\n",
       "      <td>0.185709</td>\n",
       "      <td>0.476615</td>\n",
       "      <td>0.237743</td>\n",
       "      <td>0.681256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049906</td>\n",
       "      <td>0.223397</td>\n",
       "      <td>0.174412</td>\n",
       "      <td>0.600174</td>\n",
       "      <td>0.391305</td>\n",
       "      <td>0.339218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050358</td>\n",
       "      <td>0.224406</td>\n",
       "      <td>0.174711</td>\n",
       "      <td>0.586879</td>\n",
       "      <td>0.391806</td>\n",
       "      <td>0.212321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.271167</td>\n",
       "      <td>0.520737</td>\n",
       "      <td>0.446987</td>\n",
       "      <td>0.271353</td>\n",
       "      <td>0.089614</td>\n",
       "      <td>0.485683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.270505</td>\n",
       "      <td>0.520101</td>\n",
       "      <td>0.446704</td>\n",
       "      <td>0.277588</td>\n",
       "      <td>0.087657</td>\n",
       "      <td>0.488495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047445</td>\n",
       "      <td>0.217819</td>\n",
       "      <td>0.168148</td>\n",
       "      <td>0.668612</td>\n",
       "      <td>0.475516</td>\n",
       "      <td>1.398924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.047287</td>\n",
       "      <td>0.217455</td>\n",
       "      <td>0.168899</td>\n",
       "      <td>0.502132</td>\n",
       "      <td>0.384828</td>\n",
       "      <td>15.231194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047443</td>\n",
       "      <td>0.217814</td>\n",
       "      <td>0.167772</td>\n",
       "      <td>0.669194</td>\n",
       "      <td>0.477266</td>\n",
       "      <td>1.710859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.042074</td>\n",
       "      <td>0.205120</td>\n",
       "      <td>0.155333</td>\n",
       "      <td>0.607008</td>\n",
       "      <td>0.458193</td>\n",
       "      <td>11.767120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>0.214860</td>\n",
       "      <td>0.165201</td>\n",
       "      <td>0.659569</td>\n",
       "      <td>0.479126</td>\n",
       "      <td>1.237151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041535</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.156525</td>\n",
       "      <td>0.521969</td>\n",
       "      <td>0.401117</td>\n",
       "      <td>9.800809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New User</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.041180</td>\n",
       "      <td>0.202928</td>\n",
       "      <td>0.155836</td>\n",
       "      <td>0.634885</td>\n",
       "      <td>0.452067</td>\n",
       "      <td>1.166703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New User</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.040567</td>\n",
       "      <td>0.201412</td>\n",
       "      <td>0.154480</td>\n",
       "      <td>0.636736</td>\n",
       "      <td>0.462141</td>\n",
       "      <td>1.260938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New User</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.313919</td>\n",
       "      <td>0.560285</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.202851</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>2.521362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New User</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.312582</td>\n",
       "      <td>0.559090</td>\n",
       "      <td>0.509274</td>\n",
       "      <td>0.191030</td>\n",
       "      <td>0.049907</td>\n",
       "      <td>2.494795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Scenario     Algorithm Similarity Measure  User-Based       MSE      RMSE  \\\n",
       "0     Normal      KNNBasic            pearson        True  0.047447  0.217822   \n",
       "1     Normal      KNNBasic            pearson       False  0.047217  0.217295   \n",
       "2     Normal      KNNBasic   pearson_baseline        True  0.047433  0.217790   \n",
       "3     Normal      KNNBasic   pearson_baseline       False  0.041960  0.204842   \n",
       "4     Normal      KNNBasic                msd        True  0.046086  0.214677   \n",
       "5     Normal      KNNBasic                msd       False  0.041458  0.203612   \n",
       "6     Normal           SVD                N/A        True  0.041005  0.202497   \n",
       "7     Normal           SVD                N/A       False  0.041094  0.202715   \n",
       "8     Normal  CoClustering                N/A        True  0.313754  0.560137   \n",
       "9     Normal  CoClustering                N/A       False  0.310585  0.557301   \n",
       "10    Sparse      KNNBasic            pearson        True  0.057388  0.239559   \n",
       "11    Sparse      KNNBasic            pearson       False  0.055519  0.235625   \n",
       "12    Sparse      KNNBasic   pearson_baseline        True  0.058104  0.241047   \n",
       "13    Sparse      KNNBasic   pearson_baseline       False  0.056063  0.236777   \n",
       "14    Sparse      KNNBasic                msd        True  0.062009  0.249017   \n",
       "15    Sparse      KNNBasic                msd       False  0.058758  0.242401   \n",
       "16    Sparse           SVD                N/A        True  0.049906  0.223397   \n",
       "17    Sparse           SVD                N/A       False  0.050358  0.224406   \n",
       "18    Sparse  CoClustering                N/A        True  0.271167  0.520737   \n",
       "19    Sparse  CoClustering                N/A       False  0.270505  0.520101   \n",
       "20  New User      KNNBasic            pearson        True  0.047445  0.217819   \n",
       "21  New User      KNNBasic            pearson       False  0.047287  0.217455   \n",
       "22  New User      KNNBasic   pearson_baseline        True  0.047443  0.217814   \n",
       "23  New User      KNNBasic   pearson_baseline       False  0.042074  0.205120   \n",
       "24  New User      KNNBasic                msd        True  0.046165  0.214860   \n",
       "25  New User      KNNBasic                msd       False  0.041535  0.203800   \n",
       "26  New User           SVD                N/A        True  0.041180  0.202928   \n",
       "27  New User           SVD                N/A       False  0.040567  0.201412   \n",
       "28  New User  CoClustering                N/A        True  0.313919  0.560285   \n",
       "29  New User  CoClustering                N/A       False  0.312582  0.559090   \n",
       "\n",
       "         MAE  Precision@10  Recall@10  Running Time (s)  \n",
       "0   0.168082      0.689299   0.492621          1.529102  \n",
       "1   0.168717      0.517611   0.398195         18.764348  \n",
       "2   0.167656      0.688259   0.496251          1.583247  \n",
       "3   0.155043      0.625488   0.474030         11.467633  \n",
       "4   0.164979      0.679926   0.499211          1.255274  \n",
       "5   0.156361      0.531894   0.413416          9.768819  \n",
       "6   0.155352      0.647672   0.459548          1.190404  \n",
       "7   0.155254      0.626419   0.453290          1.149808  \n",
       "8   0.511696      0.175363   0.044782          2.664798  \n",
       "9   0.510051      0.131653   0.036242          2.510326  \n",
       "10  0.188667      0.204090   0.035612          0.158362  \n",
       "11  0.185655      0.270563   0.037605          1.022089  \n",
       "12  0.189540      0.233902   0.043686          0.326732  \n",
       "13  0.186087      0.313862   0.052083          0.735174  \n",
       "14  0.192169      0.525922   0.229263          0.160648  \n",
       "15  0.185709      0.476615   0.237743          0.681256  \n",
       "16  0.174412      0.600174   0.391305          0.339218  \n",
       "17  0.174711      0.586879   0.391806          0.212321  \n",
       "18  0.446987      0.271353   0.089614          0.485683  \n",
       "19  0.446704      0.277588   0.087657          0.488495  \n",
       "20  0.168148      0.668612   0.475516          1.398924  \n",
       "21  0.168899      0.502132   0.384828         15.231194  \n",
       "22  0.167772      0.669194   0.477266          1.710859  \n",
       "23  0.155333      0.607008   0.458193         11.767120  \n",
       "24  0.165201      0.659569   0.479126          1.237151  \n",
       "25  0.156525      0.521969   0.401117          9.800809  \n",
       "26  0.155836      0.634885   0.452067          1.166703  \n",
       "27  0.154480      0.636736   0.462141          1.260938  \n",
       "28  0.510417      0.202851   0.051051          2.521362  \n",
       "29  0.509274      0.191030   0.049907          2.494795  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_CF= pd.DataFrame(results_normal + results_sparse + results_new_user)\n",
    "results_CF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38520179-d4fa-4945-b64d-2625cdb5cc5c",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "User-based algorithms generally outperformed item-based algorithms across the different sce-\n",
    "narios tested. Specifically, KNNBasic with Pearson similarity in a user-based setting demon-\n",
    "strated competitive performance, particularly excelling in the normal and new user scenarios.\n",
    "It achieved notable metrics, including high Precision@10 and Recall@10, highlighting its ef-\n",
    "fectiveness in these contexts. SVD consistently delivered strong results across all scenarios,\n",
    "achieving the lowest RMSE and MAE values, coupled with high Precision@10 and Recall@10.\n",
    "This consistent performance, combined with relatively short running times, underscores SVDs\n",
    "robustness and reliability as a recommendation algorithm for the dataset we have worked on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcddd5-551b-4d64-a6cf-70163343775f",
   "metadata": {},
   "source": [
    "# Graph-based Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116c296-8d7b-4686-92b5-f027a19d01fe",
   "metadata": {},
   "source": [
    "### For the graph-based models, we have implemented 3 algorithms as well: LightGCN, Graph Attention Network, GraphSAGE\n",
    "Graph Construction: In the graph construction phase, nodes are created to represent both users\n",
    "and movies, while edges represent the interactions between these users and movies based on\n",
    "their ratings. To facilitate this, numpy is utilized for constructing the adjacency matrix, which\n",
    "captures the user-movie interaction graph in a structured form. This adjacency matrix serves\n",
    "as the foundation for various graph-based algorithms, allowing us to represent the relationships\n",
    "between users and movies effectively. Additionally, TensorFlow is employed to handle the graph\n",
    "representation and computation, leveraging its powerful capabilities for efficient processing and\n",
    "model training in subsequent stages. \n",
    "\n",
    "### In this first part of the code, we have implemented all the useful functions and code that all the 3 algorithms shared in commun to avoid code redundancy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32f6e04e-147e-4f54-aabe-f97d4192f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['user'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['item'] = item_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "num_users = ratings_df['user'].nunique()\n",
    "num_items = ratings_df['item'].nunique()\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_data, test_data, adj_matrix=None):\n",
    "    # Prepare the training data\n",
    "    user_indices = train_data['userId'].values\n",
    "    item_indices = train_data['movieId'].values\n",
    "    labels = train_data['rating'].values\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((user_indices, item_indices, labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(train_data)).batch(256)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()  \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(user_indices, item_indices, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            if adj_matrix is not None:\n",
    "                scores = model(user_indices, item_indices, adj_matrix)\n",
    "            else:\n",
    "                scores = model(user_indices, item_indices)\n",
    "            loss = loss_fn(labels, scores)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    num_epochs = 10\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataset:\n",
    "            user_indices_batch, item_indices_batch, labels_batch = batch\n",
    "            loss = train_step(user_indices_batch, item_indices_batch, labels_batch)\n",
    "        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluating the model\n",
    "    predictions = []\n",
    "\n",
    "    test_user_indices = test_data['user'].values\n",
    "    test_item_indices = test_data['item'].values\n",
    "    test_labels = test_data['rating'].values\n",
    "\n",
    "    for (user_index, item_index, label) in zip(test_user_indices, test_item_indices, test_labels):\n",
    "        user_index_tensor = tf.constant([user_index])\n",
    "        item_index_tensor = tf.constant([item_index])\n",
    "        if adj_matrix is not None:\n",
    "            score = model(user_index_tensor, item_index_tensor, adj_matrix).numpy()[0]\n",
    "        else:\n",
    "            score = model(user_index_tensor, item_index_tensor).numpy()[0]\n",
    "        predictions.append((user_index, item_index, label, score, 0))\n",
    "\n",
    "    return predictions, training_time\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    def get_top_n(predictions, n=10):\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "        return top_n\n",
    "\n",
    "    def precision_recall_at_k(predictions, k=10, threshold=0.7): \n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        return precisions, recalls\n",
    "\n",
    "    def compute_mse(predictions):\n",
    "        \"\"\"Compute Mean Squared Error (MSE).\"\"\"\n",
    "        mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "        return mse\n",
    "\n",
    "    \n",
    "    def compute_rmse(predictions):\n",
    "        \"\"\"Compute Root Mean Squared Error (RMSE).\"\"\"\n",
    "        mse = compute_mse(predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "\n",
    "    def compute_mae(predictions):\n",
    "        mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "        return mae\n",
    "\n",
    "    mse = compute_mse(predictions)\n",
    "    rmse = compute_rmse(predictions)\n",
    "    mae = compute_mae(predictions)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10)\n",
    "\n",
    "    precision_at_10 = np.mean(list(precisions.values()))\n",
    "    recall_at_10 = np.mean(list(recalls.values()))\n",
    "\n",
    "    return mse,rmse, mae, precision_at_10, recall_at_10\n",
    "\n",
    "# Function to run evaluation for each model and scenario\n",
    "def run_evaluation(model, model_name, train_data, test_data, adj_matrix=None):\n",
    "    predictions, training_time = evaluate_model(model, train_data, test_data, adj_matrix)\n",
    "    mse,rmse, mae, precision_at_10, recall_at_10 = compute_metrics(predictions)\n",
    "    results = pd.DataFrame({\n",
    "        \"Scenario\": [scenario],\n",
    "        \"Algorithm\": [model_name],\n",
    "        \"MSE\": [mse],\n",
    "        \"RMSE\": [rmse],\n",
    "        \"MAE\": [mae],\n",
    "        \"Precision@10\": [precision_at_10],\n",
    "        \"Recall@10\": [recall_at_10],\n",
    "        \"Running Time (s)\": [training_time]\n",
    "    })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d968f6c-ae5c-4988-80c2-2588ab4105b9",
   "metadata": {},
   "source": [
    "## LightGCN Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdbb08a5-654a-455a-a6bc-90feddde91de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 13.2447 - val_loss: 9.8584\n",
      "Epoch 2/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 6.6229 - val_loss: 2.7912\n",
      "Epoch 3/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.9666 - val_loss: 1.9016\n",
      "Epoch 4/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1.1804 - val_loss: 1.6163\n",
      "Epoch 5/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.8587 - val_loss: 1.4916\n",
      "Epoch 6/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.7028 - val_loss: 1.4394\n",
      "Epoch 7/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.6087 - val_loss: 1.4152\n",
      "Epoch 8/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.5412 - val_loss: 1.4058\n",
      "Epoch 9/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4819 - val_loss: 1.4033\n",
      "Epoch 10/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.4406 - val_loss: 1.4041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:11:52.903066: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.0922755002975464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:11:54.316141: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.524085521697998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:11:55.744518: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.42562562227249146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:11:57.153378: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.5250903964042664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:11:58.923925: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.8019978404045105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:12:00.585689: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.22949157655239105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:12:02.031194: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.45636817812919617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:12:03.457016: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.19849999248981476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:12:05.989493: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.4597753882408142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:12:07.394507: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.2639344036579132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:13:16.936800: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:13:17.099273: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.30010613799095154\n",
      "Epoch 1, Loss: 0.18591414391994476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:13:17.264555: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:13:17.411207: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.13295550644397736\n",
      "Epoch 3, Loss: 0.10314126312732697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:13:17.568115: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:13:17.720397: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.08264755457639694\n",
      "Epoch 5, Loss: 0.11699971556663513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:13:17.860603: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:13:18.005621: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.06872354447841644\n",
      "Epoch 7, Loss: 0.08671410381793976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:13:18.159858: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:13:18.306919: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.05715125799179077\n",
      "Epoch 9, Loss: 0.06465554982423782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:23:31.950517: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.957898: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.964924: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.971387: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.979132: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.986603: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:31.994938: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:32.002107: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:32.009092: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 15:23:32.016952: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.2316470891237259\n",
      "Epoch 1, Loss: 0.20376814901828766\n",
      "Epoch 2, Loss: 0.1803845763206482\n",
      "Epoch 3, Loss: 0.16075095534324646\n",
      "Epoch 4, Loss: 0.1441202163696289\n",
      "Epoch 5, Loss: 0.12986089289188385\n",
      "Epoch 6, Loss: 0.11745857447385788\n",
      "Epoch 7, Loss: 0.10649746656417847\n",
      "Epoch 8, Loss: 0.09666289389133453\n",
      "Epoch 9, Loss: 0.08773539960384369\n",
      "   Scenario Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
      "0    Normal  LightGCN  1.300472  1.140382  0.814420      0.749278   0.503184   \n",
      "1    Sparse  LightGCN  1.353399  1.163357  0.837602      0.750687   0.504528   \n",
      "2  New User  LightGCN  1.352309  1.162888  0.837188      0.751206   0.504964   \n",
      "\n",
      "   Running Time (s)  \n",
      "0         16.588426  \n",
      "1          2.137099  \n",
      "2          0.539947  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['user'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['item'] = item_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "num_users = ratings_df['user'].nunique()\n",
    "num_items = ratings_df['item'].nunique()\n",
    "\n",
    "def evaluate_model(model, train_data, test_data, adj_matrix=None):\n",
    "    # Prepare the training data\n",
    "    user_indices = train_data['user'].values\n",
    "    item_indices = train_data['item'].values\n",
    "    labels = train_data['rating'].values\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((user_indices, item_indices, labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(train_data)).batch(256)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()  \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(user_indices, item_indices, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            scores = model((user_indices, item_indices))\n",
    "            loss = loss_fn(labels, scores)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    num_epochs = 10\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataset:\n",
    "            user_indices_batch, item_indices_batch, labels_batch = batch\n",
    "            loss = train_step(user_indices_batch, item_indices_batch, labels_batch)\n",
    "        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluating the model\n",
    "    predictions = []\n",
    "\n",
    "    test_user_indices = test_data['user'].values\n",
    "    test_item_indices = test_data['item'].values\n",
    "    test_labels = test_data['rating'].values\n",
    "\n",
    "    for (user_index, item_index, label) in zip(test_user_indices, test_item_indices, test_labels):\n",
    "        user_index_tensor = tf.constant([user_index])\n",
    "        item_index_tensor = tf.constant([item_index])\n",
    "        score = model((user_index_tensor, item_index_tensor)).numpy()[0]\n",
    "        predictions.append((user_index, item_index, label, score, 0))\n",
    "\n",
    "    return predictions, training_time\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    def get_top_n(predictions, n=10):\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "        return top_n\n",
    "\n",
    "    def precision_recall_at_k(predictions, k=10, threshold=3.5): \n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        return precisions, recalls\n",
    "\n",
    "    def compute_mse(predictions):\n",
    "        \"\"\"Compute Mean Squared Error (MSE).\"\"\"\n",
    "        mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "        return mse\n",
    "\n",
    "    def compute_rmse(predictions):\n",
    "        \"\"\"Compute Root Mean Squared Error (RMSE).\"\"\"\n",
    "        mse = compute_mse(predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "\n",
    "    def compute_mae(predictions):\n",
    "        mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "        return mae\n",
    "\n",
    "    mse = compute_mse(predictions)\n",
    "    rmse = compute_rmse(predictions)\n",
    "    mae = compute_mae(predictions)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10)\n",
    "\n",
    "    precision_at_10 = np.mean(list(precisions.values()))\n",
    "    recall_at_10 = np.mean(list(recalls.values()))\n",
    "\n",
    "    return mse, rmse, mae, precision_at_10, recall_at_10\n",
    "\n",
    "# Function to run evaluation for each model and scenario\n",
    "def run_evaluation(model, model_name, train_data, test_data, adj_matrix=None):\n",
    "    predictions, training_time = evaluate_model(model, train_data, test_data, adj_matrix)\n",
    "    mse, rmse, mae, precision_at_10, recall_at_10 = compute_metrics(predictions)\n",
    "    results = pd.DataFrame({\n",
    "        \"Scenario\": [scenario],\n",
    "        \"Algorithm\": [model_name],\n",
    "        \"MSE\": [mse],\n",
    "        \"RMSE\": [rmse],\n",
    "        \"MAE\": [mae],\n",
    "        \"Precision@10\": [precision_at_10],\n",
    "        \"Recall@10\": [recall_at_10],\n",
    "        \"Running Time (s)\": [training_time]\n",
    "    })\n",
    "    return results\n",
    "\n",
    "# Evaluate LightGCN\n",
    "class LightGCN(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, **kwargs):\n",
    "        super(LightGCN, self).__init__(**kwargs)\n",
    "        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_indices, item_indices = inputs\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        scores = tf.reduce_sum(user_embeddings * item_embeddings, axis=1)\n",
    "        return scores\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(LightGCN, self).get_config()\n",
    "        config.update({\n",
    "            'num_users': self.num_users,\n",
    "            'num_items': self.num_items,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "embedding_dim = 64\n",
    "lightgcn_model = LightGCN(num_users, num_items, embedding_dim)\n",
    "\n",
    "# Step 1: Split the data into training and test sets (80% training, 20% testing)\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=0.20, random_state=42)\n",
    "\n",
    "# Callbacks for early stopping and model checkpointing\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "# Compile the model\n",
    "lightgcn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model with early stopping and model checkpointing\n",
    "history = lightgcn_model.fit(\n",
    "    x=(train_df['user'].values, train_df['item'].values),\n",
    "    y=train_df['rating'].values,\n",
    "    epochs=10,  \n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "best_model = tf.keras.models.load_model('best_model.keras', custom_objects={'LightGCN': LightGCN})\n",
    "\n",
    "def get_sparse_data(ratings, frac=0.1):\n",
    "    # Placeholder function to get sparse data. Replace with actual logic.\n",
    "    return ratings.sample(frac=frac, random_state=42)\n",
    "\n",
    "def get_new_user_data(ratings, frac=0.1):\n",
    "    # Placeholder function to get new user data. Replace with actual logic.\n",
    "    new_user_indices = ratings['user'].drop_duplicates().sample(frac=frac, random_state=42).index\n",
    "    return ratings[ratings['user'].isin(new_user_indices)]\n",
    "\n",
    "# Evaluate normal scenario\n",
    "scenario = \"Normal\"\n",
    "results_lightGCN_normal = run_evaluation(best_model, \"LightGCN\", train_df, test_df)\n",
    "\n",
    "# Evaluate sparse scenario\n",
    "scenario = \"Sparse\"\n",
    "sparse_train_df = get_sparse_data(train_df, frac=0.1)\n",
    "results_lightGCN_sparse = run_evaluation(best_model, \"LightGCN\", sparse_train_df, test_df)\n",
    "\n",
    "# Evaluate new user scenario\n",
    "scenario = \"New User\"\n",
    "new_user_train_df = get_new_user_data(train_df, frac=0.1)\n",
    "results_lightGCN_new_user = run_evaluation(best_model, \"LightGCN\", new_user_train_df, test_df)\n",
    "\n",
    "# Combine LightGCN results into a single DataFrame\n",
    "results_lightGCN_combined = pd.concat([results_lightGCN_normal, results_lightGCN_sparse, results_lightGCN_new_user], ignore_index=True)\n",
    "\n",
    "# Display the combined results\n",
    "print(results_lightGCN_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "213f2a71-95e9-4551-bdda-9708052622dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>1.300472</td>\n",
       "      <td>1.140382</td>\n",
       "      <td>0.814420</td>\n",
       "      <td>0.749278</td>\n",
       "      <td>0.503184</td>\n",
       "      <td>16.588426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>1.353399</td>\n",
       "      <td>1.163357</td>\n",
       "      <td>0.837602</td>\n",
       "      <td>0.750687</td>\n",
       "      <td>0.504528</td>\n",
       "      <td>2.137099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>1.352309</td>\n",
       "      <td>1.162888</td>\n",
       "      <td>0.837188</td>\n",
       "      <td>0.751206</td>\n",
       "      <td>0.504964</td>\n",
       "      <td>0.539947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal  LightGCN  1.300472  1.140382  0.814420      0.749278   0.503184   \n",
       "1    Sparse  LightGCN  1.353399  1.163357  0.837602      0.750687   0.504528   \n",
       "2  New User  LightGCN  1.352309  1.162888  0.837188      0.751206   0.504964   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         16.588426  \n",
       "1          2.137099  \n",
       "2          0.539947  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine LightGCN results into a single DataFrame\n",
    "results_lightGCN_combined = pd.concat([results_lightGCN_normal, results_lightGCN_sparse, results_lightGCN_new_user], ignore_index=True)\n",
    "results_lightGCN_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc96032-1d22-4171-9770-97ba4d3541e4",
   "metadata": {},
   "source": [
    "# Graph Attention Network (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91902bd9-d579-40fc-a596-937263cfec17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 4.4186 - val_loss: 1.1508\n",
      "Epoch 2/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 1.1240 - val_loss: 1.1469\n",
      "Epoch 3/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 1.1112 - val_loss: 1.0692\n",
      "Epoch 4/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 1.0319 - val_loss: 1.0472\n",
      "Epoch 5/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.9298 - val_loss: 0.9864\n",
      "Epoch 6/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.9177 - val_loss: 1.0135\n",
      "Epoch 7/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.8428 - val_loss: 0.9277\n",
      "Epoch 8/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.8204 - val_loss: 0.9054\n",
      "Epoch 9/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.7728 - val_loss: 0.8885\n",
      "Epoch 10/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.7501 - val_loss: 0.8999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:730: UserWarning: Model 'gat_model_3' had a build config, but the model cannot be built automatically in `build_from_config(config)`. You should implement `def build_from_config(self, config)`, and you might also want to implement the method  that generates the config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the model (i.e. its variables) upon deserialization.\n",
      "  instance.build_from_config(build_config)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 6 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "2024-08-09 13:33:08.085953: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8535671234130859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:15.026881: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.791020929813385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:22.008986: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6955035328865051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:28.899304: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.5415529608726501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:35.857575: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.5138713717460632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:42.872480: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.6965969204902649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:33:53.050636: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.4879266917705536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:34:00.334246: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.5766206979751587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:34:08.420728: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.7400653958320618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:34:15.490516: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 1.819345235824585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:36.839548: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.681725263595581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:37.591673: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5210167169570923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:38.307332: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6364299654960632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:38.997344: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.5478856563568115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:39.727801: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.5958749055862427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:40.445690: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.5913105607032776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:41.186559: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.4851212501525879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:41.917518: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.645758330821991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:42.648162: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.5348884463310242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:38:43.371272: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.5008713603019714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 13:42:57.508671: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.524851: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.536148: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.547046: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.558032: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.569295: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.580212: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.591738: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.602860: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-09 13:42:57.613922: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5133550763130188\n",
      "Epoch 1, Loss: 0.4729280471801758\n",
      "Epoch 2, Loss: 0.5329741835594177\n",
      "Epoch 3, Loss: 0.32601064443588257\n",
      "Epoch 4, Loss: 0.2739917039871216\n",
      "Epoch 5, Loss: 0.3939181864261627\n",
      "Epoch 6, Loss: 0.3761257827281952\n",
      "Epoch 7, Loss: 0.27111342549324036\n",
      "Epoch 8, Loss: 0.24785055220127106\n",
      "Epoch 9, Loss: 0.29781031608581543\n",
      "   Scenario Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
      "0    Normal       GAT  5.279527  2.297722  1.813445      0.640868   0.339237   \n",
      "1    Sparse       GAT  9.903407  3.146968  2.508598      0.665226   0.375002   \n",
      "2  New User       GAT  8.366129  2.892426  2.294709      0.656693   0.358051   \n",
      "\n",
      "   Running Time (s)  \n",
      "0         76.762282  \n",
      "1          9.373171  \n",
      "2          2.174327  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['user'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['item'] = item_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "num_users = ratings_df['user'].nunique()\n",
    "num_items = ratings_df['item'].nunique()\n",
    "\n",
    "def evaluate_model(model, train_data, test_data):\n",
    "    # Prepare the training data\n",
    "    user_indices = train_data['user'].values\n",
    "    item_indices = train_data['item'].values\n",
    "    labels = train_data['rating'].values\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((user_indices, item_indices, labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(train_data)).batch(256)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()  \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(user_indices, item_indices, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            scores = model((user_indices, item_indices))\n",
    "            loss = loss_fn(labels, scores)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    num_epochs = 10\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataset:\n",
    "            user_indices_batch, item_indices_batch, labels_batch = batch\n",
    "            loss = train_step(user_indices_batch, item_indices_batch, labels_batch)\n",
    "        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluating the model\n",
    "    predictions = []\n",
    "\n",
    "    test_user_indices = test_data['user'].values\n",
    "    test_item_indices = test_data['item'].values\n",
    "    test_labels = test_data['rating'].values\n",
    "\n",
    "    for (user_index, item_index, label) in zip(test_user_indices, test_item_indices, test_labels):\n",
    "        user_index_tensor = tf.constant([user_index])\n",
    "        item_index_tensor = tf.constant([item_index])\n",
    "        score = model((user_index_tensor, item_index_tensor)).numpy()[0]\n",
    "        predictions.append((user_index, item_index, label, score, 0))\n",
    "\n",
    "    return predictions, training_time\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    def get_top_n(predictions, n=10):\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "        return top_n\n",
    "\n",
    "    def precision_recall_at_k(predictions, k=10, threshold=3.5): \n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        return precisions, recalls\n",
    "\n",
    "    def compute_mse(predictions):\n",
    "        \"\"\"Compute Mean Squared Error (MSE).\"\"\"\n",
    "        mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "        return mse\n",
    "\n",
    "    def compute_rmse(predictions):\n",
    "        \"\"\"Compute Root Mean Squared Error (RMSE).\"\"\"\n",
    "        mse = compute_mse(predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "\n",
    "    def compute_mae(predictions):\n",
    "        mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "        return mae\n",
    "\n",
    "    mse = compute_mse(predictions)\n",
    "    rmse = compute_rmse(predictions)\n",
    "    mae = compute_mae(predictions)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10)\n",
    "\n",
    "    precision_at_10 = np.mean(list(precisions.values()))\n",
    "    recall_at_10 = np.mean(list(recalls.values()))\n",
    "\n",
    "    return mse, rmse, mae, precision_at_10, recall_at_10\n",
    "\n",
    "# Function to run evaluation for each model and scenario\n",
    "def run_evaluation(model, model_name, train_data, test_data):\n",
    "    predictions, training_time = evaluate_model(model, train_data, test_data)\n",
    "    mse, rmse, mae, precision_at_10, recall_at_10 = compute_metrics(predictions)\n",
    "    results = pd.DataFrame({\n",
    "        \"Scenario\": [scenario],\n",
    "        \"Algorithm\": [model_name],\n",
    "        \"MSE\": [mse],\n",
    "        \"RMSE\": [rmse],\n",
    "        \"MAE\": [mae],\n",
    "        \"Precision@10\": [precision_at_10],\n",
    "        \"Recall@10\": [recall_at_10],\n",
    "        \"Running Time (s)\": [training_time]\n",
    "    })\n",
    "    return results\n",
    "\n",
    "# Evaluate GAT\n",
    "class GraphAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, attn_heads=1, dropout_rate=0.0, **kwargs):\n",
    "        super(GraphAttentionLayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.attn_heads = attn_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.attn_kernels = []\n",
    "        self.attn_self_kernels = []\n",
    "\n",
    "        for _ in range(attn_heads):\n",
    "            self.attn_kernels.append(tf.keras.layers.Dense(output_dim, use_bias=False))\n",
    "            self.attn_self_kernels.append(tf.keras.layers.Dense(1, use_bias=False))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features, adj_matrix = inputs\n",
    "        attn_outs = []\n",
    "\n",
    "        for kernel, self_kernel in zip(self.attn_kernels, self.attn_self_kernels):\n",
    "            attn_out = kernel(features)\n",
    "            attn_self = self_kernel(features)\n",
    "            attn_all = tf.add(attn_self, tf.transpose(attn_self))\n",
    "            attn_all = tf.nn.leaky_relu(attn_all)\n",
    "            attn_all = tf.nn.softmax(attn_all, axis=-1)\n",
    "            attn_all = self.dropout(attn_all)\n",
    "            node_features = tf.matmul(attn_all, attn_out)\n",
    "            attn_outs.append(node_features)\n",
    "\n",
    "        return tf.concat(attn_outs, axis=-1)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GraphAttentionLayer, self).get_config()\n",
    "        config.update({\n",
    "            'output_dim': self.output_dim,\n",
    "            'attn_heads': self.attn_heads,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "class GATModel(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, attn_heads=1, dropout_rate=0.0, **kwargs):\n",
    "        super(GATModel, self).__init__(**kwargs)\n",
    "        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
    "        self.gat_layer = GraphAttentionLayer(embedding_dim, attn_heads, dropout_rate)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.attn_heads = attn_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.adj_matrix = None\n",
    "\n",
    "    def set_adj_matrix(self, adj_matrix):\n",
    "        self.adj_matrix = adj_matrix\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_indices, item_indices = inputs\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        all_embeddings = tf.concat([user_embeddings, item_embeddings], axis=0)\n",
    "        all_embeddings = self.gat_layer([all_embeddings, self.adj_matrix])\n",
    "        user_embeddings = all_embeddings[:tf.shape(user_indices)[0]]\n",
    "        item_embeddings = all_embeddings[tf.shape(user_indices)[0]:]\n",
    "        scores = tf.reduce_sum(user_embeddings * item_embeddings, axis=1)\n",
    "        return scores\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GATModel, self).get_config()\n",
    "        config.update({\n",
    "            'num_users': self.num_users,\n",
    "            'num_items': self.num_items,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "            'attn_heads': self.attn_heads,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "adj_matrix = np.zeros((num_users + num_items, num_users + num_items))\n",
    "for _, row in ratings_df.iterrows():\n",
    "    user_id = int(row['user'])\n",
    "    item_id = int(row['item']) + num_users\n",
    "    adj_matrix[user_id, item_id] = 1\n",
    "    adj_matrix[item_id, user_id] = 1\n",
    "\n",
    "adj_matrix = tf.convert_to_tensor(adj_matrix, dtype=tf.float32)\n",
    "\n",
    "embedding_dim = 64\n",
    "attn_heads = 4\n",
    "dropout_rate = 0.5\n",
    "gat_model = GATModel(num_users, num_items, embedding_dim, attn_heads, dropout_rate)\n",
    "gat_model.set_adj_matrix(adj_matrix)\n",
    "\n",
    "# Callbacks for early stopping and model checkpointing\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_gat_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "# Compile the model\n",
    "gat_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model with early stopping and model checkpointing\n",
    "history = gat_model.fit(\n",
    "    x=[train_df['user'].values, train_df['item'].values],\n",
    "    y=train_df['rating'].values,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "best_gat_model = tf.keras.models.load_model('best_gat_model.keras', custom_objects={'GATModel': GATModel, 'GraphAttentionLayer': GraphAttentionLayer})\n",
    "best_gat_model.set_adj_matrix(adj_matrix)\n",
    "\n",
    "\n",
    "# Evaluate normal scenario\n",
    "scenario = \"Normal\"\n",
    "results_GAT_normal = run_evaluation(best_gat_model, \"GAT\", train_df, test_df)\n",
    "\n",
    "# Evaluate sparse scenario\n",
    "scenario = \"Sparse\"\n",
    "sparse_train_df = get_sparse_data(train_df, frac=0.1)\n",
    "results_GAT_sparse = run_evaluation(best_gat_model, \"GAT\", sparse_train_df, test_df)\n",
    "\n",
    "# Evaluate new user scenario\n",
    "scenario = \"New User\"\n",
    "new_user_train_df = get_new_user_data(train_df, frac=0.1)\n",
    "results_GAT_new_user = run_evaluation(best_gat_model, \"GAT\", new_user_train_df, test_df)\n",
    "\n",
    "# Combine GAT results into a single DataFrame\n",
    "results_GAT_combined = pd.concat([results_GAT_normal, results_GAT_sparse, results_GAT_new_user], ignore_index=True)\n",
    "\n",
    "# Display the combined results\n",
    "print(results_GAT_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb63d5-b62b-4fbf-b57c-51a02556efbf",
   "metadata": {},
   "source": [
    "# GraphSAGE (SAmple and aggreGatE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb21c9c-5543-49af-a8a1-ffd870a89014",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - loss: 3.2163 - val_loss: 1.5399\n",
      "Epoch 2/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 25ms/step - loss: 1.1261 - val_loss: 1.1178\n",
      "Epoch 3/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - loss: 0.8146 - val_loss: 1.0694\n",
      "Epoch 4/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 0.7007 - val_loss: 1.0774\n",
      "Epoch 5/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - loss: 0.6651 - val_loss: 1.1709\n",
      "Epoch 6/10\n",
      "\u001b[1m505/505\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 27ms/step - loss: 0.6228 - val_loss: 1.1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:730: UserWarning: Model 'graph_sage_model_2' had a build config, but the model cannot be built automatically in `build_from_config(config)`. You should implement `def build_from_config(self, config)`, and you might also want to implement the method  that generates the config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the model (i.e. its variables) upon deserialization.\n",
      "  instance.build_from_config(build_config)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 6 variables whereas the saved optimizer has 10 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n",
      "2024-08-08 20:33:48.929446: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8244467973709106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:33:55.527243: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.8825513124465942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:02.429511: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6544685363769531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:09.064167: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.7395923733711243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:15.658951: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.7510672211647034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:22.298359: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.5206165909767151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:29.336899: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.41095617413520813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:37.019341: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 1.2692623138427734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:44.164126: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.6173475980758667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:34:51.570223: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.24220798909664154\n",
      "  Scenario  Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
      "0   Normal  GraphSAGE  0.995274  0.997634  0.765923      0.737043   0.525224   \n",
      "\n",
      "   Running Time (s)  \n",
      "0         71.149196  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "ratings_df['user'] = user_encoder.fit_transform(ratings_df['userId'])\n",
    "ratings_df['item'] = item_encoder.fit_transform(ratings_df['movieId'])\n",
    "\n",
    "num_users = ratings_df['user'].nunique()\n",
    "num_items = ratings_df['item'].nunique()\n",
    "\n",
    "# Adjacency Matrix Construction\n",
    "adj_matrix = lil_matrix((num_users + num_items, num_users + num_items))\n",
    "for _, row in ratings_df.iterrows():\n",
    "    user_id = int(row['user'])\n",
    "    item_id = int(row['item']) + num_users\n",
    "    adj_matrix[user_id, item_id] = 1\n",
    "    adj_matrix[item_id, user_id] = 1\n",
    "\n",
    "adj_matrix = csr_matrix(adj_matrix)\n",
    "\n",
    "# Convert to TensorFlow SparseTensor\n",
    "adj_matrix_indices = np.vstack((adj_matrix.nonzero()[0], adj_matrix.nonzero()[1])).T\n",
    "adj_matrix_values = adj_matrix.data\n",
    "adj_matrix_shape = adj_matrix.shape\n",
    "\n",
    "adj_matrix = tf.sparse.SparseTensor(\n",
    "    indices=adj_matrix_indices,\n",
    "    values=adj_matrix_values,\n",
    "    dense_shape=adj_matrix_shape\n",
    ")\n",
    "\n",
    "# Ensure the sparse tensor is properly ordered\n",
    "adj_matrix = tf.sparse.reorder(adj_matrix)\n",
    "\n",
    "class GraphSAGELayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, aggregator_type='mean', dropout_rate=0.0, **kwargs):\n",
    "        super(GraphSAGELayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.aggregator_type = aggregator_type\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dense_self = tf.keras.layers.Dense(output_dim, use_bias=False)\n",
    "        self.dense_neighbor = tf.keras.layers.Dense(output_dim, use_bias=False)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.act = tf.nn.relu\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features, adj_matrix = inputs\n",
    "        neighbor_features = tf.sparse.sparse_dense_matmul(adj_matrix, features)\n",
    "        node_features = self.dense_self(features) + self.dense_neighbor(neighbor_features)\n",
    "        node_features = self.act(node_features)\n",
    "        node_features = self.dropout(node_features)\n",
    "        return node_features\n",
    "\n",
    "class GraphSAGEModel(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, aggregator_type='mean', dropout_rate=0.0, **kwargs):\n",
    "        super(GraphSAGEModel, self).__init__(**kwargs)\n",
    "        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
    "        self.graphsage_layer = GraphSAGELayer(embedding_dim, aggregator_type, dropout_rate)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.aggregator_type = aggregator_type\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.adj_matrix = None\n",
    "\n",
    "    def set_adj_matrix(self, adj_matrix):\n",
    "        self.adj_matrix = adj_matrix\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_indices, item_indices = inputs\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        all_user_embeddings = self.user_embedding(tf.range(self.num_users))\n",
    "        all_item_embeddings = self.item_embedding(tf.range(self.num_items))\n",
    "        all_embeddings = tf.concat([all_user_embeddings, all_item_embeddings], axis=0)\n",
    "        all_embeddings = self.graphsage_layer([all_embeddings, self.adj_matrix])\n",
    "        user_embeddings = tf.gather(all_embeddings, user_indices)\n",
    "        item_embeddings = tf.gather(all_embeddings, item_indices + self.num_users)\n",
    "        scores = tf.reduce_sum(user_embeddings * item_embeddings, axis=1)\n",
    "        return scores\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GraphSAGEModel, self).get_config()\n",
    "        config.update({\n",
    "            'num_users': self.num_users,\n",
    "            'num_items': self.num_items,\n",
    "            'embedding_dim': self.embedding_dim,\n",
    "            'aggregator_type': self.aggregator_type,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "# Set the adjacency matrix\n",
    "embedding_dim = 64\n",
    "aggregator_type = 'mean'\n",
    "dropout_rate = 0.5\n",
    "graphsage_model = GraphSAGEModel(num_users, num_items, embedding_dim, aggregator_type, dropout_rate)\n",
    "graphsage_model.set_adj_matrix(adj_matrix)\n",
    "\n",
    "# Callbacks for early stopping and model checkpointing\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_graphsage_model.keras', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "# Compile the model\n",
    "graphsage_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Prepare training and testing data (assuming train_df and test_df are predefined)\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model with early stopping and model checkpointing\n",
    "history = graphsage_model.fit(\n",
    "    x=[train_df['user'].values, train_df['item'].values],\n",
    "    y=train_df['rating'].values,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, checkpoint]\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "best_graphsage_model = tf.keras.models.load_model('best_graphsage_model.keras', custom_objects={'GraphSAGEModel': GraphSAGEModel, 'GraphSAGELayer': GraphSAGELayer})\n",
    "best_graphsage_model.set_adj_matrix(adj_matrix)\n",
    "\n",
    "# Evaluate normal scenario\n",
    "scenario = \"Normal\"\n",
    "results_SAGE_normal = run_evaluation(best_graphsage_model, \"GraphSAGE\", train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa051b3-0d87-4a79-bada-6085d57e1435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:40.752479: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5703974366188049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:41.434409: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.509819746017456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:42.130202: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.26427775621414185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:42.809304: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.296459823846817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:43.490807: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.3283613324165344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:44.196381: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.21200093626976013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:44.867099: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.25174692273139954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:45.545930: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.16219724714756012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:46.217347: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.21970874071121216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:41:46.920936: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.15669916570186615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:48:22.836179: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.862791: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.887528: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.914367: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.937209: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.959044: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:22.981578: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:23.005962: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-08-08 20:48:23.028798: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.44780388474464417\n",
      "Epoch 1, Loss: 3.4853625297546387\n",
      "Epoch 2, Loss: 0.2548128366470337\n",
      "Epoch 3, Loss: 0.9237936735153198\n",
      "Epoch 4, Loss: 1.4512138366699219\n",
      "Epoch 5, Loss: 1.2539323568344116\n",
      "Epoch 6, Loss: 0.6974046230316162\n",
      "Epoch 7, Loss: 0.308746874332428\n",
      "Epoch 8, Loss: 0.47734466195106506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:48:23.061360: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.7331115007400513\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NormalSparseNew User</td>\n",
       "      <td>GraphSAGEGraphSAGEGraphSAGE</td>\n",
       "      <td>4.539952</td>\n",
       "      <td>3.623258</td>\n",
       "      <td>2.8031</td>\n",
       "      <td>2.19935</td>\n",
       "      <td>1.495469</td>\n",
       "      <td>80.491525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Scenario                    Algorithm       MSE      RMSE  \\\n",
       "0  NormalSparseNew User  GraphSAGEGraphSAGEGraphSAGE  4.539952  3.623258   \n",
       "\n",
       "      MAE  Precision@10  Recall@10  Running Time (s)  \n",
       "0  2.8031       2.19935   1.495469         80.491525  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate sparse scenario\n",
    "scenario = \"Sparse\"\n",
    "sparse_train_df = get_sparse_data(train_df, frac=0.1)\n",
    "results_SAGE_sparse = run_evaluation(best_graphsage_model, \"GraphSAGE\", sparse_train_df, test_df)\n",
    "\n",
    "# Evaluate new user scenario\n",
    "scenario = \"New User\"\n",
    "new_user_train_df = get_new_user_data(train_df, frac=0.1)\n",
    "results_SAGE_new_user = run_evaluation(best_graphsage_model, \"GraphSAGE\", new_user_train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee3cb63e-c30d-4294-b14d-b9822188b7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>0.997634</td>\n",
       "      <td>0.765923</td>\n",
       "      <td>0.737043</td>\n",
       "      <td>0.525224</td>\n",
       "      <td>71.149196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>1.191938</td>\n",
       "      <td>1.091759</td>\n",
       "      <td>0.853637</td>\n",
       "      <td>0.729891</td>\n",
       "      <td>0.473050</td>\n",
       "      <td>8.101512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>2.352740</td>\n",
       "      <td>1.533864</td>\n",
       "      <td>1.183540</td>\n",
       "      <td>0.732416</td>\n",
       "      <td>0.497194</td>\n",
       "      <td>1.240817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario  Algorithm       MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal  GraphSAGE  0.995274  0.997634  0.765923      0.737043   0.525224   \n",
       "1    Sparse  GraphSAGE  1.191938  1.091759  0.853637      0.729891   0.473050   \n",
       "2  New User  GraphSAGE  2.352740  1.533864  1.183540      0.732416   0.497194   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         71.149196  \n",
       "1          8.101512  \n",
       "2          1.240817  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_SAGE_combined = pd.concat([results_SAGE_normal, results_SAGE_sparse, results_SAGE_new_user], ignore_index=True)\n",
    "results_SAGE_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdc7c59-ca00-4e09-ba88-9ba202175e27",
   "metadata": {},
   "source": [
    "# Hypergraph-based Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a58d20-1107-45b8-a49a-12fde2eaf858",
   "metadata": {},
   "source": [
    "### For the hypergraph-based models, we have implemented 2 algorithms: HyperGCN which an extension of Graph Convolution Network on Hypergraphs and Node2Vec algorithm. \n",
    "\n",
    "This part gather all the code thaat the 2 algoriithms have in commun notably the construction of the hypergraph with hyperedge users who has given the same rating on a movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f5edb79-d400-4367-a940-4b720625845a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypergraph created with 9593 nodes and 26961 edges.\n",
      "Number of nodes in hypergraph: 9593\n",
      "Sample nodes: ['user_509.0', 'movie_7347.0', 'user_380.0', 'user_274.0', 'user_474.0']\n",
      "Adjacency matrix created with shape (9593, 9593)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import hypernetx as hnx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=0.20, random_state=42)\n",
    "\n",
    "# Build the hypergraph\n",
    "edges = defaultdict(list)\n",
    "for _, row in train_df.iterrows():\n",
    "    user_node = f'user_{row[\"userId\"]}'\n",
    "    movie_node = f'movie_{row[\"movieId\"]}'\n",
    "    rating = row[\"rating\"]\n",
    "    hyperedge = f'{movie_node}_rating_{rating}'\n",
    "    edges[hyperedge].append(user_node)\n",
    "    edges[hyperedge].append(movie_node)\n",
    "\n",
    "H = hnx.Hypergraph(edges)\n",
    "print(f\"Hypergraph created with {len(H.nodes)} nodes and {len(H.edges)} edges.\")\n",
    "print(f\"Number of nodes in hypergraph: {len(H.nodes)}\")\n",
    "print(f\"Sample nodes: {list(H.nodes)[:5]}\")\n",
    "\n",
    "\n",
    "# Create adjacency matrix for hypergraph\n",
    "def create_hypergraph_adjacency_matrix(hypergraph):\n",
    "    node_list = list(hypergraph.nodes)\n",
    "    node_idx = {node: idx for idx, node in enumerate(node_list)}\n",
    "    n = len(node_list)\n",
    "    \n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "\n",
    "    for edge in hypergraph.edges:\n",
    "        edge_nodes = list(hypergraph.edges[edge])\n",
    "        for i in range(len(edge_nodes)):\n",
    "            for j in range(i + 1, len(edge_nodes)):\n",
    "                node_i = node_idx[edge_nodes[i]]\n",
    "                node_j = node_idx[edge_nodes[j]]\n",
    "                data.append(1)\n",
    "                row.append(node_i)\n",
    "                col.append(node_j)\n",
    "                data.append(1)\n",
    "                row.append(node_j)\n",
    "                col.append(node_i)\n",
    "\n",
    "    adj_matrix = csr_matrix((data, (row, col)), shape=(n, n))\n",
    "    print(f\"Adjacency matrix created with shape {adj_matrix.shape}\")\n",
    "    return adj_matrix, node_idx\n",
    "\n",
    "adj_matrix, node_to_idx = create_hypergraph_adjacency_matrix(H)\n",
    "adj_matrix_sparse = tf.sparse.SparseTensor(indices=np.array([adj_matrix.nonzero()[0], adj_matrix.nonzero()[1]]).T,\n",
    "                                           values=adj_matrix.data.astype(np.float32),\n",
    "                                           dense_shape=adj_matrix.shape)\n",
    "adj_matrix_sparse = tf.sparse.reorder(adj_matrix_sparse)\n",
    "\n",
    "\n",
    "# Evaluation metrics functions\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    return precisions, recalls\n",
    "\n",
    "def compute_rmse(predictions):\n",
    "    mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def compute_mae(predictions):\n",
    "    mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "    return mae\n",
    "\n",
    "# Functions to generate sparse and new user data\n",
    "def get_sparse_data(ratings, frac=0.1):\n",
    "    sparse_ratings_df = ratings.sample(frac=frac, random_state=42) \n",
    "    return sparse_ratings_df\n",
    "\n",
    "def get_new_user_data(ratings, frac=0.1):\n",
    "    new_user_ratings_df = ratings[ratings['userId'].isin(ratings['userId'].sample(frac=frac, random_state=42))]\n",
    "    return new_user_ratings_df\n",
    "\n",
    "def evaluate_model(test, embeddings, user_mapping, movie_mapping, scenario, algorithm):\n",
    "    def predict_rating(user, movie):\n",
    "        if user in user_mapping and movie in movie_mapping:\n",
    "            user_idx = user_mapping[user]\n",
    "            movie_idx = movie_mapping[movie]\n",
    "            if user_idx >= embeddings.shape[0] or movie_idx >= embeddings.shape[0]:\n",
    "                return 0\n",
    "            user_emb = embeddings[user_idx]\n",
    "            movie_emb = embeddings[movie_idx]\n",
    "            return np.dot(user_emb, movie_emb)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    predictions = []\n",
    "    for _, row in test.iterrows():\n",
    "        uid = row['userId']\n",
    "        mid = row['movieId']\n",
    "        true_r = row['rating']\n",
    "        est = predict_rating(uid, mid)\n",
    "        predictions.append((uid, mid, true_r, est, None))\n",
    "\n",
    "    mse = compute_mse(predictions)\n",
    "    rmse = compute_rmse(predictions)\n",
    "    mae = compute_mae(predictions)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10)\n",
    "\n",
    "    avg_precision = np.mean(list(precisions.values()))\n",
    "    avg_recall = np.mean(list(recalls.values()))\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Scenario': [scenario],\n",
    "        'Algorithm': [algorithm],\n",
    "        'MSE':[mse],\n",
    "        'RMSE': [rmse],\n",
    "        'MAE': [mae],\n",
    "        'Precision@10': [avg_precision],\n",
    "        'Recall@10': [avg_recall]\n",
    "    })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14958d1b-ad69-451e-8d87-7ed68752f64d",
   "metadata": {},
   "source": [
    "# Node2Vec Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca621b-c280-4e19-ad8e-f9223ccf8e5b",
   "metadata": {},
   "source": [
    "## Original Dataset Node2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c86adf08-1af8-4da7-af1a-08b7ee3187f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random walks...\n",
      "Random walks generation completed.\n",
      "Starting model training...\n",
      "Epoch 1/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 2246440.7500\n",
      "Epoch 2/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 2344078.0000\n",
      "Epoch 3/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 2053699.5000\n",
      "Epoch 4/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1756091.2500\n",
      "Epoch 5/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.0000e+00 - loss: 1661303.6250\n",
      "Epoch 6/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1549297.2500\n",
      "Epoch 7/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 1713258.7500\n",
      "Epoch 8/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1652718.0000\n",
      "Epoch 9/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1593299.6250\n",
      "Epoch 10/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1700624.8750\n",
      "Epoch 11/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 1464686.1250\n",
      "Epoch 12/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 1457919.2500\n",
      "Epoch 13/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1581634.6250\n",
      "Epoch 14/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1529770.3750\n",
      "Epoch 15/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 1477939.0000\n",
      "Epoch 16/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 1534949.2500\n",
      "Epoch 17/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1318599.5000\n",
      "Epoch 18/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1453911.8750\n",
      "Epoch 19/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1364722.5000\n",
      "Epoch 20/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 1397203.1250\n",
      "Epoch 21/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1299563.8750\n",
      "Epoch 22/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1209939.0000\n",
      "Epoch 23/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 1234738.8750\n",
      "Epoch 24/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1184524.3750\n",
      "Epoch 25/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 1192010.0000\n",
      "Epoch 26/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 1114603.6250\n",
      "Epoch 27/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1026731.8750\n",
      "Epoch 28/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 1140167.1250\n",
      "Epoch 29/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 998360.6250 \n",
      "Epoch 30/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1059531.8750\n",
      "Epoch 31/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1022629.5625\n",
      "Epoch 32/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 839645.7500\n",
      "Epoch 33/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 811480.0625\n",
      "Epoch 34/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 800905.3750\n",
      "Epoch 35/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: 685420.3125\n",
      "Epoch 36/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 680066.4375\n",
      "Epoch 37/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 618101.6250\n",
      "Epoch 38/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 633226.7500\n",
      "Epoch 39/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 562191.6875\n",
      "Epoch 40/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 578949.0000\n",
      "Epoch 41/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 479998.8125\n",
      "Epoch 42/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 474754.9062\n",
      "Epoch 43/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 454193.5938\n",
      "Epoch 44/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 439502.1562\n",
      "Epoch 45/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 402269.5938\n",
      "Epoch 46/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 427180.8438\n",
      "Epoch 47/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 416954.5312\n",
      "Epoch 48/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 386432.7500\n",
      "Epoch 49/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 357587.9375\n",
      "Epoch 50/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 355107.4375\n",
      "Epoch 51/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 323928.2812\n",
      "Epoch 52/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 293222.3125\n",
      "Epoch 53/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 339086.1250\n",
      "Epoch 54/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 339550.4062\n",
      "Epoch 55/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 299966.8438\n",
      "Epoch 56/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 293071.0938\n",
      "Epoch 57/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 274846.3438\n",
      "Epoch 58/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 297694.1250\n",
      "Epoch 59/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 285901.9375\n",
      "Epoch 60/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 270491.3750\n",
      "Epoch 61/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 269465.5938\n",
      "Epoch 62/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 270255.5000\n",
      "Epoch 63/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 236632.4219\n",
      "Epoch 64/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 229178.5625\n",
      "Epoch 65/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 229234.3906\n",
      "Epoch 66/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 201408.1094\n",
      "Epoch 67/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 228691.5469\n",
      "Epoch 68/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 199614.2500\n",
      "Epoch 69/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 183379.0625\n",
      "Epoch 70/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 190596.3906\n",
      "Epoch 71/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - loss: 180260.9062\n",
      "Epoch 72/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 170551.6094\n",
      "Epoch 73/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 156567.6562\n",
      "Epoch 74/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 170310.3125\n",
      "Epoch 75/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 159697.6875\n",
      "Epoch 76/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 171049.7344\n",
      "Epoch 77/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 177944.5938\n",
      "Epoch 78/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 149985.2812\n",
      "Epoch 79/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 151483.7656\n",
      "Epoch 80/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 170355.2344\n",
      "Epoch 81/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 173845.4531\n",
      "Epoch 82/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 157158.7031\n",
      "Epoch 83/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 149838.2812\n",
      "Epoch 84/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 158993.2188\n",
      "Epoch 85/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 141427.1094\n",
      "Epoch 86/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 141417.0312\n",
      "Epoch 87/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 135799.6250\n",
      "Epoch 88/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 150622.5000\n",
      "Epoch 89/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 148325.5781\n",
      "Epoch 90/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 143869.7656\n",
      "Epoch 91/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 122851.4062\n",
      "Epoch 92/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 123995.0703\n",
      "Epoch 93/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 119653.9766\n",
      "Epoch 94/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 116034.3359\n",
      "Epoch 95/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 101827.5000\n",
      "Epoch 96/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 95957.0938\n",
      "Epoch 97/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 111880.0000\n",
      "Epoch 98/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 101732.3984\n",
      "Epoch 99/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 79514.7031\n",
      "Epoch 100/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 89125.0938\n",
      "Epoch 101/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 76847.5469\n",
      "Epoch 102/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 80199.3984\n",
      "Epoch 103/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 72700.5625\n",
      "Epoch 104/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 72981.4609\n",
      "Epoch 105/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 87445.6484\n",
      "Epoch 106/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 77504.0469\n",
      "Epoch 107/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 66839.8516\n",
      "Epoch 108/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 84526.3047\n",
      "Epoch 109/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 85185.8516\n",
      "Epoch 110/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 85728.5312\n",
      "Epoch 111/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 99483.0391\n",
      "Epoch 112/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 112822.3281\n",
      "Epoch 113/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 86032.2266\n",
      "Epoch 114/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 77171.6719\n",
      "Epoch 115/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 79186.6172\n",
      "Epoch 116/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 85723.2969\n",
      "Epoch 117/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 69533.7578\n",
      "Epoch 118/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 66172.8984\n",
      "Epoch 119/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 61669.2305\n",
      "Epoch 120/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 55992.0469\n",
      "Epoch 121/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 48134.4062\n",
      "Epoch 122/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 38068.9492\n",
      "Epoch 123/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 33563.6133\n",
      "Epoch 124/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 37371.8203\n",
      "Epoch 125/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 33990.4375\n",
      "Epoch 126/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 35488.9805\n",
      "Epoch 127/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 30535.0996\n",
      "Epoch 128/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 42754.2188\n",
      "Epoch 129/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 25425.2832\n",
      "Epoch 130/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 27145.6172\n",
      "Epoch 131/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 28609.4668\n",
      "Epoch 132/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 24457.1309\n",
      "Epoch 133/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 26135.6367\n",
      "Epoch 134/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 23881.3379\n",
      "Epoch 135/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - loss: 27018.8418\n",
      "Epoch 136/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: 23684.6992\n",
      "Epoch 137/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 22879.1992\n",
      "Epoch 138/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 18051.2422\n",
      "Epoch 139/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 15813.0615\n",
      "Epoch 140/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 24998.0664\n",
      "Epoch 141/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 17391.7559\n",
      "Epoch 142/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 17593.4883\n",
      "Epoch 143/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 18640.1543\n",
      "Epoch 144/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 13070.2949\n",
      "Epoch 145/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 17216.9824\n",
      "Epoch 146/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: 13995.3115\n",
      "Epoch 147/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 12846.3340\n",
      "Epoch 148/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 17916.5254\n",
      "Epoch 149/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 22803.4570\n",
      "Epoch 150/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 11995.4707\n",
      "Training completed in 59.13 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import hypernetx as hnx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Node2Vec(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
    "                                          embeddings_initializer=tf.keras.initializers.RandomNormal(stddev=1.0),\n",
    "                                          embeddings_regularizer=tf.keras.regularizers.l2(1e-5))  # Reduced regularization\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.dense1 = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-5))\n",
    "        self.dense2 = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-5))\n",
    "        self.dense3 = layers.Dense(1, activation='linear')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "def train_node2vec_model(H, train, test, scenario):\n",
    "    user_ids = train['userId'].unique()\n",
    "    movie_ids = train['movieId'].unique()\n",
    "\n",
    "    user_mapping = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    movie_mapping = {movie_id: idx + len(user_ids) for idx, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "    train['user_idx'] = train['userId'].map(user_mapping)\n",
    "    train['movie_idx'] = train['movieId'].map(movie_mapping)\n",
    "\n",
    "    test['user_idx'] = test['userId'].map(user_mapping)\n",
    "    test['movie_idx'] = test['movieId'].map(movie_mapping)\n",
    "\n",
    "    # Generate random walks from the hypergraph\n",
    "    def random_walk(hypergraph, start_node, walk_length):\n",
    "        walk = [start_node]\n",
    "        while len(walk) < walk_length:\n",
    "            cur = walk[-1]\n",
    "            neighbors = list(hypergraph.neighbors(cur))\n",
    "            if neighbors:\n",
    "                walk.append(np.random.choice(neighbors))\n",
    "            else:\n",
    "                break\n",
    "        return [str(node) for node in walk]\n",
    "\n",
    "    def generate_walks(hypergraph, num_walks, walk_length):\n",
    "        print(\"Generating random walks...\")\n",
    "        nodes = list(hypergraph.nodes)\n",
    "        walks = Parallel(n_jobs=-1)(delayed(random_walk)(hypergraph, np.random.choice(nodes), walk_length) for _ in range(num_walks))\n",
    "        print(\"Random walks generation completed.\")\n",
    "        return walks\n",
    "\n",
    "    num_walks = 100  \n",
    "    walk_length = 50  \n",
    "    dimensions = 128  \n",
    "    window_size = 5 \n",
    "    epochs = 150  \n",
    "    learning_rate = 0.001  \n",
    "\n",
    "    walks = generate_walks(H, num_walks, walk_length)\n",
    "\n",
    "    # Convert walks to integer indices\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(H.nodes)}\n",
    "    walks_indices = [[node_to_idx[node] for node in walk if node in node_to_idx] for walk in walks]\n",
    "    vocab_size = len(node_to_idx)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for walk in walks_indices:\n",
    "        if len(walk) > window_size:\n",
    "            for i in range(len(walk) - window_size):\n",
    "                context = walk[i:i + window_size]\n",
    "                target = walk[i + window_size]\n",
    "                X.append(context)\n",
    "                y.append(target)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if X.size == 0 or y.size == 0:\n",
    "        print(\"No data generated for training. Check the random walk and context-target extraction steps.\")\n",
    "        return pd.DataFrame({\n",
    "            'Scenario': [scenario],\n",
    "            'Algorithm': ['Node2Vec'],\n",
    "            'MSE': [None],\n",
    "            'RMSE': [None],\n",
    "            'MAE': [None],\n",
    "            'Precision@10': [None],\n",
    "            'Recall@10': [None],\n",
    "            'Running Time (s)': [None]\n",
    "        })\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X, y)).batch(256).shuffle(buffer_size=1024).repeat()\n",
    "        steps_per_epoch = len(X) // 256\n",
    "        if steps_per_epoch == 0:\n",
    "            steps_per_epoch = 1\n",
    "\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=learning_rate,\n",
    "            decay_steps=1000,\n",
    "            decay_rate=0.96,\n",
    "            staircase=True)\n",
    "\n",
    "        model = Node2Vec(vocab_size, dimensions)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss='mean_squared_error', metrics=['accuracy'])\n",
    "        print(\"Starting model training...\")\n",
    "        start_time = time.time()\n",
    "        history = model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch)\n",
    "        end_time = time.time()\n",
    "        print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        embeddings = model.embedding.get_weights()[0]\n",
    "\n",
    "    results = evaluate_model(test, embeddings, user_mapping, movie_mapping, scenario, \"Node2Vec\")\n",
    "    results['Running Time (s)'] = end_time - start_time\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Evaluate Node2Vec model for different scenarios\n",
    "results_node2vec_normal = train_node2vec_model(H, train_df, test_df, \"Normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb437887-a41d-4786-a402-d315f19c9de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Node2Vec</td>\n",
       "      <td>46.897165</td>\n",
       "      <td>6.84815</td>\n",
       "      <td>4.982268</td>\n",
       "      <td>0.474496</td>\n",
       "      <td>0.11272</td>\n",
       "      <td>59.128732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scenario Algorithm        MSE     RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0   Normal  Node2Vec  46.897165  6.84815  4.982268      0.474496    0.11272   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         59.128732  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_node2vec_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2d4607-90f9-477b-8198-6c2df05c3ec0",
   "metadata": {},
   "source": [
    "# Sparse data Node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2f459c0-3032-42fd-be5e-415d731dfd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random walks...\n",
      "Random walks generation completed.\n",
      "Starting model training...\n",
      "Epoch 1/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 7.6526e-04 - loss: 1451524.5000\n",
      "Epoch 2/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1294319.2500\n",
      "Epoch 3/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 1151162.1250\n",
      "Epoch 4/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 994514.1250 \n",
      "Epoch 5/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 747250.3750\n",
      "Epoch 6/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 751999.0000\n",
      "Epoch 7/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 764305.7500\n",
      "Epoch 8/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 778838.2500\n",
      "Epoch 9/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 739402.6250\n",
      "Epoch 10/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 711617.3125\n",
      "Epoch 11/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 686405.6250\n",
      "Epoch 12/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 687847.6875\n",
      "Epoch 13/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 666624.6875\n",
      "Epoch 14/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 656335.8125\n",
      "Epoch 15/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 678639.5000\n",
      "Epoch 16/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 657936.3125\n",
      "Epoch 17/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 676704.6250\n",
      "Epoch 18/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 687963.1875\n",
      "Epoch 19/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 629230.0000\n",
      "Epoch 20/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 631994.9375\n",
      "Epoch 21/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 640738.5625\n",
      "Epoch 22/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 612128.1250\n",
      "Epoch 23/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 599612.8125\n",
      "Epoch 24/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 599153.8125\n",
      "Epoch 25/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 607022.7500\n",
      "Epoch 26/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 574096.0000\n",
      "Epoch 27/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 601624.1875\n",
      "Epoch 28/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 579617.6875\n",
      "Epoch 29/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 557250.3750\n",
      "Epoch 30/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 561406.0000\n",
      "Epoch 31/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 579700.5625\n",
      "Epoch 32/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 516009.2188\n",
      "Epoch 33/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 517549.9375\n",
      "Epoch 34/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 505096.5625\n",
      "Epoch 35/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 514486.3125\n",
      "Epoch 36/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 481575.3438\n",
      "Epoch 37/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 488687.0312\n",
      "Epoch 38/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 453691.7500\n",
      "Epoch 39/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 450205.4062\n",
      "Epoch 40/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 452578.1875\n",
      "Epoch 41/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 449945.7188\n",
      "Epoch 42/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 426331.1250\n",
      "Epoch 43/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 434097.8750\n",
      "Epoch 44/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 427636.5938\n",
      "Epoch 45/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 418464.1875\n",
      "Epoch 46/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 398343.1562\n",
      "Epoch 47/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 391788.0312\n",
      "Epoch 48/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 413467.5938\n",
      "Epoch 49/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 374204.6250\n",
      "Epoch 50/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 384341.6562\n",
      "Epoch 51/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 364125.1250\n",
      "Epoch 52/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 368291.8438\n",
      "Epoch 53/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 348733.6250\n",
      "Epoch 54/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 339350.3125\n",
      "Epoch 55/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 319994.5312\n",
      "Epoch 56/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 345870.5312\n",
      "Epoch 57/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 302265.0000\n",
      "Epoch 58/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 318235.1875\n",
      "Epoch 59/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 317667.8438\n",
      "Epoch 60/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 302386.0625\n",
      "Epoch 61/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 306910.7812\n",
      "Epoch 62/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 326341.2500\n",
      "Epoch 63/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 302442.1562\n",
      "Epoch 64/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 296122.8125\n",
      "Epoch 65/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 278141.5312\n",
      "Epoch 66/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 288906.2500\n",
      "Epoch 67/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 263783.4688\n",
      "Epoch 68/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 251147.0469\n",
      "Epoch 69/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 263065.9375\n",
      "Epoch 70/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 270310.6562\n",
      "Epoch 71/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 257624.9531\n",
      "Epoch 72/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 259503.5312\n",
      "Epoch 73/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 238346.7500\n",
      "Epoch 74/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 258177.9062\n",
      "Epoch 75/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 217424.5781\n",
      "Epoch 76/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 228794.7812\n",
      "Epoch 77/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 249377.7969\n",
      "Epoch 78/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 235738.5625\n",
      "Epoch 79/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 231102.1875\n",
      "Epoch 80/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 224793.0312\n",
      "Epoch 81/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 224103.4688\n",
      "Epoch 82/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 188327.3750\n",
      "Epoch 83/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 193542.8594\n",
      "Epoch 84/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 188062.7812\n",
      "Epoch 85/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 203457.2969\n",
      "Epoch 86/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 181666.4688\n",
      "Epoch 87/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 189159.2031\n",
      "Epoch 88/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 185999.0938\n",
      "Epoch 89/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 173720.8750\n",
      "Epoch 90/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 176743.5469\n",
      "Epoch 91/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 159167.8281\n",
      "Epoch 92/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 150578.6406\n",
      "Epoch 93/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 150557.1250\n",
      "Epoch 94/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 143637.2344\n",
      "Epoch 95/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 141215.5625\n",
      "Epoch 96/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 131810.6094\n",
      "Epoch 97/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 119107.3203\n",
      "Epoch 98/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 115942.1875\n",
      "Epoch 99/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 118209.8281\n",
      "Epoch 100/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 3.1315e-04 - loss: 105545.5312\n",
      "Epoch 101/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 99132.9688\n",
      "Epoch 102/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 3.8555e-04 - loss: 103349.1797\n",
      "Epoch 103/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 97721.5000\n",
      "Epoch 104/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 81238.2891\n",
      "Epoch 105/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.6938e-04 - loss: 86451.4062\n",
      "Epoch 106/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0698e-04 - loss: 81958.4531\n",
      "Epoch 107/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 2.6127e-04 - loss: 77509.3516\n",
      "Epoch 108/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 82569.6250\n",
      "Epoch 109/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 86581.3594\n",
      "Epoch 110/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.6938e-04 - loss: 89898.1953\n",
      "Epoch 111/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 5.6513e-05 - loss: 112294.2969\n",
      "Epoch 112/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 98827.0078\n",
      "Epoch 113/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 104641.1719\n",
      "Epoch 114/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 77117.6328\n",
      "Epoch 115/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 68439.6562\n",
      "Epoch 116/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 4.4125e-04 - loss: 59924.1055\n",
      "Epoch 117/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 59727.1133\n",
      "Epoch 118/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 4.0111e-05 - loss: 39789.4844\n",
      "Epoch 119/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 46002.6172\n",
      "Epoch 120/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 4.3615e-04 - loss: 41494.1445\n",
      "Epoch 121/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.4527e-04 - loss: 45799.4727\n",
      "Epoch 122/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 2.3509e-04 - loss: 36457.7891\n",
      "Epoch 123/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 3.3851e-04 - loss: 37031.3242\n",
      "Epoch 124/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.2357e-04 - loss: 38561.3477\n",
      "Epoch 125/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.7545e-04 - loss: 32238.8809\n",
      "Epoch 126/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.6197e-04 - loss: 30469.6289\n",
      "Epoch 127/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 32819.4258\n",
      "Epoch 128/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 5.3460e-04 - loss: 32579.2031\n",
      "Epoch 129/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 28373.5137\n",
      "Epoch 130/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.3204e-04 - loss: 24154.1074\n",
      "Epoch 131/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 32145.0078\n",
      "Epoch 132/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 5.4998e-05 - loss: 31036.5176\n",
      "Epoch 133/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 8.5756e-05 - loss: 26148.1875\n",
      "Epoch 134/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 5.6513e-05 - loss: 27361.0117\n",
      "Epoch 135/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.4294e-04 - loss: 31681.2480\n",
      "Epoch 136/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 30412.6855\n",
      "Epoch 137/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 33129.5117\n",
      "Epoch 138/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 5.4218e-04 - loss: 35046.3789\n",
      "Epoch 139/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 5.7150e-04 - loss: 34875.2539\n",
      "Epoch 140/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 8.9305e-05 - loss: 35005.9492\n",
      "Epoch 141/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 8.5756e-05 - loss: 57515.8398\n",
      "Epoch 142/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 5.4466e-04 - loss: 65051.2969\n",
      "Epoch 143/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 3.6421e-04 - loss: 33408.2305\n",
      "Epoch 144/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 3.1665e-04 - loss: 31882.5918\n",
      "Epoch 145/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 4.0111e-05 - loss: 24652.3066\n",
      "Epoch 146/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0449e-04 - loss: 24052.5176\n",
      "Epoch 147/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 6.9063e-05 - loss: 22770.9336\n",
      "Epoch 148/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.1031e-04 - loss: 21148.4629\n",
      "Epoch 149/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 18489.2754\n",
      "Epoch 150/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 20528.9316\n",
      "Training completed in 38.81 seconds\n"
     ]
    }
   ],
   "source": [
    "sparse_train_df = get_sparse_data(train_df, frac=0.1)\n",
    "\n",
    "# Sparse \n",
    "# Build the hypergraph\n",
    "edges_sparse = defaultdict(list)\n",
    "for _, row in sparse_train_df.iterrows():\n",
    "    user_node = f'user_{row[\"userId\"]}'\n",
    "    movie_node = f'movie_{row[\"movieId\"]}'\n",
    "    rating = row[\"rating\"]\n",
    "    hyperedge = f'{movie_node}_rating_{rating}'\n",
    "    edges_sparse[hyperedge].append(user_node)\n",
    "    edges_sparse[hyperedge].append(movie_node)\n",
    "\n",
    "H_sparse = hnx.Hypergraph(edges_sparse)\n",
    "\n",
    "\n",
    "def train_node2vec_model(H, train, test, scenario):\n",
    "    user_ids = train['userId'].unique()\n",
    "    movie_ids = train['movieId'].unique()\n",
    "\n",
    "    user_mapping = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    movie_mapping = {movie_id: idx + len(user_ids) for idx, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "    train['user_idx'] = train['userId'].map(user_mapping)\n",
    "    train['movie_idx'] = train['movieId'].map(movie_mapping)\n",
    "\n",
    "    test['user_idx'] = test['userId'].map(user_mapping)\n",
    "    test['movie_idx'] = test['movieId'].map(movie_mapping)\n",
    "\n",
    "    # Generate random walks from the hypergraph\n",
    "    def random_walk(hypergraph, start_node, walk_length):\n",
    "        walk = [start_node]\n",
    "        while len(walk) < walk_length:\n",
    "            cur = walk[-1]\n",
    "            neighbors = list(hypergraph.neighbors(cur))\n",
    "            if neighbors:\n",
    "                walk.append(np.random.choice(neighbors))\n",
    "            else:\n",
    "                break\n",
    "        return [str(node) for node in walk]\n",
    "\n",
    "    def generate_walks(hypergraph, num_walks, walk_length):\n",
    "        print(\"Generating random walks...\")\n",
    "        nodes = list(hypergraph.nodes)\n",
    "        walks = Parallel(n_jobs=-1)(delayed(random_walk)(hypergraph, np.random.choice(nodes), walk_length) for _ in range(num_walks))\n",
    "        print(\"Random walks generation completed.\")\n",
    "        return walks\n",
    "\n",
    "    num_walks = 100  \n",
    "    walk_length = 50  \n",
    "    dimensions = 128  \n",
    "    window_size = 5 \n",
    "    epochs = 150  \n",
    "    learning_rate = 0.001  \n",
    "\n",
    "    walks = generate_walks(H_sparse, num_walks, walk_length)\n",
    "\n",
    "    # Convert walks to integer indices\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(H_sparse.nodes)}\n",
    "    walks_indices = [[node_to_idx[node] for node in walk if node in node_to_idx] for walk in walks]\n",
    "    vocab_size = len(node_to_idx)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for walk in walks_indices:\n",
    "        if len(walk) > window_size:\n",
    "            for i in range(len(walk) - window_size):\n",
    "                context = walk[i:i + window_size]\n",
    "                target = walk[i + window_size]\n",
    "                X.append(context)\n",
    "                y.append(target)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if X.size == 0 or y.size == 0:\n",
    "        print(\"No data generated for training. Check the random walk and context-target extraction steps.\")\n",
    "        return pd.DataFrame({\n",
    "            'Scenario': [scenario],\n",
    "            'Algorithm': ['Node2Vec'],\n",
    "            'MSE': [None],\n",
    "            'RMSE': [None],\n",
    "            'MAE': [None],\n",
    "            'Precision@10': [None],\n",
    "            'Recall@10': [None],\n",
    "            'Running Time (s)': [None]\n",
    "        })\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X, y)).batch(256).shuffle(buffer_size=1024).repeat()\n",
    "        steps_per_epoch = len(X) // 256\n",
    "        if steps_per_epoch == 0:\n",
    "            steps_per_epoch = 1\n",
    "\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=learning_rate,\n",
    "            decay_steps=1000,\n",
    "            decay_rate=0.96,\n",
    "            staircase=True)\n",
    "\n",
    "        model = Node2Vec(vocab_size, dimensions)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss='mean_squared_error', metrics=['accuracy'])\n",
    "        print(\"Starting model training...\")\n",
    "        start_time = time.time()\n",
    "        history = model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch)\n",
    "        end_time = time.time()\n",
    "        print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        embeddings = model.embedding.get_weights()[0]\n",
    "\n",
    "    results = evaluate_model(test, embeddings, user_mapping, movie_mapping, scenario, \"Node2Vec\")\n",
    "    results['Running Time (s)'] = end_time - start_time\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "results_node2vec_sparse = train_node2vec_model(H_sparse, sparse_train_df, test_df, \"Sparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14d43e30-7045-4807-9b97-01854d6d786d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>Node2Vec</td>\n",
       "      <td>48.482455</td>\n",
       "      <td>6.962934</td>\n",
       "      <td>5.095941</td>\n",
       "      <td>0.407286</td>\n",
       "      <td>0.099925</td>\n",
       "      <td>38.807848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Scenario Algorithm        MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0   Sparse  Node2Vec  48.482455  6.962934  5.095941      0.407286   0.099925   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         38.807848  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_node2vec_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68999b00-3084-458a-83cc-7c4dd053b553",
   "metadata": {},
   "source": [
    "# New user Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bdd1956-df02-4083-89fb-7e03da48cfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random walks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/js5nvmg90d37xtyx33clr3th0000gn/T/ipykernel_1333/2495281623.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_idx'] = train['userId'].map(user_mapping)\n",
      "/var/folders/dr/js5nvmg90d37xtyx33clr3th0000gn/T/ipykernel_1333/2495281623.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['movie_idx'] = train['movieId'].map(movie_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random walks generation completed.\n",
      "Starting model training...\n",
      "Epoch 1/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 2410074.2500\n",
      "Epoch 2/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: 2663334.2500\n",
      "Epoch 3/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 2267722.0000\n",
      "Epoch 4/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 2033621.7500\n",
      "Epoch 5/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1813715.5000\n",
      "Epoch 6/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1780027.7500\n",
      "Epoch 7/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1920920.2500\n",
      "Epoch 8/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1750865.6250\n",
      "Epoch 9/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1618256.1250\n",
      "Epoch 10/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - loss: 1673358.7500\n",
      "Epoch 11/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - loss: 1730855.0000\n",
      "Epoch 12/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 1834998.7500\n",
      "Epoch 13/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 1744368.1250\n",
      "Epoch 14/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1660874.5000\n",
      "Epoch 15/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1695144.7500\n",
      "Epoch 16/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1528695.0000\n",
      "Epoch 17/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1625095.5000\n",
      "Epoch 18/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1469506.2500\n",
      "Epoch 19/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1505214.3750\n",
      "Epoch 20/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1447264.7500\n",
      "Epoch 21/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1618593.2500\n",
      "Epoch 22/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1397291.8750\n",
      "Epoch 23/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1405091.0000\n",
      "Epoch 24/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1395206.2500\n",
      "Epoch 25/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1498031.1250\n",
      "Epoch 26/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1341200.1250\n",
      "Epoch 27/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 1055550.8750\n",
      "Epoch 28/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - loss: 1205982.3750\n",
      "Epoch 29/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 1144131.5000\n",
      "Epoch 30/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 1063625.2500\n",
      "Epoch 31/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 989274.8750\n",
      "Epoch 32/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 917200.0000\n",
      "Epoch 33/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1016930.0000\n",
      "Epoch 34/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 919185.6250\n",
      "Epoch 35/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 783917.5000\n",
      "Epoch 36/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 836202.5625\n",
      "Epoch 37/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 747392.4375\n",
      "Epoch 38/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 764766.2500\n",
      "Epoch 39/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 714213.3125\n",
      "Epoch 40/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 662970.3125\n",
      "Epoch 41/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 665783.4375\n",
      "Epoch 42/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 591618.1875\n",
      "Epoch 43/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 534628.8750\n",
      "Epoch 44/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 542333.2500\n",
      "Epoch 45/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 446517.1875\n",
      "Epoch 46/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 523667.1562\n",
      "Epoch 47/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 471894.3125\n",
      "Epoch 48/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 475168.2500\n",
      "Epoch 49/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 469995.7188\n",
      "Epoch 50/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 411805.0938\n",
      "Epoch 51/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 426704.2500\n",
      "Epoch 52/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 368247.4688\n",
      "Epoch 53/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 380549.7188\n",
      "Epoch 54/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 375373.4375\n",
      "Epoch 55/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 334022.6875\n",
      "Epoch 56/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 386298.7188\n",
      "Epoch 57/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 286703.4062\n",
      "Epoch 58/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 304532.7500\n",
      "Epoch 59/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 324459.1250\n",
      "Epoch 60/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 309456.3125\n",
      "Epoch 61/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 267667.0312\n",
      "Epoch 62/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 294471.8750\n",
      "Epoch 63/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 302297.2188\n",
      "Epoch 64/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 253364.1875\n",
      "Epoch 65/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 271992.0312\n",
      "Epoch 66/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 248134.6250\n",
      "Epoch 67/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.0000e+00 - loss: 237922.1875\n",
      "Epoch 68/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 251158.7031\n",
      "Epoch 69/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 227908.0312\n",
      "Epoch 70/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 252569.5938\n",
      "Epoch 71/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 255467.0000\n",
      "Epoch 72/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 279881.0312\n",
      "Epoch 73/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 222025.8750\n",
      "Epoch 74/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 230773.0312\n",
      "Epoch 75/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 232456.3438\n",
      "Epoch 76/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0000e+00 - loss: 198686.5625\n",
      "Epoch 77/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 164496.9219\n",
      "Epoch 78/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 191230.2500\n",
      "Epoch 79/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 224286.2031\n",
      "Epoch 80/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 177886.2344\n",
      "Epoch 81/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 168461.0312\n",
      "Epoch 82/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 187705.3281\n",
      "Epoch 83/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - loss: 188508.3750\n",
      "Epoch 84/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 176646.0781\n",
      "Epoch 85/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.0000e+00 - loss: 150812.9375\n",
      "Epoch 86/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 155061.8125\n",
      "Epoch 87/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 159777.5156\n",
      "Epoch 88/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 128682.7188\n",
      "Epoch 89/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 131652.9062\n",
      "Epoch 90/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 143754.4062\n",
      "Epoch 91/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 8.8234e-05 - loss: 152540.2188\n",
      "Epoch 92/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0000e+00 - loss: 138887.6094\n",
      "Epoch 93/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 6.3231e-04 - loss: 108895.3047\n",
      "Epoch 94/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 6.4732e-04 - loss: 115911.8594\n",
      "Epoch 95/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 2.6512e-04 - loss: 109222.2578\n",
      "Epoch 96/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.9651e-04 - loss: 128772.2500\n",
      "Epoch 97/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0849e-04 - loss: 109249.8828\n",
      "Epoch 98/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 2.5531e-05 - loss: 114580.1641\n",
      "Epoch 99/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 96052.8125\n",
      "Epoch 100/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.9965e-04 - loss: 87844.5938\n",
      "Epoch 101/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 2.6616e-04 - loss: 105920.6094\n",
      "Epoch 102/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 2.2999e-04 - loss: 84115.3594\n",
      "Epoch 103/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 2.8921e-04 - loss: 106656.2969\n",
      "Epoch 104/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 111674.3828\n",
      "Epoch 105/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 7.4363e-04 - loss: 106959.7734\n",
      "Epoch 106/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 3.0708e-04 - loss: 103221.5469\n",
      "Epoch 107/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 4.1693e-04 - loss: 86678.2109\n",
      "Epoch 108/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 7.0119e-04 - loss: 83417.8594\n",
      "Epoch 109/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 5.4320e-04 - loss: 72407.6406\n",
      "Epoch 110/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 7.7597e-04 - loss: 79172.6250\n",
      "Epoch 111/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 70720.9219\n",
      "Epoch 112/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0012 - loss: 67744.9297\n",
      "Epoch 113/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 6.2502e-04 - loss: 65224.7500\n",
      "Epoch 114/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 2.6864e-05 - loss: 68668.8906\n",
      "Epoch 115/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 5.1545e-04 - loss: 59406.2500\n",
      "Epoch 116/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 7.5920e-04 - loss: 53421.4180\n",
      "Epoch 117/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 7.8890e-04 - loss: 51241.5273\n",
      "Epoch 118/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 4.7277e-04 - loss: 49960.0664\n",
      "Epoch 119/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 4.4222e-04 - loss: 45035.1797\n",
      "Epoch 120/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 5.7733e-04 - loss: 51469.0273\n",
      "Epoch 121/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 50299.7266\n",
      "Epoch 122/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 3.0138e-04 - loss: 32668.9512\n",
      "Epoch 123/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 44017.4141\n",
      "Epoch 124/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 9.7796e-04 - loss: 38946.2188\n",
      "Epoch 125/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 40345.7773\n",
      "Epoch 126/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 5.6046e-04 - loss: 31046.8945\n",
      "Epoch 127/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 2.7126e-04 - loss: 27075.9766\n",
      "Epoch 128/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 6.6001e-04 - loss: 25189.5332\n",
      "Epoch 129/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0011 - loss: 26099.7773\n",
      "Epoch 130/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 2.6326e-04 - loss: 34340.6250\n",
      "Epoch 131/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 5.1943e-04 - loss: 29282.3535\n",
      "Epoch 132/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 7.8117e-04 - loss: 23743.0605\n",
      "Epoch 133/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 32836.5469\n",
      "Epoch 134/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 6.1511e-04 - loss: 37086.3945\n",
      "Epoch 135/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 2.5531e-05 - loss: 34400.8477\n",
      "Epoch 136/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 3.1979e-04 - loss: 46985.2539\n",
      "Epoch 137/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 4.6429e-04 - loss: 48458.7656\n",
      "Epoch 138/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 2.6181e-05 - loss: 51864.0781\n",
      "Epoch 139/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 9.2858e-04 - loss: 36021.0977\n",
      "Epoch 140/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0011 - loss: 44852.2109\n",
      "Epoch 141/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.4219e-04 - loss: 39550.1719\n",
      "Epoch 142/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 9.4594e-05 - loss: 31595.7734\n",
      "Epoch 143/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 3.2338e-04 - loss: 31238.8945\n",
      "Epoch 144/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.7331e-04 - loss: 34617.6289\n",
      "Epoch 145/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 4.2414e-04 - loss: 24450.9902\n",
      "Epoch 146/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0010 - loss: 16944.6309\n",
      "Epoch 147/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0024 - loss: 20649.0430\n",
      "Epoch 148/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0014 - loss: 17008.4199\n",
      "Epoch 149/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0013 - loss: 18527.3672\n",
      "Epoch 150/150\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 8.4226e-04 - loss: 18023.5430\n",
      "Training completed in 59.45 seconds\n"
     ]
    }
   ],
   "source": [
    "new_user_train_df = get_new_user_data(train_df, frac=0.1)\n",
    "\n",
    "# Build the hypergraph\n",
    "edges_new_user = defaultdict(list)\n",
    "for _, row in new_user_train_df.iterrows():\n",
    "    user_node = f'user_{row[\"userId\"]}'\n",
    "    movie_node = f'movie_{row[\"movieId\"]}'\n",
    "    rating = row[\"rating\"]\n",
    "    hyperedge = f'{movie_node}_rating_{rating}'\n",
    "    edges_new_user[hyperedge].append(user_node)\n",
    "    edges_new_user[hyperedge].append(movie_node)\n",
    "\n",
    "H_new_user = hnx.Hypergraph(edges_new_user)\n",
    "\n",
    "\n",
    "def train_node2vec_model(H, train, test, scenario):\n",
    "    user_ids = train['userId'].unique()\n",
    "    movie_ids = train['movieId'].unique()\n",
    "\n",
    "    user_mapping = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    movie_mapping = {movie_id: idx + len(user_ids) for idx, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "    train['user_idx'] = train['userId'].map(user_mapping)\n",
    "    train['movie_idx'] = train['movieId'].map(movie_mapping)\n",
    "\n",
    "    test['user_idx'] = test['userId'].map(user_mapping)\n",
    "    test['movie_idx'] = test['movieId'].map(movie_mapping)\n",
    "\n",
    "    # Generate random walks from the hypergraph\n",
    "    def random_walk(hypergraph, start_node, walk_length):\n",
    "        walk = [start_node]\n",
    "        while len(walk) < walk_length:\n",
    "            cur = walk[-1]\n",
    "            neighbors = list(hypergraph.neighbors(cur))\n",
    "            if neighbors:\n",
    "                walk.append(np.random.choice(neighbors))\n",
    "            else:\n",
    "                break\n",
    "        return [str(node) for node in walk]\n",
    "\n",
    "    def generate_walks(hypergraph, num_walks, walk_length):\n",
    "        print(\"Generating random walks...\")\n",
    "        nodes = list(hypergraph.nodes)\n",
    "        walks = Parallel(n_jobs=-1)(delayed(random_walk)(hypergraph, np.random.choice(nodes), walk_length) for _ in range(num_walks))\n",
    "        print(\"Random walks generation completed.\")\n",
    "        return walks\n",
    "\n",
    "    num_walks = 100  \n",
    "    walk_length = 50  \n",
    "    dimensions = 128  \n",
    "    window_size = 5 \n",
    "    epochs = 150  \n",
    "    learning_rate = 0.001  \n",
    "\n",
    "    walks = generate_walks(H_new_user, num_walks, walk_length)\n",
    "\n",
    "    # Convert walks to integer indices\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(H_new_user.nodes)}\n",
    "    walks_indices = [[node_to_idx[node] for node in walk if node in node_to_idx] for walk in walks]\n",
    "    vocab_size = len(node_to_idx)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for walk in walks_indices:\n",
    "        if len(walk) > window_size:\n",
    "            for i in range(len(walk) - window_size):\n",
    "                context = walk[i:i + window_size]\n",
    "                target = walk[i + window_size]\n",
    "                X.append(context)\n",
    "                y.append(target)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if X.size == 0 or y.size == 0:\n",
    "        print(\"No data generated for training. Check the random walk and context-target extraction steps.\")\n",
    "        return pd.DataFrame({\n",
    "            'Scenario': [scenario],\n",
    "            'Algorithm': ['Node2Vec'],\n",
    "            'MSE': [None],\n",
    "            'RMSE': [None],\n",
    "            'MAE': [None],\n",
    "            'Precision@10': [None],\n",
    "            'Recall@10': [None],\n",
    "            'Running Time (s)': [None]\n",
    "        })\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X, y)).batch(256).shuffle(buffer_size=1024).repeat()\n",
    "        steps_per_epoch = len(X) // 256\n",
    "        if steps_per_epoch == 0:\n",
    "            steps_per_epoch = 1\n",
    "\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=learning_rate,\n",
    "            decay_steps=1000,\n",
    "            decay_rate=0.96,\n",
    "            staircase=True)\n",
    "\n",
    "        model = Node2Vec(vocab_size, dimensions)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss='mean_squared_error', metrics=['accuracy'])\n",
    "        print(\"Starting model training...\")\n",
    "        start_time = time.time()\n",
    "        history = model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch)\n",
    "        end_time = time.time()\n",
    "        print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        embeddings = model.embedding.get_weights()[0]\n",
    "\n",
    "    results = evaluate_model(test, embeddings, user_mapping, movie_mapping, scenario, \"Node2Vec\")\n",
    "    results['Running Time (s)'] = end_time - start_time\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "results_node2vec_new_user = train_node2vec_model(H_new_user, new_user_train_df, test_df, \"New User\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62e64ddf-cde9-4837-8039-1752ce5be886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New User</td>\n",
       "      <td>Node2Vec</td>\n",
       "      <td>47.357681</td>\n",
       "      <td>6.881692</td>\n",
       "      <td>4.988233</td>\n",
       "      <td>0.442582</td>\n",
       "      <td>0.097093</td>\n",
       "      <td>59.448123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario Algorithm        MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0  New User  Node2Vec  47.357681  6.881692  4.988233      0.442582   0.097093   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         59.448123  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_node2vec_new_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "12a3b054-ba23-45f7-ba86-6effbc58695b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Node2Vec</td>\n",
       "      <td>47.267650</td>\n",
       "      <td>6.875147</td>\n",
       "      <td>5.017519</td>\n",
       "      <td>0.473556</td>\n",
       "      <td>0.104442</td>\n",
       "      <td>57.877078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>Node2Vec</td>\n",
       "      <td>48.482455</td>\n",
       "      <td>6.962934</td>\n",
       "      <td>5.095941</td>\n",
       "      <td>0.407286</td>\n",
       "      <td>0.099925</td>\n",
       "      <td>38.807848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>Node2Vec</td>\n",
       "      <td>47.357681</td>\n",
       "      <td>6.881692</td>\n",
       "      <td>4.988233</td>\n",
       "      <td>0.442582</td>\n",
       "      <td>0.097093</td>\n",
       "      <td>59.448123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario Algorithm        MSE      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal  Node2Vec  47.267650  6.875147  5.017519      0.473556   0.104442   \n",
       "1    Sparse  Node2Vec  48.482455  6.962934  5.095941      0.407286   0.099925   \n",
       "2  New User  Node2Vec  47.357681  6.881692  4.988233      0.442582   0.097093   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         57.877078  \n",
       "1         38.807848  \n",
       "2         59.448123  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Combine Node2Vec results into a single DataFrame\n",
    "results_node2vec_combined = pd.concat([results_node2vec_normal, results_node2vec_sparse, results_node2vec_new_user], ignore_index=True)\n",
    "\n",
    "results_node2vec_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60bb938-731f-4d6d-b24b-f9f764a618dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
