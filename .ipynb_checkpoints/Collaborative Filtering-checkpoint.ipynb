{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14b8616-ae1c-4191-ba8b-3f3ac50447f7",
   "metadata": {},
   "source": [
    "# Experimentation and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95904abf-f705-4e53-8bce-a6c3ecb6d93e",
   "metadata": {},
   "source": [
    "## Objective of the project \n",
    "\n",
    "This study seeks to conduct a thorough comparative analysis of these three models, focusing\n",
    "on their performance with regards to accuracy, computational complexity, scalability, and their\n",
    "effectiveness in handling data sparsity and dynamically changing environments. By evaluat-\n",
    "ing these aspects, the research aims to illuminate the operational strengths and weaknesses\n",
    "of each model, providing clear insights that could guide the development and deployment of\n",
    "future recommender systems. Through this comparative framework, we aspire to answer which\n",
    "model, under what conditions, provides the most reliable and robust recommendations, thereby\n",
    "significantly contributing to the optimization of digital services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec1c5afc-8ec3-4beb-9777-ef5cd6260e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter, defaultdict\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD, CoClustering, accuracy\n",
    "#from surprise.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.accuracy import rmse, mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89d2f34e-8624-4280-9fb9-28ed84c78540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Links':    movieId  imdbId   tmdbId\n",
       " 0        1  114709    862.0\n",
       " 1        2  113497   8844.0\n",
       " 2        3  113228  15602.0\n",
       " 3        4  114885  31357.0\n",
       " 4        5  113041  11862.0,\n",
       " 'Movies':    movieId                               title  \\\n",
       " 0        1                    Toy Story (1995)   \n",
       " 1        2                      Jumanji (1995)   \n",
       " 2        3             Grumpier Old Men (1995)   \n",
       " 3        4            Waiting to Exhale (1995)   \n",
       " 4        5  Father of the Bride Part II (1995)   \n",
       " \n",
       "                                         genres  \n",
       " 0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       " 1                   Adventure|Children|Fantasy  \n",
       " 2                               Comedy|Romance  \n",
       " 3                         Comedy|Drama|Romance  \n",
       " 4                                       Comedy  ,\n",
       " 'Ratings':    userId  movieId  rating  timestamp\n",
       " 0       1        1     4.0  964982703\n",
       " 1       1        3     4.0  964981247\n",
       " 2       1        6     4.0  964982224\n",
       " 3       1       47     5.0  964983815\n",
       " 4       1       50     5.0  964982931,\n",
       " 'Tags':    userId  movieId              tag   timestamp\n",
       " 0       2    60756            funny  1445714994\n",
       " 1       2    60756  Highly quotable  1445714996\n",
       " 2       2    60756     will ferrell  1445714992\n",
       " 3       2    89774     Boxing story  1445715207\n",
       " 4       2    89774              MMA  1445715200}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_df = pd.read_csv('MovieLens_100k/links.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "tags_df = pd.read_csv('MovieLens_100k/tags.csv')\n",
    "\n",
    "datasets = {\n",
    "    \"Links\": links_df,\n",
    "    \"Movies\": movies_df,\n",
    "    \"Ratings\": ratings_df,\n",
    "    \"Tags\": tags_df\n",
    "}\n",
    "\n",
    "datasets_info = {name: df.head() for name, df in datasets.items()}\n",
    "datasets_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffed4e8-5b41-485b-8277-e2a6fba0e61b",
   "metadata": {},
   "source": [
    "## Dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862584cf-a7e4-415e-b6bc-ec7f894fb287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Links dataset:\n",
      "movieId    0\n",
      "imdbId     0\n",
      "tmdbId     8\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Movies dataset:\n",
      "movieId    0\n",
      "title      0\n",
      "genres     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Ratings dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Tags dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "tag          0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each dataset\n",
    "missing_values = {name: df.isnull().sum() for name, df in datasets.items()}\n",
    "\n",
    "# Print the information about missing values\n",
    "for name, missing in missing_values.items():\n",
    "    print(f\"Missing values in {name} dataset:\\n{missing}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713549fa-4fca-4d77-9bb7-7d1f73ef073d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Links DataFrame is: (9742, 3)\n",
      "The shape of the Movies DataFrame is: (9742, 3)\n",
      "The shape of the Ratings DataFrame is: (100836, 4)\n",
      "The shape of the Tags DataFrame is: (3683, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of each DataFrame\n",
    "for name, df in datasets.items():\n",
    "    print(f\"The shape of the {name} DataFrame is: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "083bc746-5ced-4d3e-a934-90d141950572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.5</td>\n",
       "      <td>13136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>26818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.5</td>\n",
       "      <td>8551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  count\n",
       "0     0.5   1370\n",
       "1     1.0   2811\n",
       "2     1.5   1791\n",
       "3     2.0   7551\n",
       "4     2.5   5550\n",
       "5     3.0  20047\n",
       "6     3.5  13136\n",
       "7     4.0  26818\n",
       "8     4.5   8551\n",
       "9     5.0  13211"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_of_ratings = ratings_df.groupby('rating').size().reset_index(name='count')\n",
    "distribution_of_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a6200-e172-4221-a145-5f3f9dd4936c",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f3cda-6102-4105-b4b9-a9b9179845b7",
   "metadata": {},
   "source": [
    "### For the collaborative filtering, we have implemented 3 algorithms liisted below: \n",
    "\n",
    "### a. KNNBasic (K-Nearest Neighbors)\n",
    "The KNNBasic algorithm leverages the k-nearest neighbors technique to predict user ratings\n",
    "based on the weighted average of ratings from similar users or items. For KNN, we have chosen 3 different similarity measures to test: Pearson, Pearson baseline and Mean squared difference. Refer to the technical report for more detail. \n",
    "\n",
    "### b. SVD (Singular Value Decomposition)\n",
    "SVD: SVD is a matrix factorization technique that decomposes the user-item rating matrix into\n",
    "latent factors, enabling the prediction of ratings through these latent factors.\n",
    "\n",
    "### c. CoClustering\n",
    "CoClustering: CoClustering simultaneously clusters users and items to uncover hidden re-\n",
    "lationships in the data, facilitating more accurate rating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f052626-a527-4413-a248-c93e56285302",
   "metadata": {},
   "source": [
    "### Useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7402410-d7e1-4228-ad03-d46ab4685c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\"\"\"\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Map the predictions to only the top N items\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def get_top_n_recommendations(user_id, n=10):\n",
    "    # Get a list of all movies in the dataset\n",
    "    all_movies = movies_df['movieId'].unique()\n",
    "    \n",
    "    # Get movies that the user has already rated\n",
    "    rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].tolist()\n",
    "    \n",
    "    # Predict ratings for all movies the user hasn't rated yet\n",
    "    predictions = []\n",
    "    for movie_id in set(all_movies) - set(rated_movies):\n",
    "        pred = model.predict(uid=user_id, iid=movie_id)\n",
    "        predictions.append((movie_id, pred.est))\n",
    "    \n",
    "    # Sort the predictions by estimated rating in descending order and select the top N\n",
    "    top_n = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    # Map the movie IDs back to titles\n",
    "    top_n_movies = [(movies_df[movies_df['movieId'] == mid]['title'].values[0], est) for mid, est in top_n]\n",
    "    \n",
    "    return top_n_movies\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=0.7):  \n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        return precisions, recalls\n",
    "\n",
    "def compute_mse(predictions):\n",
    "    \"\"\"Compute Mean Squared Error (MSE).\"\"\"\n",
    "    mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "    return mse\n",
    "\n",
    "def compute_rmse(predictions):\n",
    "    \"\"\"Compute Root Mean Squared Error (RMSE).\"\"\"\n",
    "    mse = compute_mse(predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def compute_mae(predictions):\n",
    "    \"\"\"Compute Mean Absolute Error (MAE).\"\"\"\n",
    "    mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "    return mae\n",
    "\n",
    "def get_sparse_data(ratings, frac=0.1):\n",
    "    sparse_ratings_df = ratings.sample(frac=frac, random_state=42)  \n",
    "    return sparse_ratings_df\n",
    "\n",
    "def get_new_user_data(ratings, frac=0.1):\n",
    "    new_user_ratings_df = ratings[ratings['userId'].isin(ratings['userId'].sample(frac=frac, random_state=42))]\n",
    "    return new_user_ratings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955f9e0-cb6e-4303-8d90-591853dd4fa5",
   "metadata": {},
   "source": [
    "### In this part, we use the Surprise library, renowned for its robust implementation of various collaborative filtering algorithms, to evaluate different recommendation system models. Specifically, we implement KNNBasic, SVD, and CoClustering algorithms, chosen for their widespread recognition and effectiveness in collaborative filtering tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b30382f7-3538-4805-b956-cc2b95cb3c28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to evaluate a model with a given algorithm and similarity measure\n",
    "def evaluate_algorithm(algo_name, similarity_measure, train_set, test_set, user_based=True):\n",
    "    if algo_name == 'KNNBasic':\n",
    "        sim_options = {\n",
    "            'name': similarity_measure,\n",
    "            'user_based': user_based\n",
    "        }\n",
    "        model = KNNBasic(sim_options=sim_options)\n",
    "    elif algo_name == 'SVD':\n",
    "        model = SVD()\n",
    "    elif algo_name == 'CoClustering':\n",
    "        model = CoClustering()\n",
    "\n",
    "    # Measure start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_set)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = model.test(test_set)\n",
    "\n",
    "    # Measure end time\n",
    "    end_time = time.time()\n",
    "    # Calculate running time\n",
    "    running_time = end_time - start_time\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    mse_score = accuracy.mse(predictions, verbose=False)\n",
    "    rmse_score = accuracy.rmse(predictions, verbose=False)\n",
    "    mae_score = accuracy.mae(predictions, verbose=False)\n",
    "\n",
    "    \n",
    "    # Compute precision and recall\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=0.7)\n",
    "    precision_avg = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall_avg = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    return algo_name, similarity_measure, user_based, mse_score, rmse_score, mae_score, precision_avg, recall_avg, running_time\n",
    "\n",
    "# Function to evaluate all scenarios\n",
    "def evaluate_all_scenarios(train_set, test_set, scenario_name):\n",
    "    results_combined = []\n",
    "    for algo_name, similarity_measure in algorithms:\n",
    "        for user_based in [True, False]:\n",
    "            algo_name, similarity_measure, user_based, mse_score, rmse_score, mae_score, precision_avg, recall_avg, running_time = evaluate_algorithm(algo_name, similarity_measure, train_set, test_set, user_based)\n",
    "            results_combined.append({\n",
    "                'Scenario': scenario_name,\n",
    "                'Algorithm': algo_name,\n",
    "                'Similarity Measure': similarity_measure if similarity_measure else 'N/A',\n",
    "                'User-Based': user_based,\n",
    "                'MSE': mse_score,\n",
    "                'RMSE': rmse_score,\n",
    "                'MAE': mae_score,\n",
    "                'Precision@10': precision_avg,\n",
    "                'Recall@10': recall_avg,\n",
    "                'Running Time (s)': running_time\n",
    "            })\n",
    "    return results_combined\n",
    "\n",
    "\n",
    "reader = Reader(rating_scale=(ratings_df['rating'].min(), ratings_df['rating'].max()))\n",
    "\n",
    "# Step 1: Split the data into training and test sets (80% training, 20% testing)\n",
    "train_df, test_df = train_test_split(ratings_df, test_size=0.20, random_state=42)\n",
    "\n",
    "# Convert the training set into a Surprise dataset\n",
    "train_data = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']], reader)\n",
    "train_set = train_data.build_full_trainset()\n",
    "\n",
    "# Convert the test set into a Surprise dataset for later use\n",
    "test_data = Dataset.load_from_df(test_df[['userId', 'movieId', 'rating']], reader)\n",
    "test_set = test_data.build_full_trainset().build_testset()\n",
    "\n",
    "# Step 2: Create the sparse training set from the 80% training data\n",
    "sparse_train_df = get_sparse_data(train_df, frac=0.1)\n",
    "sparse_data = Dataset.load_from_df(sparse_train_df[['userId', 'movieId', 'rating']], reader)\n",
    "sparse_train_set = sparse_data.build_full_trainset()\n",
    "\n",
    "# Step 3: Create the new user training set from the 80% training data\n",
    "new_user_train_df = get_new_user_data(train_df, frac=0.1)\n",
    "new_user_data = Dataset.load_from_df(new_user_train_df[['userId', 'movieId', 'rating']], reader)\n",
    "new_user_train_set = new_user_data.build_full_trainset()\n",
    "\n",
    "\n",
    "# Output to check\n",
    "train_set.n_ratings, len(test_set)\n",
    "\n",
    "# List of algorithms and their similarity measures to evaluate\n",
    "algorithms = [\n",
    "    ('KNNBasic', 'pearson'),\n",
    "    ('KNNBasic', 'pearson_baseline'),\n",
    "    ('KNNBasic', 'msd'),\n",
    "    ('SVD', None),  # SVD does not use similarity measures\n",
    "    ('CoClustering', None)  # CoClustering does not use similarity measures\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c16696e-7b49-4294-bd9b-c9af3f8c25c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate normal scenario\n",
    "results_normal = evaluate_all_scenarios(train_set, test_set, \"Normal\")\n",
    "\n",
    "# Evaluate sparse data scenario\n",
    "results_sparse = evaluate_all_scenarios(sparse_train_set, test_set, \"Sparse\")\n",
    "\n",
    "# Evaluate new user data scenario\n",
    "results_new_user = evaluate_all_scenarios(new_user_train_set, test_set, \"New User\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee916ab8-7eb9-467f-b827-34db3b283d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Similarity Measure</th>\n",
       "      <th>User-Based</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047447</td>\n",
       "      <td>0.217822</td>\n",
       "      <td>0.168082</td>\n",
       "      <td>0.689299</td>\n",
       "      <td>0.492621</td>\n",
       "      <td>1.529102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.217295</td>\n",
       "      <td>0.168717</td>\n",
       "      <td>0.517611</td>\n",
       "      <td>0.398195</td>\n",
       "      <td>18.764348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047433</td>\n",
       "      <td>0.217790</td>\n",
       "      <td>0.167656</td>\n",
       "      <td>0.688259</td>\n",
       "      <td>0.496251</td>\n",
       "      <td>1.583247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041960</td>\n",
       "      <td>0.204842</td>\n",
       "      <td>0.155043</td>\n",
       "      <td>0.625488</td>\n",
       "      <td>0.474030</td>\n",
       "      <td>11.467633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.046086</td>\n",
       "      <td>0.214677</td>\n",
       "      <td>0.164979</td>\n",
       "      <td>0.679926</td>\n",
       "      <td>0.499211</td>\n",
       "      <td>1.255274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041458</td>\n",
       "      <td>0.203612</td>\n",
       "      <td>0.156361</td>\n",
       "      <td>0.531894</td>\n",
       "      <td>0.413416</td>\n",
       "      <td>9.768819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Normal</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.041005</td>\n",
       "      <td>0.202497</td>\n",
       "      <td>0.155352</td>\n",
       "      <td>0.647672</td>\n",
       "      <td>0.459548</td>\n",
       "      <td>1.190404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Normal</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041094</td>\n",
       "      <td>0.202715</td>\n",
       "      <td>0.155254</td>\n",
       "      <td>0.626419</td>\n",
       "      <td>0.453290</td>\n",
       "      <td>1.149808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Normal</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.313754</td>\n",
       "      <td>0.560137</td>\n",
       "      <td>0.511696</td>\n",
       "      <td>0.175363</td>\n",
       "      <td>0.044782</td>\n",
       "      <td>2.664798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Normal</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.310585</td>\n",
       "      <td>0.557301</td>\n",
       "      <td>0.510051</td>\n",
       "      <td>0.131653</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>2.510326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.057388</td>\n",
       "      <td>0.239559</td>\n",
       "      <td>0.188667</td>\n",
       "      <td>0.204090</td>\n",
       "      <td>0.035612</td>\n",
       "      <td>0.158362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.055519</td>\n",
       "      <td>0.235625</td>\n",
       "      <td>0.185655</td>\n",
       "      <td>0.270563</td>\n",
       "      <td>0.037605</td>\n",
       "      <td>1.022089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.058104</td>\n",
       "      <td>0.241047</td>\n",
       "      <td>0.189540</td>\n",
       "      <td>0.233902</td>\n",
       "      <td>0.043686</td>\n",
       "      <td>0.326732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.056063</td>\n",
       "      <td>0.236777</td>\n",
       "      <td>0.186087</td>\n",
       "      <td>0.313862</td>\n",
       "      <td>0.052083</td>\n",
       "      <td>0.735174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.062009</td>\n",
       "      <td>0.249017</td>\n",
       "      <td>0.192169</td>\n",
       "      <td>0.525922</td>\n",
       "      <td>0.229263</td>\n",
       "      <td>0.160648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.058758</td>\n",
       "      <td>0.242401</td>\n",
       "      <td>0.185709</td>\n",
       "      <td>0.476615</td>\n",
       "      <td>0.237743</td>\n",
       "      <td>0.681256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049906</td>\n",
       "      <td>0.223397</td>\n",
       "      <td>0.174412</td>\n",
       "      <td>0.600174</td>\n",
       "      <td>0.391305</td>\n",
       "      <td>0.339218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.050358</td>\n",
       "      <td>0.224406</td>\n",
       "      <td>0.174711</td>\n",
       "      <td>0.586879</td>\n",
       "      <td>0.391806</td>\n",
       "      <td>0.212321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.271167</td>\n",
       "      <td>0.520737</td>\n",
       "      <td>0.446987</td>\n",
       "      <td>0.271353</td>\n",
       "      <td>0.089614</td>\n",
       "      <td>0.485683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.270505</td>\n",
       "      <td>0.520101</td>\n",
       "      <td>0.446704</td>\n",
       "      <td>0.277588</td>\n",
       "      <td>0.087657</td>\n",
       "      <td>0.488495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047445</td>\n",
       "      <td>0.217819</td>\n",
       "      <td>0.168148</td>\n",
       "      <td>0.668612</td>\n",
       "      <td>0.475516</td>\n",
       "      <td>1.398924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.047287</td>\n",
       "      <td>0.217455</td>\n",
       "      <td>0.168899</td>\n",
       "      <td>0.502132</td>\n",
       "      <td>0.384828</td>\n",
       "      <td>15.231194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.047443</td>\n",
       "      <td>0.217814</td>\n",
       "      <td>0.167772</td>\n",
       "      <td>0.669194</td>\n",
       "      <td>0.477266</td>\n",
       "      <td>1.710859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.042074</td>\n",
       "      <td>0.205120</td>\n",
       "      <td>0.155333</td>\n",
       "      <td>0.607008</td>\n",
       "      <td>0.458193</td>\n",
       "      <td>11.767120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>0.214860</td>\n",
       "      <td>0.165201</td>\n",
       "      <td>0.659569</td>\n",
       "      <td>0.479126</td>\n",
       "      <td>1.237151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.041535</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>0.156525</td>\n",
       "      <td>0.521969</td>\n",
       "      <td>0.401117</td>\n",
       "      <td>9.800809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New User</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.041180</td>\n",
       "      <td>0.202928</td>\n",
       "      <td>0.155836</td>\n",
       "      <td>0.634885</td>\n",
       "      <td>0.452067</td>\n",
       "      <td>1.166703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New User</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.040567</td>\n",
       "      <td>0.201412</td>\n",
       "      <td>0.154480</td>\n",
       "      <td>0.636736</td>\n",
       "      <td>0.462141</td>\n",
       "      <td>1.260938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New User</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.313919</td>\n",
       "      <td>0.560285</td>\n",
       "      <td>0.510417</td>\n",
       "      <td>0.202851</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>2.521362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New User</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.312582</td>\n",
       "      <td>0.559090</td>\n",
       "      <td>0.509274</td>\n",
       "      <td>0.191030</td>\n",
       "      <td>0.049907</td>\n",
       "      <td>2.494795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Scenario     Algorithm Similarity Measure  User-Based       MSE      RMSE  \\\n",
       "0     Normal      KNNBasic            pearson        True  0.047447  0.217822   \n",
       "1     Normal      KNNBasic            pearson       False  0.047217  0.217295   \n",
       "2     Normal      KNNBasic   pearson_baseline        True  0.047433  0.217790   \n",
       "3     Normal      KNNBasic   pearson_baseline       False  0.041960  0.204842   \n",
       "4     Normal      KNNBasic                msd        True  0.046086  0.214677   \n",
       "5     Normal      KNNBasic                msd       False  0.041458  0.203612   \n",
       "6     Normal           SVD                N/A        True  0.041005  0.202497   \n",
       "7     Normal           SVD                N/A       False  0.041094  0.202715   \n",
       "8     Normal  CoClustering                N/A        True  0.313754  0.560137   \n",
       "9     Normal  CoClustering                N/A       False  0.310585  0.557301   \n",
       "10    Sparse      KNNBasic            pearson        True  0.057388  0.239559   \n",
       "11    Sparse      KNNBasic            pearson       False  0.055519  0.235625   \n",
       "12    Sparse      KNNBasic   pearson_baseline        True  0.058104  0.241047   \n",
       "13    Sparse      KNNBasic   pearson_baseline       False  0.056063  0.236777   \n",
       "14    Sparse      KNNBasic                msd        True  0.062009  0.249017   \n",
       "15    Sparse      KNNBasic                msd       False  0.058758  0.242401   \n",
       "16    Sparse           SVD                N/A        True  0.049906  0.223397   \n",
       "17    Sparse           SVD                N/A       False  0.050358  0.224406   \n",
       "18    Sparse  CoClustering                N/A        True  0.271167  0.520737   \n",
       "19    Sparse  CoClustering                N/A       False  0.270505  0.520101   \n",
       "20  New User      KNNBasic            pearson        True  0.047445  0.217819   \n",
       "21  New User      KNNBasic            pearson       False  0.047287  0.217455   \n",
       "22  New User      KNNBasic   pearson_baseline        True  0.047443  0.217814   \n",
       "23  New User      KNNBasic   pearson_baseline       False  0.042074  0.205120   \n",
       "24  New User      KNNBasic                msd        True  0.046165  0.214860   \n",
       "25  New User      KNNBasic                msd       False  0.041535  0.203800   \n",
       "26  New User           SVD                N/A        True  0.041180  0.202928   \n",
       "27  New User           SVD                N/A       False  0.040567  0.201412   \n",
       "28  New User  CoClustering                N/A        True  0.313919  0.560285   \n",
       "29  New User  CoClustering                N/A       False  0.312582  0.559090   \n",
       "\n",
       "         MAE  Precision@10  Recall@10  Running Time (s)  \n",
       "0   0.168082      0.689299   0.492621          1.529102  \n",
       "1   0.168717      0.517611   0.398195         18.764348  \n",
       "2   0.167656      0.688259   0.496251          1.583247  \n",
       "3   0.155043      0.625488   0.474030         11.467633  \n",
       "4   0.164979      0.679926   0.499211          1.255274  \n",
       "5   0.156361      0.531894   0.413416          9.768819  \n",
       "6   0.155352      0.647672   0.459548          1.190404  \n",
       "7   0.155254      0.626419   0.453290          1.149808  \n",
       "8   0.511696      0.175363   0.044782          2.664798  \n",
       "9   0.510051      0.131653   0.036242          2.510326  \n",
       "10  0.188667      0.204090   0.035612          0.158362  \n",
       "11  0.185655      0.270563   0.037605          1.022089  \n",
       "12  0.189540      0.233902   0.043686          0.326732  \n",
       "13  0.186087      0.313862   0.052083          0.735174  \n",
       "14  0.192169      0.525922   0.229263          0.160648  \n",
       "15  0.185709      0.476615   0.237743          0.681256  \n",
       "16  0.174412      0.600174   0.391305          0.339218  \n",
       "17  0.174711      0.586879   0.391806          0.212321  \n",
       "18  0.446987      0.271353   0.089614          0.485683  \n",
       "19  0.446704      0.277588   0.087657          0.488495  \n",
       "20  0.168148      0.668612   0.475516          1.398924  \n",
       "21  0.168899      0.502132   0.384828         15.231194  \n",
       "22  0.167772      0.669194   0.477266          1.710859  \n",
       "23  0.155333      0.607008   0.458193         11.767120  \n",
       "24  0.165201      0.659569   0.479126          1.237151  \n",
       "25  0.156525      0.521969   0.401117          9.800809  \n",
       "26  0.155836      0.634885   0.452067          1.166703  \n",
       "27  0.154480      0.636736   0.462141          1.260938  \n",
       "28  0.510417      0.202851   0.051051          2.521362  \n",
       "29  0.509274      0.191030   0.049907          2.494795  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_CF= pd.DataFrame(results_normal + results_sparse + results_new_user)\n",
    "results_CF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
