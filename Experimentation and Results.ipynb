{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14b8616-ae1c-4191-ba8b-3f3ac50447f7",
   "metadata": {},
   "source": [
    "# Experimentation and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95904abf-f705-4e53-8bce-a6c3ecb6d93e",
   "metadata": {},
   "source": [
    "## Objective of the project \n",
    "\n",
    "This study seeks to conduct a thorough comparative analysis of these three models, focusing\n",
    "on their performance with regards to accuracy, computational complexity, scalability, and their\n",
    "effectiveness in handling data sparsity and dynamically changing environments. By evaluat-\n",
    "ing these aspects, the research aims to illuminate the operational strengths and weaknesses\n",
    "of each model, providing clear insights that could guide the development and deployment of\n",
    "future recommender systems. Through this comparative framework, we aspire to answer which\n",
    "model, under what conditions, provides the most reliable and robust recommendations, thereby\n",
    "significantly contributing to the optimization of digital services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec1c5afc-8ec3-4beb-9777-ef5cd6260e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter, defaultdict\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD, CoClustering, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.accuracy import rmse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d2f34e-8624-4280-9fb9-28ed84c78540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Links':    movieId  imdbId   tmdbId\n",
       " 0        1  114709    862.0\n",
       " 1        2  113497   8844.0\n",
       " 2        3  113228  15602.0\n",
       " 3        4  114885  31357.0\n",
       " 4        5  113041  11862.0,\n",
       " 'Movies':    movieId                               title  \\\n",
       " 0        1                    Toy Story (1995)   \n",
       " 1        2                      Jumanji (1995)   \n",
       " 2        3             Grumpier Old Men (1995)   \n",
       " 3        4            Waiting to Exhale (1995)   \n",
       " 4        5  Father of the Bride Part II (1995)   \n",
       " \n",
       "                                         genres  \n",
       " 0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       " 1                   Adventure|Children|Fantasy  \n",
       " 2                               Comedy|Romance  \n",
       " 3                         Comedy|Drama|Romance  \n",
       " 4                                       Comedy  ,\n",
       " 'Ratings':    userId  movieId  rating  timestamp\n",
       " 0       1        1     4.0  964982703\n",
       " 1       1        3     4.0  964981247\n",
       " 2       1        6     4.0  964982224\n",
       " 3       1       47     5.0  964983815\n",
       " 4       1       50     5.0  964982931,\n",
       " 'Tags':    userId  movieId              tag   timestamp\n",
       " 0       2    60756            funny  1445714994\n",
       " 1       2    60756  Highly quotable  1445714996\n",
       " 2       2    60756     will ferrell  1445714992\n",
       " 3       2    89774     Boxing story  1445715207\n",
       " 4       2    89774              MMA  1445715200}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links_df = pd.read_csv('MovieLens_100k/links.csv')\n",
    "movies_df = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "ratings_df = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "tags_df = pd.read_csv('MovieLens_100k/tags.csv')\n",
    "\n",
    "datasets = {\n",
    "    \"Links\": links_df,\n",
    "    \"Movies\": movies_df,\n",
    "    \"Ratings\": ratings_df,\n",
    "    \"Tags\": tags_df\n",
    "}\n",
    "\n",
    "datasets_info = {name: df.head() for name, df in datasets.items()}\n",
    "datasets_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffed4e8-5b41-485b-8277-e2a6fba0e61b",
   "metadata": {},
   "source": [
    "## Dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862584cf-a7e4-415e-b6bc-ec7f894fb287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Links dataset:\n",
      "movieId    0\n",
      "imdbId     0\n",
      "tmdbId     8\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Movies dataset:\n",
      "movieId    0\n",
      "title      0\n",
      "genres     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Ratings dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Tags dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "tag          0\n",
      "timestamp    0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each dataset\n",
    "missing_values = {name: df.isnull().sum() for name, df in datasets.items()}\n",
    "\n",
    "# Print the information about missing values\n",
    "for name, missing in missing_values.items():\n",
    "    print(f\"Missing values in {name} dataset:\\n{missing}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713549fa-4fca-4d77-9bb7-7d1f73ef073d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Links DataFrame is: (9742, 3)\n",
      "The shape of the Movies DataFrame is: (9742, 3)\n",
      "The shape of the Ratings DataFrame is: (100836, 4)\n",
      "The shape of the Tags DataFrame is: (3683, 4)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of each DataFrame\n",
    "for name, df in datasets.items():\n",
    "    print(f\"The shape of the {name} DataFrame is: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "083bc746-5ced-4d3e-a934-90d141950572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>7551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>20047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.5</td>\n",
       "      <td>13136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>26818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.5</td>\n",
       "      <td>8551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>13211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating  count\n",
       "0     0.5   1370\n",
       "1     1.0   2811\n",
       "2     1.5   1791\n",
       "3     2.0   7551\n",
       "4     2.5   5550\n",
       "5     3.0  20047\n",
       "6     3.5  13136\n",
       "7     4.0  26818\n",
       "8     4.5   8551\n",
       "9     5.0  13211"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_of_ratings = ratings_df.groupby('rating').size().reset_index(name='count')\n",
    "distribution_of_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309a6200-e172-4221-a145-5f3f9dd4936c",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f3cda-6102-4105-b4b9-a9b9179845b7",
   "metadata": {},
   "source": [
    "### For the collaborative filtering, we have implemented 3 algorithms liisted below: \n",
    "\n",
    "### a. KNNBasic (K-Nearest Neighbors)\n",
    "The KNNBasic algorithm leverages the k-nearest neighbors technique to predict user ratings\n",
    "based on the weighted average of ratings from similar users or items. For KNN, we have chosen 3 different similarity measures to test: Pearson, Pearson baseline and Mean squared difference. Refer to the technical report for more detail. \n",
    "\n",
    "### b. SVD (Singular Value Decomposition)\n",
    "SVD: SVD is a matrix factorization technique that decomposes the user-item rating matrix into\n",
    "latent factors, enabling the prediction of ratings through these latent factors.\n",
    "\n",
    "### c. CoClustering\n",
    "CoClustering: CoClustering simultaneously clusters users and items to uncover hidden re-\n",
    "lationships in the data, facilitating more accurate rating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f052626-a527-4413-a248-c93e56285302",
   "metadata": {},
   "source": [
    "### Useful functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7402410-d7e1-4228-ad03-d46ab4685c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\"\"\"\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Map the predictions to only the top N items\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def get_top_n_recommendations(user_id, n=10):\n",
    "    # Get a list of all movies in the dataset\n",
    "    all_movies = movies_df['movieId'].unique()\n",
    "    \n",
    "    # Get movies that the user has already rated\n",
    "    rated_movies = ratings_df[ratings_df['userId'] == user_id]['movieId'].tolist()\n",
    "    \n",
    "    # Predict ratings for all movies the user hasn't rated yet\n",
    "    predictions = []\n",
    "    for movie_id in set(all_movies) - set(rated_movies):\n",
    "        pred = model.predict(uid=user_id, iid=movie_id)\n",
    "        predictions.append((movie_id, pred.est))\n",
    "    \n",
    "    # Sort the predictions by estimated rating in descending order and select the top N\n",
    "    top_n = sorted(predictions, key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    # Map the movie IDs back to titles\n",
    "    top_n_movies = [(movies_df[movies_df['movieId'] == mid]['title'].values[0], est) for mid, est in top_n]\n",
    "    \n",
    "    return top_n_movies\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=0.7):  \n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        return precisions, recalls\n",
    "     \n",
    "def compute_rmse(predictions):\n",
    "    \"\"\"Compute Root Mean Squared Error (RMSE).\"\"\"\n",
    "    mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def compute_mae(predictions):\n",
    "    \"\"\"Compute Mean Absolute Error (MAE).\"\"\"\n",
    "    mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955f9e0-cb6e-4303-8d90-591853dd4fa5",
   "metadata": {},
   "source": [
    "### In this part, we use the Surprise library, renowned for its robust implementation of various collaborative filtering algorithms, to evaluate different recommendation system models. Specifically, we implement KNNBasic, SVD, and CoClustering algorithms, chosen for their widespread recognition and effectiveness in collaborative filtering tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b30382f7-3538-4805-b956-cc2b95cb3c28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD, CoClustering, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Function to evaluate a model with a given algorithm and similarity measure\n",
    "def evaluate_algorithm(algo_name, similarity_measure, train_set, test_set, user_based=True):\n",
    "    if algo_name == 'KNNBasic':\n",
    "        sim_options = {\n",
    "            'name': similarity_measure,\n",
    "            'user_based': user_based\n",
    "        }\n",
    "        model = KNNBasic(sim_options=sim_options)\n",
    "    elif algo_name == 'SVD':\n",
    "        model = SVD()\n",
    "    elif algo_name == 'CoClustering':\n",
    "        model = CoClustering()\n",
    "\n",
    "    # Measure start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_set)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    predictions = model.test(test_set)\n",
    "\n",
    "    # Measure end time\n",
    "    end_time = time.time()\n",
    "    # Calculate running time\n",
    "    running_time = end_time - start_time\n",
    "    \n",
    "    # Evaluate accuracy\n",
    "    rmse_score = accuracy.rmse(predictions, verbose=False)\n",
    "    mae_score = accuracy.mae(predictions, verbose=False)\n",
    "    \n",
    "    # Compute precision and recall\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10, threshold=0.7)\n",
    "    precision_avg = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall_avg = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    \n",
    "    return algo_name, similarity_measure, user_based, rmse_score, mae_score, precision_avg, recall_avg, running_time\n",
    "\n",
    "# Function to evaluate all scenarios\n",
    "def evaluate_all_scenarios(train_set, test_set, scenario_name):\n",
    "    results_combined = []\n",
    "    for algo_name, similarity_measure in algorithms:\n",
    "        for user_based in [True, False]:\n",
    "            algo_name, similarity_measure, user_based, rmse_score, mae_score, precision_avg, recall_avg, running_time = evaluate_algorithm(algo_name, similarity_measure, train_set, test_set, user_based)\n",
    "            results_combined.append({\n",
    "                'Scenario': scenario_name,\n",
    "                'Algorithm': algo_name,\n",
    "                'Similarity Measure': similarity_measure if similarity_measure else 'N/A',\n",
    "                'User-Based': user_based,\n",
    "                'RMSE': rmse_score,\n",
    "                'MAE': mae_score,\n",
    "                'Precision@10': precision_avg,\n",
    "                'Recall@10': recall_avg,\n",
    "                'Running Time (s)': running_time\n",
    "            })\n",
    "    return results_combined\n",
    "\n",
    "# Create a Surprise dataset\n",
    "ratings_df['rating'] = (ratings_df['rating'] - ratings_df['rating'].min()) / (ratings_df['rating'].max() - ratings_df['rating'].min())\n",
    "\n",
    "reader = Reader(rating_scale=(ratings_df['rating'].min(), ratings_df['rating'].max()))\n",
    "data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_set, test_set = train_test_split(data, test_size=0.20)\n",
    "\n",
    "# Output to check\n",
    "train_set.n_ratings, len(test_set)\n",
    "\n",
    "# List of algorithms and their similarity measures to evaluate\n",
    "algorithms = [\n",
    "    ('KNNBasic', 'pearson'),\n",
    "    ('KNNBasic', 'pearson_baseline'),\n",
    "    ('KNNBasic', 'msd'),\n",
    "    ('SVD', None),  # SVD does not use similarity measures\n",
    "    ('CoClustering', None)  # CoClustering does not use similarity measures\n",
    "]\n",
    "\n",
    "# Evaluate normal scenario\n",
    "results_normal = evaluate_all_scenarios(train_set, test_set, \"Normal\")\n",
    "\n",
    "# Simulation for sparse data\n",
    "sparse_ratings_df = ratings_df.sample(frac=0.1, random_state=42)  # Keeping only 10% of the data\n",
    "sparse_data = Dataset.load_from_df(sparse_ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "sparse_train_set, sparse_test_set = train_test_split(sparse_data, test_size=0.20)\n",
    "\n",
    "# Evaluate sparse data scenario\n",
    "results_sparse = evaluate_all_scenarios(sparse_train_set, sparse_test_set, \"Sparse\")\n",
    "\n",
    "# Simulation for cold start problem (new users)\n",
    "new_user_ratings_df = ratings_df[ratings_df['userId'].isin(ratings_df['userId'].sample(frac=0.1, random_state=42))]\n",
    "\n",
    "# Create a Surprise dataset for new user data\n",
    "new_user_data = Dataset.load_from_df(new_user_ratings_df[['userId', 'movieId', 'rating']], reader)\n",
    "new_user_train_set, new_user_test_set = train_test_split(new_user_data, test_size=0.20)\n",
    "\n",
    "# Evaluate new user data scenario\n",
    "results_new_user = evaluate_all_scenarios(new_user_train_set, new_user_test_set, \"New User\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da453d1f-4ba9-4b9e-8041-3e8acccc1c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Similarity Measure</th>\n",
       "      <th>User-Based</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.217433</td>\n",
       "      <td>0.167403</td>\n",
       "      <td>0.681419</td>\n",
       "      <td>0.482391</td>\n",
       "      <td>1.577275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.214941</td>\n",
       "      <td>0.166982</td>\n",
       "      <td>0.517631</td>\n",
       "      <td>0.389731</td>\n",
       "      <td>14.983212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.217501</td>\n",
       "      <td>0.167079</td>\n",
       "      <td>0.676271</td>\n",
       "      <td>0.487729</td>\n",
       "      <td>1.601246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.204038</td>\n",
       "      <td>0.154259</td>\n",
       "      <td>0.609774</td>\n",
       "      <td>0.461591</td>\n",
       "      <td>12.312512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.213605</td>\n",
       "      <td>0.163704</td>\n",
       "      <td>0.672722</td>\n",
       "      <td>0.488166</td>\n",
       "      <td>1.281166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Normal</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.202160</td>\n",
       "      <td>0.155620</td>\n",
       "      <td>0.522313</td>\n",
       "      <td>0.417250</td>\n",
       "      <td>10.443120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Normal</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.199440</td>\n",
       "      <td>0.153197</td>\n",
       "      <td>0.636856</td>\n",
       "      <td>0.450793</td>\n",
       "      <td>1.219783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Normal</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.199464</td>\n",
       "      <td>0.153466</td>\n",
       "      <td>0.636138</td>\n",
       "      <td>0.449077</td>\n",
       "      <td>1.084938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Normal</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.558738</td>\n",
       "      <td>0.512389</td>\n",
       "      <td>0.111245</td>\n",
       "      <td>0.032385</td>\n",
       "      <td>2.333833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Normal</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.561689</td>\n",
       "      <td>0.513963</td>\n",
       "      <td>0.144278</td>\n",
       "      <td>0.042020</td>\n",
       "      <td>2.316910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.237807</td>\n",
       "      <td>0.188140</td>\n",
       "      <td>0.119334</td>\n",
       "      <td>0.057817</td>\n",
       "      <td>0.037749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.235729</td>\n",
       "      <td>0.186501</td>\n",
       "      <td>0.082593</td>\n",
       "      <td>0.038550</td>\n",
       "      <td>0.524907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.238456</td>\n",
       "      <td>0.187579</td>\n",
       "      <td>0.144836</td>\n",
       "      <td>0.076237</td>\n",
       "      <td>0.047723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.236430</td>\n",
       "      <td>0.186289</td>\n",
       "      <td>0.121704</td>\n",
       "      <td>0.059102</td>\n",
       "      <td>0.238681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.244304</td>\n",
       "      <td>0.189860</td>\n",
       "      <td>0.333362</td>\n",
       "      <td>0.252445</td>\n",
       "      <td>0.024163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.239449</td>\n",
       "      <td>0.185353</td>\n",
       "      <td>0.321258</td>\n",
       "      <td>0.253624</td>\n",
       "      <td>0.161412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.216410</td>\n",
       "      <td>0.169533</td>\n",
       "      <td>0.448187</td>\n",
       "      <td>0.406446</td>\n",
       "      <td>0.127224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.220187</td>\n",
       "      <td>0.172711</td>\n",
       "      <td>0.438220</td>\n",
       "      <td>0.394566</td>\n",
       "      <td>0.113744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.519440</td>\n",
       "      <td>0.448089</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.062898</td>\n",
       "      <td>0.422259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.521285</td>\n",
       "      <td>0.449601</td>\n",
       "      <td>0.112222</td>\n",
       "      <td>0.059269</td>\n",
       "      <td>0.418421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>True</td>\n",
       "      <td>0.216375</td>\n",
       "      <td>0.167251</td>\n",
       "      <td>0.684808</td>\n",
       "      <td>0.465282</td>\n",
       "      <td>1.402579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson</td>\n",
       "      <td>False</td>\n",
       "      <td>0.214508</td>\n",
       "      <td>0.166308</td>\n",
       "      <td>0.534035</td>\n",
       "      <td>0.396585</td>\n",
       "      <td>14.104410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>True</td>\n",
       "      <td>0.216124</td>\n",
       "      <td>0.166519</td>\n",
       "      <td>0.692850</td>\n",
       "      <td>0.480907</td>\n",
       "      <td>1.580747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>pearson_baseline</td>\n",
       "      <td>False</td>\n",
       "      <td>0.203326</td>\n",
       "      <td>0.153958</td>\n",
       "      <td>0.627913</td>\n",
       "      <td>0.475188</td>\n",
       "      <td>12.432336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>True</td>\n",
       "      <td>0.212011</td>\n",
       "      <td>0.163236</td>\n",
       "      <td>0.689563</td>\n",
       "      <td>0.481867</td>\n",
       "      <td>1.274559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>New User</td>\n",
       "      <td>KNNBasic</td>\n",
       "      <td>msd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.201419</td>\n",
       "      <td>0.154856</td>\n",
       "      <td>0.516358</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>10.612801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>New User</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.198844</td>\n",
       "      <td>0.153150</td>\n",
       "      <td>0.635569</td>\n",
       "      <td>0.438056</td>\n",
       "      <td>1.214717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>New User</td>\n",
       "      <td>SVD</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.199565</td>\n",
       "      <td>0.153569</td>\n",
       "      <td>0.633467</td>\n",
       "      <td>0.437789</td>\n",
       "      <td>1.104816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>New User</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>True</td>\n",
       "      <td>0.564291</td>\n",
       "      <td>0.516131</td>\n",
       "      <td>0.158539</td>\n",
       "      <td>0.041992</td>\n",
       "      <td>2.394291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>New User</td>\n",
       "      <td>CoClustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>False</td>\n",
       "      <td>0.561599</td>\n",
       "      <td>0.515394</td>\n",
       "      <td>0.119774</td>\n",
       "      <td>0.033225</td>\n",
       "      <td>2.355567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Scenario     Algorithm Similarity Measure  User-Based      RMSE       MAE  \\\n",
       "0     Normal      KNNBasic            pearson        True  0.217433  0.167403   \n",
       "1     Normal      KNNBasic            pearson       False  0.214941  0.166982   \n",
       "2     Normal      KNNBasic   pearson_baseline        True  0.217501  0.167079   \n",
       "3     Normal      KNNBasic   pearson_baseline       False  0.204038  0.154259   \n",
       "4     Normal      KNNBasic                msd        True  0.213605  0.163704   \n",
       "5     Normal      KNNBasic                msd       False  0.202160  0.155620   \n",
       "6     Normal           SVD                N/A        True  0.199440  0.153197   \n",
       "7     Normal           SVD                N/A       False  0.199464  0.153466   \n",
       "8     Normal  CoClustering                N/A        True  0.558738  0.512389   \n",
       "9     Normal  CoClustering                N/A       False  0.561689  0.513963   \n",
       "10    Sparse      KNNBasic            pearson        True  0.237807  0.188140   \n",
       "11    Sparse      KNNBasic            pearson       False  0.235729  0.186501   \n",
       "12    Sparse      KNNBasic   pearson_baseline        True  0.238456  0.187579   \n",
       "13    Sparse      KNNBasic   pearson_baseline       False  0.236430  0.186289   \n",
       "14    Sparse      KNNBasic                msd        True  0.244304  0.189860   \n",
       "15    Sparse      KNNBasic                msd       False  0.239449  0.185353   \n",
       "16    Sparse           SVD                N/A        True  0.216410  0.169533   \n",
       "17    Sparse           SVD                N/A       False  0.220187  0.172711   \n",
       "18    Sparse  CoClustering                N/A        True  0.519440  0.448089   \n",
       "19    Sparse  CoClustering                N/A       False  0.521285  0.449601   \n",
       "20  New User      KNNBasic            pearson        True  0.216375  0.167251   \n",
       "21  New User      KNNBasic            pearson       False  0.214508  0.166308   \n",
       "22  New User      KNNBasic   pearson_baseline        True  0.216124  0.166519   \n",
       "23  New User      KNNBasic   pearson_baseline       False  0.203326  0.153958   \n",
       "24  New User      KNNBasic                msd        True  0.212011  0.163236   \n",
       "25  New User      KNNBasic                msd       False  0.201419  0.154856   \n",
       "26  New User           SVD                N/A        True  0.198844  0.153150   \n",
       "27  New User           SVD                N/A       False  0.199565  0.153569   \n",
       "28  New User  CoClustering                N/A        True  0.564291  0.516131   \n",
       "29  New User  CoClustering                N/A       False  0.561599  0.515394   \n",
       "\n",
       "    Precision@10  Recall@10  Running Time (s)  \n",
       "0       0.681419   0.482391          1.577275  \n",
       "1       0.517631   0.389731         14.983212  \n",
       "2       0.676271   0.487729          1.601246  \n",
       "3       0.609774   0.461591         12.312512  \n",
       "4       0.672722   0.488166          1.281166  \n",
       "5       0.522313   0.417250         10.443120  \n",
       "6       0.636856   0.450793          1.219783  \n",
       "7       0.636138   0.449077          1.084938  \n",
       "8       0.111245   0.032385          2.333833  \n",
       "9       0.144278   0.042020          2.316910  \n",
       "10      0.119334   0.057817          0.037749  \n",
       "11      0.082593   0.038550          0.524907  \n",
       "12      0.144836   0.076237          0.047723  \n",
       "13      0.121704   0.059102          0.238681  \n",
       "14      0.333362   0.252445          0.024163  \n",
       "15      0.321258   0.253624          0.161412  \n",
       "16      0.448187   0.406446          0.127224  \n",
       "17      0.438220   0.394566          0.113744  \n",
       "18      0.118889   0.062898          0.422259  \n",
       "19      0.112222   0.059269          0.418421  \n",
       "20      0.684808   0.465282          1.402579  \n",
       "21      0.534035   0.396585         14.104410  \n",
       "22      0.692850   0.480907          1.580747  \n",
       "23      0.627913   0.475188         12.432336  \n",
       "24      0.689563   0.481867          1.274559  \n",
       "25      0.516358   0.406667         10.612801  \n",
       "26      0.635569   0.438056          1.214717  \n",
       "27      0.633467   0.437789          1.104816  \n",
       "28      0.158539   0.041992          2.394291  \n",
       "29      0.119774   0.033225          2.355567  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_CF1 = pd.DataFrame(results_normal + results_sparse + results_new_user)\n",
    "results_CF1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38520179-d4fa-4945-b64d-2625cdb5cc5c",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "User-based algorithms generally outperformed item-based algorithms across the different sce-\n",
    "narios tested. Specifically, KNNBasic with Pearson similarity in a user-based setting demon-\n",
    "strated competitive performance, particularly excelling in the normal and new user scenarios.\n",
    "It achieved notable metrics, including high Precision@10 and Recall@10, highlighting its ef-\n",
    "fectiveness in these contexts. SVD consistently delivered strong results across all scenarios,\n",
    "achieving the lowest RMSE and MAE values, coupled with high Precision@10 and Recall@10.\n",
    "This consistent performance, combined with relatively short running times, underscores SVDâ€™s\n",
    "robustness and reliability as a recommendation algorithm for the dataset we have worked on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bcddd5-551b-4d64-a6cf-70163343775f",
   "metadata": {},
   "source": [
    "# Graph-based Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a116c296-8d7b-4686-92b5-f027a19d01fe",
   "metadata": {},
   "source": [
    "### For the graph-based models, we have implemented 3 algorithms as well: LightGCN, Graph Attention Network, GraphSAGE\n",
    "Graph Construction: In the graph construction phase, nodes are created to represent both users\n",
    "and movies, while edges represent the interactions between these users and movies based on\n",
    "their ratings. To facilitate this, numpy is utilized for constructing the adjacency matrix, which\n",
    "captures the user-movie interaction graph in a structured form. This adjacency matrix serves\n",
    "as the foundation for various graph-based algorithms, allowing us to represent the relationships\n",
    "between users and movies effectively. Additionally, TensorFlow is employed to handle the graph\n",
    "representation and computation, leveraging its powerful capabilities for efficient processing and\n",
    "model training in subsequent stages. \n",
    "\n",
    "### In this first part of the code, we have implemented all the useful functions and code that all the 3 algorithms shared in commun to avoid code redundancy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32f6e04e-147e-4f54-aabe-f97d4192f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "ratings = pd.read_csv('MovieLens_100k/ratings.csv')\n",
    "movies = pd.read_csv('MovieLens_100k/movies.csv')\n",
    "\n",
    "# Data Preprocessing\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "ratings['user'] = user_encoder.fit_transform(ratings['userId'])\n",
    "ratings['item'] = item_encoder.fit_transform(ratings['movieId'])\n",
    "\n",
    "num_users = ratings['user'].nunique()\n",
    "num_items = ratings['item'].nunique()\n",
    "\n",
    "# Normalize the ratings \n",
    "ratings['rating'] = (ratings['rating'] - ratings['rating'].min()) / (ratings['rating'].max() - ratings['rating'].min())\n",
    "\n",
    "def get_sparse_data(ratings, frac=0.1):\n",
    "    sparse_ratings_df = ratings.sample(frac=frac, random_state=42)  \n",
    "    return sparse_ratings_df\n",
    "\n",
    "def get_new_user_data(ratings, frac=0.1):\n",
    "    new_user_ratings_df = ratings[ratings['userId'].isin(ratings['userId'].sample(frac=frac, random_state=42))]\n",
    "    return new_user_ratings_df\n",
    "\n",
    "def evaluate_model(model, train_data, test_data, adj_matrix=None):\n",
    "    # Prepare the training data\n",
    "    user_indices = train_data['userId'].values\n",
    "    item_indices = train_data['movieId'].values\n",
    "    labels = train_data['rating'].values\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((user_indices, item_indices, labels))\n",
    "    dataset = dataset.shuffle(buffer_size=len(train_data)).batch(256)\n",
    "\n",
    "    # Training loop\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    loss_fn = tf.keras.losses.MeanSquaredError()  \n",
    "\n",
    "    @tf.function\n",
    "    def train_step(user_indices, item_indices, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            if adj_matrix is not None:\n",
    "                scores = model(user_indices, item_indices, adj_matrix)\n",
    "            else:\n",
    "                scores = model(user_indices, item_indices)\n",
    "            loss = loss_fn(labels, scores)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    num_epochs = 10\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in dataset:\n",
    "            user_indices_batch, item_indices_batch, labels_batch = batch\n",
    "            loss = train_step(user_indices_batch, item_indices_batch, labels_batch)\n",
    "        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Evaluating the model\n",
    "    predictions = []\n",
    "\n",
    "    test_user_indices = test_data['user'].values\n",
    "    test_item_indices = test_data['item'].values\n",
    "    test_labels = test_data['rating'].values\n",
    "\n",
    "    for (user_index, item_index, label) in zip(test_user_indices, test_item_indices, test_labels):\n",
    "        user_index_tensor = tf.constant([user_index])\n",
    "        item_index_tensor = tf.constant([item_index])\n",
    "        if adj_matrix is not None:\n",
    "            score = model(user_index_tensor, item_index_tensor, adj_matrix).numpy()[0]\n",
    "        else:\n",
    "            score = model(user_index_tensor, item_index_tensor).numpy()[0]\n",
    "        predictions.append((user_index, item_index, label, score, 0))\n",
    "\n",
    "    return predictions, training_time\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    def get_top_n(predictions, n=10):\n",
    "        top_n = defaultdict(list)\n",
    "        for uid, iid, true_r, est, _ in predictions:\n",
    "            top_n[uid].append((iid, est))\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "            top_n[uid] = user_ratings[:n]\n",
    "        return top_n\n",
    "\n",
    "    def precision_recall_at_k(predictions, k=10, threshold=0.7): \n",
    "        user_est_true = defaultdict(list)\n",
    "        for uid, _, true_r, est, _ in predictions:\n",
    "            user_est_true[uid].append((est, true_r))\n",
    "        precisions = dict()\n",
    "        recalls = dict()\n",
    "        for uid, user_ratings in user_est_true.items():\n",
    "            user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "            n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "            n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "            n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "            precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "            recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "        return precisions, recalls\n",
    "\n",
    "    def compute_rmse(predictions):\n",
    "        mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "        rmse = np.sqrt(mse)\n",
    "        return rmse\n",
    "\n",
    "    def compute_mae(predictions):\n",
    "        mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "        return mae\n",
    "\n",
    "    rmse = compute_rmse(predictions)\n",
    "    mae = compute_mae(predictions)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10)\n",
    "\n",
    "    precision_at_10 = np.mean(list(precisions.values()))\n",
    "    recall_at_10 = np.mean(list(recalls.values()))\n",
    "\n",
    "    return rmse, mae, precision_at_10, recall_at_10\n",
    "\n",
    "# Function to run evaluation for each model and scenario\n",
    "def run_evaluation(model, model_name, train_data, test_data, adj_matrix=None):\n",
    "    predictions, training_time = evaluate_model(model, train_data, test_data, adj_matrix)\n",
    "    rmse, mae, precision_at_10, recall_at_10 = compute_metrics(predictions)\n",
    "    results = pd.DataFrame({\n",
    "        \"Scenario\": [scenario],\n",
    "        \"Algorithm\": [model_name],\n",
    "        \"RMSE\": [rmse],\n",
    "        \"MAE\": [mae],\n",
    "        \"Precision@10\": [precision_at_10],\n",
    "        \"Recall@10\": [recall_at_10],\n",
    "        \"Running Time (s)\": [training_time]\n",
    "    })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ffba12-5b86-4589-b66f-b4d9f9b50943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d968f6c-ae5c-4988-80c2-2588ab4105b9",
   "metadata": {},
   "source": [
    "## LightGCN Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73728330-6635-46a9-be2a-378203b18d56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:31:03.217447: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.28932985663414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:31:04.882563: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0534636490046978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:31:07.520747: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.01657233014702797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:31:09.328605: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.01574024371802807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:31:11.211531: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.04002286493778229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:31:12.985620: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.010989277623593807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:31:14.825036: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.01989801414310932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:31:16.658457: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.01790313608944416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:31:18.456158: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.00961360614746809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:31:20.565704: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.002892544027417898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:32:44.802943: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-22 19:32:44.996401: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.005441933870315552\n",
      "Epoch 1, Loss: 0.0037565233651548624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:32:45.204268: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-07-22 19:32:45.404667: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.0032107247970998287\n",
      "Epoch 3, Loss: 0.002524585695937276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:32:45.630849: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.0008240296156145632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:32:45.840155: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.0012967386282980442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:32:46.075698: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0004003034846391529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:32:46.304455: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0006772354827262461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:32:46.525788: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0005122995935380459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:32:46.770635: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0004288715135771781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:38:47.895628: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.0146847078576684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:38:49.890116: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.008437825366854668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:38:51.835151: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.011311208829283714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:38:53.593727: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.007394261192530394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:38:55.577969: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.007581524085253477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:38:57.926579: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.010632302612066269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:39:00.646273: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.009195016697049141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:39:02.962324: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.004009094089269638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:39:05.855038: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.00395465362817049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:39:07.926802: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0026527103036642075\n"
     ]
    }
   ],
   "source": [
    "# Evaluate LightGCN\n",
    "class LightGCN(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    def call(self, user_indices, item_indices):\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        scores = tf.reduce_sum(user_embeddings * item_embeddings, axis=1)\n",
    "        return scores\n",
    "\n",
    "embedding_dim = 64\n",
    "lightgcn_model = LightGCN(num_users, num_items, embedding_dim)\n",
    "\n",
    "\n",
    "# Evaluate normal scenario\n",
    "scenario = \"Normal\"\n",
    "train_data = ratings.sample(frac=0.8, random_state=42)\n",
    "test_data = ratings.drop(train_data.index)\n",
    "results_lightGCN_normal = run_evaluation(lightgcn_model, \"LightGCN\", train_data, test_data)\n",
    "\n",
    "# Evaluate sparse scenario\n",
    "scenario = \"Sparse\"\n",
    "train_data = get_sparse_data(ratings, frac=0.1)\n",
    "test_data = ratings.drop(train_data.index)\n",
    "results_lightGCN_sparse = run_evaluation(lightgcn_model, \"LightGCN\", train_data, test_data)\n",
    "\n",
    "# Evaluate new user scenario\n",
    "scenario = \"New User\"\n",
    "train_data = get_new_user_data(ratings, frac=0.1)\n",
    "test_data = ratings.drop(train_data.index)\n",
    "results_lightGCN_new_user = run_evaluation(lightgcn_model, \"LightGCN\", train_data, test_data)\n",
    "\n",
    "# Combine LightGCN results into a single DataFrame\n",
    "results_lightGCN_combined = pd.concat([results_lightGCN_normal, results_lightGCN_sparse, results_lightGCN_new_user], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b52effc-e474-4f76-91c7-4fd666fdf8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>0.248914</td>\n",
       "      <td>0.184007</td>\n",
       "      <td>0.670826</td>\n",
       "      <td>0.427905</td>\n",
       "      <td>20.895310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>0.142379</td>\n",
       "      <td>0.091555</td>\n",
       "      <td>0.946684</td>\n",
       "      <td>0.309876</td>\n",
       "      <td>2.923885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>LightGCN</td>\n",
       "      <td>0.151234</td>\n",
       "      <td>0.110233</td>\n",
       "      <td>0.844048</td>\n",
       "      <td>0.594584</td>\n",
       "      <td>23.099947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario Algorithm      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal  LightGCN  0.248914  0.184007      0.670826   0.427905   \n",
       "1    Sparse  LightGCN  0.142379  0.091555      0.946684   0.309876   \n",
       "2  New User  LightGCN  0.151234  0.110233      0.844048   0.594584   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         20.895310  \n",
       "1          2.923885  \n",
       "2         23.099947  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_lightGCN_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bedf164-6977-4289-861a-a2c2dd16e174",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc96032-1d22-4171-9770-97ba4d3541e4",
   "metadata": {},
   "source": [
    "# Graph Attention Network (GAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80dccaa9-c6ec-4a4c-ac3c-10e15b965934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:41:57.120941: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.04164614528417587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:42:15.129184: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.09281927347183228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:42:36.500524: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.048704296350479126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:43:00.014601: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.07605619728565216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:43:39.974912: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.047069624066352844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:43:58.547278: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.06208371743559837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:44:21.376450: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.030390137806534767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:44:49.071506: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.04275280982255936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:45:10.581492: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.032630305737257004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:45:33.375788: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.04514634609222412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:55:38.077915: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.04317385330796242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:55:40.679911: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.04331973195075989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:55:43.115968: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.03145625814795494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:55:45.549496: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.02483309432864189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:55:48.397139: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.028472645208239555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:55:51.121040: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.04274964705109596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:55:54.028474: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.026976875960826874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:55:57.036478: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.0423617921769619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:55:59.775645: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.03205025941133499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 19:56:04.140274: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.02661043405532837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:32:55.267918: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.057373929768800735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:33:19.755149: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.03648923709988594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:33:43.454937: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.02544747292995453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:34:03.873626: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.05476325377821922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:34:23.846139: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.035788439214229584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:34:43.396208: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.06346458941698074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:35:02.985062: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.030774442479014397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:35:22.250132: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.03495458513498306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:35:41.558774: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.04711348935961723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:36:00.952542: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.033315509557724\n"
     ]
    }
   ],
   "source": [
    "# Evaluate GAT\n",
    "class GraphAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, attn_heads=1, dropout_rate=0.0, **kwargs):\n",
    "        super(GraphAttentionLayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.attn_heads = attn_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.attn_kernels = []\n",
    "        self.attn_self_kernels = []\n",
    "\n",
    "        for _ in range(attn_heads):\n",
    "            self.attn_kernels.append(tf.keras.layers.Dense(output_dim, use_bias=False))\n",
    "            self.attn_self_kernels.append(tf.keras.layers.Dense(1, use_bias=False))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features, adj_matrix = inputs\n",
    "        attn_outs = []\n",
    "\n",
    "        for kernel, self_kernel in zip(self.attn_kernels, self.attn_self_kernels):\n",
    "            attn_out = kernel(features)\n",
    "            attn_self = self_kernel(features)\n",
    "            attn_all = tf.add(attn_self, tf.transpose(attn_self))\n",
    "            attn_all = tf.nn.leaky_relu(attn_all)\n",
    "            attn_all = tf.nn.softmax(attn_all, axis=-1)\n",
    "            attn_all = self.dropout(attn_all)\n",
    "            node_features = tf.matmul(attn_all, attn_out)\n",
    "            attn_outs.append(node_features)\n",
    "\n",
    "        return tf.concat(attn_outs, axis=-1)\n",
    "\n",
    "class GATModel(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, attn_heads=1, dropout_rate=0.0):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
    "        self.gat_layer = GraphAttentionLayer(embedding_dim, attn_heads, dropout_rate)\n",
    "\n",
    "    def call(self, user_indices, item_indices, adj_matrix):\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        all_embeddings = tf.concat([user_embeddings, item_embeddings], axis=0)\n",
    "        all_embeddings = self.gat_layer([all_embeddings, adj_matrix])\n",
    "        user_embeddings = all_embeddings[:tf.shape(user_indices)[0]]\n",
    "        item_embeddings = all_embeddings[tf.shape(user_indices)[0]:]\n",
    "        scores = tf.reduce_sum(user_embeddings * item_embeddings, axis=1)\n",
    "        return scores\n",
    "\n",
    "adj_matrix = np.zeros((num_users + num_items, num_users + num_items))\n",
    "for _, row in ratings.iterrows():\n",
    "    user_id = int(row['user'])\n",
    "    item_id = int(row['item']) + num_users\n",
    "    adj_matrix[user_id, item_id] = 1\n",
    "    adj_matrix[item_id, user_id] = 1\n",
    "\n",
    "adj_matrix = tf.convert_to_tensor(adj_matrix, dtype=tf.float32)\n",
    "\n",
    "embedding_dim = 64\n",
    "attn_heads = 8\n",
    "dropout_rate = 0.5\n",
    "gat_model = GATModel(num_users, num_items, embedding_dim, attn_heads, dropout_rate)\n",
    "\n",
    "# Combine results for GAT\n",
    "\n",
    "# Evaluate normal scenario\n",
    "scenario = \"Normal\"\n",
    "train_data = ratings.sample(frac=0.8, random_state=42)\n",
    "test_data = ratings.drop(train_data.index)\n",
    "results_GAT_normal = run_evaluation(gat_model, \"GAT\", train_data, test_data, adj_matrix)\n",
    "\n",
    "# Evaluate sparse scenario\n",
    "scenario = \"Sparse\"\n",
    "train_data = get_sparse_data(ratings, frac=0.1)\n",
    "test_data = ratings.drop(train_data.index)\n",
    "results_GAT_sparse = run_evaluation(gat_model, \"GAT\", train_data, test_data, adj_matrix)\n",
    "\n",
    "# Evaluate new user scenario\n",
    "scenario = \"New User\"\n",
    "train_data = get_new_user_data(ratings, frac=0.1)\n",
    "test_data = ratings.drop(train_data.index)\n",
    "results_GAT_new_user = run_evaluation(gat_model, \"GAT\", train_data, test_data, adj_matrix)\n",
    "\n",
    "# Combine GAT results into a single DataFrame\n",
    "results_GAT_combined = pd.concat([results_GAT_normal, results_GAT_sparse, results_GAT_new_user], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9589534f-9bd5-42f5-aa89-e6698aa21ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>GAT</td>\n",
       "      <td>2.197966</td>\n",
       "      <td>1.591850</td>\n",
       "      <td>0.581629</td>\n",
       "      <td>0.541810</td>\n",
       "      <td>234.961458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>GAT</td>\n",
       "      <td>2.779026</td>\n",
       "      <td>1.968980</td>\n",
       "      <td>0.607473</td>\n",
       "      <td>0.210916</td>\n",
       "      <td>33.093867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>GAT</td>\n",
       "      <td>1.605601</td>\n",
       "      <td>1.060572</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.474437</td>\n",
       "      <td>209.951633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario Algorithm      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal       GAT  2.197966  1.591850      0.581629   0.541810   \n",
       "1    Sparse       GAT  2.779026  1.968980      0.607473   0.210916   \n",
       "2  New User       GAT  1.605601  1.060572      0.614286   0.474437   \n",
       "\n",
       "   Running Time (s)  \n",
       "0        234.961458  \n",
       "1         33.093867  \n",
       "2        209.951633  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_GAT_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb63d5-b62b-4fbf-b57c-51a02556efbf",
   "metadata": {},
   "source": [
    "# GraphSAGE (SAmple and aggreGatE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5385869c-2fcc-4f4a-8b69-fd59bf290f3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:43:35.659895: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.06893366575241089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:45:23.889446: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.08900823444128036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:47:34.639566: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.12095379084348679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:49:57.484678: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0843137726187706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:51:47.706927: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.05222022160887718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:53:35.361876: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.05716760456562042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:55:20.705604: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.0774926245212555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:57:08.923738: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.05163055285811424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 20:58:51.604235: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.05806591734290123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 21:00:32.962941: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.026816928759217262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:31:16.546231: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.0421975702047348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:31:28.935082: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.028855610638856888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:31:41.315727: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.030069472268223763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:31:53.692435: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.024326035752892494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:32:06.996283: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.01785353012382984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:32:18.823266: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.028327492997050285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:32:30.651658: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.019512180238962173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:32:42.434182: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.022672701627016068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:32:54.157859: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.022627104073762894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 22:33:05.761436: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.022172890603542328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 06:07:43.977535: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.03333196043968201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 06:09:36.635938: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.02856939472258091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 06:11:30.918223: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.042769815772771835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 06:13:23.846837: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.03738968074321747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 06:15:17.369917: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.04058655723929405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 06:17:12.636314: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.02843991480767727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 06:19:05.741806: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.03035759925842285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 06:20:59.629750: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.03030986897647381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 06:22:52.686607: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.029295336455106735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 06:24:51.456300: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.026935644447803497\n"
     ]
    }
   ],
   "source": [
    "# Evaluate GraphSAGE\n",
    "class GraphSAGELayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, aggregator_type='mean', dropout_rate=0.0, **kwargs):\n",
    "        super(GraphSAGELayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.aggregator_type = aggregator_type\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dense_self = tf.keras.layers.Dense(output_dim, use_bias=False)\n",
    "        self.dense_neighbor = tf.keras.layers.Dense(output_dim, use_bias=False)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.act = tf.nn.relu\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features, adj_matrix = inputs\n",
    "        if self.aggregator_type == 'mean':\n",
    "            neighbor_features = tf.matmul(adj_matrix, features)\n",
    "            node_features = self.dense_self(features) + self.dense_neighbor(neighbor_features)\n",
    "        elif self.aggregator_type == 'max':\n",
    "            neighbor_features = tf.reduce_max(tf.matmul(adj_matrix, features), axis=1)\n",
    "            node_features = self.dense_self(features) + self.dense_neighbor(neighbor_features)\n",
    "        elif self.aggregator_type == 'lstm':\n",
    "            raise NotImplementedError(\"LSTM aggregator is not implemented in this example.\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown aggregator type: {self.aggregator_type}\")\n",
    "        \n",
    "        node_features = self.act(node_features)\n",
    "        node_features = self.dropout(node_features)\n",
    "        return node_features\n",
    "\n",
    "class GraphSAGEModel(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, aggregator_type='mean', dropout_rate=0.0):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.user_embedding = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
    "        self.graphsage_layer = GraphSAGELayer(embedding_dim, aggregator_type, dropout_rate)\n",
    "\n",
    "    def call(self, user_indices, item_indices, adj_matrix):\n",
    "        user_embeddings = self.user_embedding(user_indices)\n",
    "        item_embeddings = self.item_embedding(item_indices)\n",
    "        all_user_embeddings = self.user_embedding(tf.range(num_users))\n",
    "        all_item_embeddings = self.item_embedding(tf.range(num_items))\n",
    "        all_embeddings = tf.concat([all_user_embeddings, all_item_embeddings], axis=0)\n",
    "        all_embeddings = self.graphsage_layer([all_embeddings, adj_matrix])\n",
    "        user_embeddings = tf.gather(all_embeddings, user_indices)\n",
    "        item_embeddings = tf.gather(all_embeddings, item_indices + num_users)\n",
    "        scores = tf.reduce_sum(user_embeddings * item_embeddings, axis=1)\n",
    "        return scores\n",
    "\n",
    "embedding_dim = 64\n",
    "aggregator_type = 'mean'\n",
    "dropout_rate = 0.5\n",
    "graphsage_model = GraphSAGEModel(num_users, num_items, embedding_dim, aggregator_type, dropout_rate)\n",
    "\n",
    "# Combine results for GraphSAGE\n",
    "\n",
    "# Evaluate normal scenario\n",
    "scenario = \"Normal\"\n",
    "train_data = ratings.sample(frac=0.8, random_state=42)\n",
    "test_data = ratings.drop(train_data.index)\n",
    "results_SAGE_normal = run_evaluation(graphsage_model, \"GraphSAGE\", train_data, test_data, adj_matrix)\n",
    "\n",
    "# Evaluate sparse scenario\n",
    "scenario = \"Sparse\"\n",
    "train_data = get_sparse_data(ratings, frac=0.1)\n",
    "test_data = ratings.drop(train_data.index)\n",
    "results_SAGE_sparse = run_evaluation(graphsage_model, \"GraphSAGE\", train_data, test_data, adj_matrix)\n",
    "\n",
    "# Evaluate new user scenario\n",
    "scenario = \"New User\"\n",
    "train_data = get_new_user_data(ratings, frac=0.1)\n",
    "test_data = ratings.drop(train_data.index)\n",
    "results_SAGE_new_user = run_evaluation(graphsage_model, \"GraphSAGE\", train_data, test_data, adj_matrix)\n",
    "\n",
    "# Combine GraphSAGE results into a single DataFrame\n",
    "results_SAGE_combined = pd.concat([results_SAGE_normal, results_SAGE_sparse, results_SAGE_new_user], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85832223-0e5e-4cd1-97b3-0dc5de0df35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>0.233555</td>\n",
       "      <td>0.180065</td>\n",
       "      <td>0.650521</td>\n",
       "      <td>0.443586</td>\n",
       "      <td>1135.601531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>0.227016</td>\n",
       "      <td>0.176313</td>\n",
       "      <td>0.774862</td>\n",
       "      <td>0.230562</td>\n",
       "      <td>123.121829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>GraphSAGE</td>\n",
       "      <td>0.421851</td>\n",
       "      <td>0.375382</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>1141.266339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario  Algorithm      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal  GraphSAGE  0.233555  0.180065      0.650521   0.443586   \n",
       "1    Sparse  GraphSAGE  0.227016  0.176313      0.774862   0.230562   \n",
       "2  New User  GraphSAGE  0.421851  0.375382      0.142857   0.007143   \n",
       "\n",
       "   Running Time (s)  \n",
       "0       1135.601531  \n",
       "1        123.121829  \n",
       "2       1141.266339  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_SAGE_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdc7c59-ca00-4e09-ba88-9ba202175e27",
   "metadata": {},
   "source": [
    "# Hypergraph-based Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a58d20-1107-45b8-a49a-12fde2eaf858",
   "metadata": {},
   "source": [
    "### For the hypergraph-based models, we have implemented 2 algorithms: HyperGCN which an extension of Graph Convolution Network on Hypergraphs and Node2Vec algorithm. \n",
    "\n",
    "This part gather all the code thaat the 2 algoriithms have in commun notably the construction of the hypergraph with hyperedge users who has given the same rating on a movie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c4c2303-3f02-44bb-bb44-4197eae74aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 20:36:28.175221: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypergraph created with 9593 nodes and 26961 edges.\n",
      "Number of nodes in hypergraph: 9593\n",
      "Sample nodes: ['user_509.0', 'movie_7347.0', 'user_380.0', 'user_274.0', 'user_474.0']\n",
      "Adjacency matrix created with shape (9593, 9593)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import hypernetx as hnx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Normalize ratings\n",
    "scaler = MinMaxScaler()\n",
    "ratings_df['rating'] = scaler.fit_transform(ratings_df[['rating']])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train, test = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the hypergraph\n",
    "edges = defaultdict(list)\n",
    "for _, row in train.iterrows():\n",
    "    user_node = f'user_{row[\"userId\"]}'\n",
    "    movie_node = f'movie_{row[\"movieId\"]}'\n",
    "    rating = row[\"rating\"]\n",
    "    hyperedge = f'{movie_node}_rating_{rating}'\n",
    "    edges[hyperedge].append(user_node)\n",
    "    edges[hyperedge].append(movie_node)\n",
    "\n",
    "H = hnx.Hypergraph(edges)\n",
    "print(f\"Hypergraph created with {len(H.nodes)} nodes and {len(H.edges)} edges.\")\n",
    "print(f\"Number of nodes in hypergraph: {len(H.nodes)}\")\n",
    "print(f\"Sample nodes: {list(H.nodes)[:5]}\")\n",
    "\n",
    "sparse_data = get_sparse_data(ratings_df)\n",
    "new_user_data = get_new_user_data(ratings_df)\n",
    "\n",
    "# Create adjacency matrix for hypergraph\n",
    "def create_hypergraph_adjacency_matrix(hypergraph):\n",
    "    node_list = list(hypergraph.nodes)\n",
    "    node_idx = {node: idx for idx, node in enumerate(node_list)}\n",
    "    n = len(node_list)\n",
    "    \n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "\n",
    "    for edge in hypergraph.edges:\n",
    "        edge_nodes = list(hypergraph.edges[edge])\n",
    "        for i in range(len(edge_nodes)):\n",
    "            for j in range(i + 1, len(edge_nodes)):\n",
    "                node_i = node_idx[edge_nodes[i]]\n",
    "                node_j = node_idx[edge_nodes[j]]\n",
    "                data.append(1)\n",
    "                row.append(node_i)\n",
    "                col.append(node_j)\n",
    "                data.append(1)\n",
    "                row.append(node_j)\n",
    "                col.append(node_i)\n",
    "\n",
    "    adj_matrix = csr_matrix((data, (row, col)), shape=(n, n))\n",
    "    print(f\"Adjacency matrix created with shape {adj_matrix.shape}\")\n",
    "    return adj_matrix, node_idx\n",
    "\n",
    "adj_matrix, node_to_idx = create_hypergraph_adjacency_matrix(H)\n",
    "adj_matrix_sparse = tf.sparse.SparseTensor(indices=np.array([adj_matrix.nonzero()[0], adj_matrix.nonzero()[1]]).T,\n",
    "                                           values=adj_matrix.data.astype(np.float32),\n",
    "                                           dense_shape=adj_matrix.shape)\n",
    "adj_matrix_sparse = tf.sparse.reorder(adj_matrix_sparse)\n",
    "\n",
    "\n",
    "# Evaluation metrics functions\n",
    "def precision_recall_at_k(predictions, k=10, threshold=0.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold)) for (est, true_r) in user_ratings[:k])\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    return precisions, recalls\n",
    "\n",
    "def compute_rmse(predictions):\n",
    "    mse = np.mean([(true_r - est) ** 2 for (_, _, true_r, est, _) in predictions])\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def compute_mae(predictions):\n",
    "    mae = np.mean([abs(true_r - est) for (_, _, true_r, est, _) in predictions])\n",
    "    return mae\n",
    "\n",
    "# Functions to generate sparse and new user data\n",
    "def get_sparse_data(ratings, frac=0.1):\n",
    "    sparse_ratings_df = ratings.sample(frac=frac, random_state=42) \n",
    "    return sparse_ratings_df\n",
    "\n",
    "def get_new_user_data(ratings, frac=0.1):\n",
    "    new_user_ratings_df = ratings[ratings['userId'].isin(ratings['userId'].sample(frac=frac, random_state=42))]\n",
    "    return new_user_ratings_df\n",
    "\n",
    "def evaluate_model(test, embeddings, user_mapping, movie_mapping, scenario, algorithm):\n",
    "    def predict_rating(user, movie):\n",
    "        if user in user_mapping and movie in movie_mapping:\n",
    "            user_idx = user_mapping[user]\n",
    "            movie_idx = movie_mapping[movie]\n",
    "            if user_idx >= embeddings.shape[0] or movie_idx >= embeddings.shape[0]:\n",
    "                return 0\n",
    "            user_emb = embeddings[user_idx]\n",
    "            movie_emb = embeddings[movie_idx]\n",
    "            return np.dot(user_emb, movie_emb)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    predictions = []\n",
    "    for _, row in test.iterrows():\n",
    "        uid = row['userId']\n",
    "        mid = row['movieId']\n",
    "        true_r = row['rating']\n",
    "        est = predict_rating(uid, mid)\n",
    "        predictions.append((uid, mid, true_r, est, None))\n",
    "\n",
    "    rmse = compute_rmse(predictions)\n",
    "    mae = compute_mae(predictions)\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=10)\n",
    "\n",
    "    avg_precision = np.mean(list(precisions.values()))\n",
    "    avg_recall = np.mean(list(recalls.values()))\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Scenario': [scenario],\n",
    "        'Algorithm': [algorithm],\n",
    "        'RMSE': [rmse],\n",
    "        'MAE': [mae],\n",
    "        'Precision@10': [avg_precision],\n",
    "        'Recall@10': [avg_recall]\n",
    "    })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f808172-5ced-4177-87fc-f559bddcd6a3",
   "metadata": {},
   "source": [
    "# HyperGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b50f889b-2c49-45d7-9bd0-4932e541eea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 80668 negative samples\n",
      "Number of positive samples: 80668\n",
      "Number of negative samples: 80668\n",
      "Epoch 0, Loss: 0.999934732913971\n",
      "Epoch 10, Loss: 0.9869195818901062\n",
      "Epoch 20, Loss: 0.9526710510253906\n",
      "Epoch 30, Loss: 0.8124383091926575\n",
      "Epoch 40, Loss: 0.3995513319969177\n",
      "Epoch 50, Loss: 0.1945350468158722\n",
      "Epoch 60, Loss: 0.11867774277925491\n",
      "Epoch 70, Loss: 0.07247839868068695\n",
      "Epoch 80, Loss: 0.04291127249598503\n",
      "Epoch 90, Loss: 0.024636704474687576\n",
      "Epoch 100, Loss: 0.013938989490270615\n",
      "Epoch 110, Loss: 0.007689888123422861\n",
      "Epoch 120, Loss: 0.004110455513000488\n",
      "Epoch 130, Loss: 0.0021072046365588903\n",
      "Epoch 140, Loss: 0.001034366781823337\n",
      "Epoch 150, Loss: 0.00048456471995450556\n",
      "Epoch 160, Loss: 0.000214907675399445\n",
      "Epoch 170, Loss: 8.409914880758151e-05\n",
      "Epoch 180, Loss: 2.6276418793713674e-05\n",
      "Epoch 190, Loss: 5.5467430684075225e-06\n",
      "Generated 10084 negative samples\n",
      "Number of positive samples: 10084\n",
      "Number of negative samples: 10084\n",
      "Epoch 0, Loss: 1.0000203847885132\n",
      "Epoch 10, Loss: 0.9629374742507935\n",
      "Epoch 20, Loss: 0.9039987921714783\n",
      "Epoch 30, Loss: 0.7962945103645325\n",
      "Epoch 40, Loss: 0.6041403412818909\n",
      "Epoch 50, Loss: 0.30666136741638184\n",
      "Epoch 60, Loss: 0.06330166757106781\n",
      "Epoch 70, Loss: 0.0042687528766691685\n",
      "Epoch 80, Loss: 0.0001899382477859035\n",
      "Epoch 90, Loss: 0.0\n",
      "Epoch 100, Loss: 0.0\n",
      "Epoch 110, Loss: 0.0\n",
      "Epoch 120, Loss: 0.0\n",
      "Epoch 130, Loss: 0.0\n",
      "Epoch 140, Loss: 0.0\n",
      "Epoch 150, Loss: 0.0\n",
      "Epoch 160, Loss: 0.0\n",
      "Epoch 170, Loss: 0.0\n",
      "Epoch 180, Loss: 0.0\n",
      "Epoch 190, Loss: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/js5nvmg90d37xtyx33clr3th0000gn/T/ipykernel_1043/2591200080.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_idx'] = train['userId'].map(user_mapping)\n",
      "/var/folders/dr/js5nvmg90d37xtyx33clr3th0000gn/T/ipykernel_1043/2591200080.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['movie_idx'] = train['movieId'].map(movie_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100654 negative samples\n",
      "Number of positive samples: 100654\n",
      "Number of negative samples: 100654\n",
      "Epoch 0, Loss: 1.0000200271606445\n",
      "Epoch 10, Loss: 0.9884659051895142\n",
      "Epoch 20, Loss: 0.9515051245689392\n",
      "Epoch 30, Loss: 0.7592405676841736\n",
      "Epoch 40, Loss: 0.3240206837654114\n",
      "Epoch 50, Loss: 0.1749018430709839\n",
      "Epoch 60, Loss: 0.11328203231096268\n",
      "Epoch 70, Loss: 0.07312606275081635\n",
      "Epoch 80, Loss: 0.04645015299320221\n",
      "Epoch 90, Loss: 0.028919674456119537\n",
      "Epoch 100, Loss: 0.017635205760598183\n",
      "Epoch 110, Loss: 0.010489451698958874\n",
      "Epoch 120, Loss: 0.006125546991825104\n",
      "Epoch 130, Loss: 0.0034394057001918554\n",
      "Epoch 140, Loss: 0.001914128428325057\n",
      "Epoch 150, Loss: 0.001048172009177506\n",
      "Epoch 160, Loss: 0.0005439634551294148\n",
      "Epoch 170, Loss: 0.0002834537881426513\n",
      "Epoch 180, Loss: 0.00014076723891776055\n",
      "Epoch 190, Loss: 6.63048485876061e-05\n"
     ]
    }
   ],
   "source": [
    "class ImprovedHyperGCN(tf.keras.Model):\n",
    "    def __init__(self, num_nodes, num_features, hidden_dims, output_dim, dropout_rate):\n",
    "        super(ImprovedHyperGCN, self).__init__()\n",
    "        self.embedding = layers.Embedding(num_nodes, num_features)\n",
    "        self.hidden_layers = [layers.Dense(dim, activation='relu', kernel_regularizer=regularizers.l2(0.01)) for dim in hidden_dims]\n",
    "        self.output_layer = layers.Dense(output_dim, activation='linear')\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, adj_matrix):\n",
    "        x = self.embedding(tf.range(adj_matrix.shape[0]))\n",
    "        x = tf.sparse.sparse_dense_matmul(adj_matrix, x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "def train_hypergcn_model(H, train, test, scenario):\n",
    "    user_ids = train['userId'].unique()\n",
    "    movie_ids = train['movieId'].unique()\n",
    "\n",
    "    user_mapping = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    movie_mapping = {movie_id: idx + len(user_ids) for idx, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "    train['user_idx'] = train['userId'].map(user_mapping)\n",
    "    train['movie_idx'] = train['movieId'].map(movie_mapping)\n",
    "\n",
    "    test['user_idx'] = test['userId'].map(user_mapping)\n",
    "    test['movie_idx'] = test['movieId'].map(movie_mapping)\n",
    "\n",
    "    num_nodes = len(user_ids) + len(movie_ids)\n",
    "    num_features = 128\n",
    "    hidden_dims = [256, 128]\n",
    "    output_dim = 1\n",
    "    dropout_rate = 0.5\n",
    "\n",
    "    model = ImprovedHyperGCN(num_nodes, num_features, hidden_dims, output_dim, dropout_rate)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "    def pairwise_hinge_loss(positive_scores, negative_scores, margin=1.0):\n",
    "        return tf.reduce_mean(tf.maximum(0.0, margin - positive_scores + negative_scores))\n",
    "\n",
    "    def improved_sample_negative_edges(train_df, user_mapping, movie_mapping, num_neg_samples):\n",
    "        users = train_df['userId'].unique()\n",
    "        movies = train_df['movieId'].unique()\n",
    "        positive_samples = train_df[['userId', 'movieId']].values\n",
    "        positive_samples_set = set((user_mapping[user], movie_mapping[movie]) for user, movie in positive_samples)\n",
    "        \n",
    "        neg_samples = []\n",
    "        while len(neg_samples) < num_neg_samples:\n",
    "            user = np.random.choice(users)\n",
    "            user_idx = user_mapping[user]\n",
    "            negative_movies = np.setdiff1d(movies, train_df[train_df['userId'] == user]['movieId'].values)\n",
    "            neg_movie = np.random.choice(negative_movies)\n",
    "            neg_movie_idx = movie_mapping[neg_movie]\n",
    "            if (user_idx, neg_movie_idx) not in positive_samples_set:\n",
    "                neg_samples.append((user_idx, neg_movie_idx))\n",
    "        \n",
    "        neg_df = pd.DataFrame(neg_samples, columns=['user_idx', 'movie_idx'])\n",
    "        print(f\"Generated {len(neg_df)} negative samples\")\n",
    "        return neg_df\n",
    "\n",
    "    positive_samples = train[['user_idx', 'movie_idx']]\n",
    "    neg_train_samples = improved_sample_negative_edges(train, user_mapping, movie_mapping, num_neg_samples=len(positive_samples))\n",
    "    print(f\"Number of positive samples: {len(positive_samples)}\")\n",
    "    print(f\"Number of negative samples: {len(neg_train_samples)}\")\n",
    "\n",
    "    epochs = 200\n",
    "    batch_size = 256\n",
    "\n",
    "    def train_step(model, adj_matrix, optimizer, positive_samples, negative_samples):\n",
    "        with tf.GradientTape() as tape:\n",
    "            positive_user_embeddings = model.embedding(positive_samples['user_idx'].values)\n",
    "            positive_movie_embeddings = model.embedding(positive_samples['movie_idx'].values)\n",
    "            negative_user_embeddings = model.embedding(negative_samples['user_idx'].values)\n",
    "            negative_movie_embeddings = model.embedding(negative_samples['movie_idx'].values)\n",
    "\n",
    "            positive_scores = tf.reduce_sum(positive_user_embeddings * positive_movie_embeddings, axis=1)\n",
    "            negative_scores = tf.reduce_sum(negative_user_embeddings * negative_movie_embeddings, axis=1)\n",
    "\n",
    "            loss = pairwise_hinge_loss(positive_scores, negative_scores)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        loss = train_step(model, adj_matrix_sparse, optimizer, positive_samples, neg_train_samples)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n",
    "\n",
    "    end_time = time.time()\n",
    "    embeddings = model.embedding(tf.range(num_nodes)).numpy()\n",
    "\n",
    "    results = evaluate_model(test, embeddings, user_mapping, movie_mapping, scenario, \"HyperGCN\")\n",
    "    results['Running Time (s)'] = end_time - start_time\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate HyperGCN model for different scenarios\n",
    "results_hypergcn_normal = train_hypergcn_model(H, train, test, \"Normal\")\n",
    "results_hypergcn_sparse = train_hypergcn_model(H, sparse_data, test, \"Sparse\")\n",
    "results_hypergcn_new_user = train_hypergcn_model(H, new_user_data, test, \"New User\")\n",
    "\n",
    "# Combine HyperGCN results into a single DataFrame\n",
    "results_hypergcn_combined = pd.concat([results_hypergcn_normal, results_hypergcn_sparse, results_hypergcn_new_user], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09490097-9144-4ca8-833e-38e4dff410bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>HyperGCN</td>\n",
       "      <td>1.348297</td>\n",
       "      <td>1.068175</td>\n",
       "      <td>0.866068</td>\n",
       "      <td>0.516942</td>\n",
       "      <td>76.816076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>HyperGCN</td>\n",
       "      <td>0.586816</td>\n",
       "      <td>0.491858</td>\n",
       "      <td>0.812171</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>16.090587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>HyperGCN</td>\n",
       "      <td>1.832062</td>\n",
       "      <td>1.540105</td>\n",
       "      <td>0.865797</td>\n",
       "      <td>0.606913</td>\n",
       "      <td>94.246901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario Algorithm      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal  HyperGCN  1.348297  1.068175      0.866068   0.516942   \n",
       "1    Sparse  HyperGCN  0.586816  0.491858      0.812171   0.343434   \n",
       "2  New User  HyperGCN  1.832062  1.540105      0.865797   0.606913   \n",
       "\n",
       "   Running Time (s)  \n",
       "0         76.816076  \n",
       "1         16.090587  \n",
       "2         94.246901  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_hypergcn_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14958d1b-ad69-451e-8d87-7ed68752f64d",
   "metadata": {},
   "source": [
    "# Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5bd48235-aaa3-4938-bac0-2e811bb0a2a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random walks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random walks generation completed.\n",
      "Starting model training...\n",
      "Epoch 1/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.0014 - loss: 2365155.5000\n",
      "Epoch 2/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 2346714.0000\n",
      "Epoch 3/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 2304159.7500\n",
      "Epoch 4/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 2129557.2500\n",
      "Epoch 5/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 2310509.7500\n",
      "Epoch 6/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 2206428.2500\n",
      "Epoch 7/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 2121127.7500\n",
      "Epoch 8/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 2339558.2500\n",
      "Epoch 9/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 2141600.7500\n",
      "Epoch 10/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 2026027.8750\n",
      "Epoch 11/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1899123.7500\n",
      "Epoch 12/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 2105192.2500\n",
      "Epoch 13/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1895421.8750\n",
      "Epoch 14/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1764793.3750\n",
      "Epoch 15/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1946490.0000\n",
      "Epoch 16/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1730412.2500\n",
      "Epoch 17/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1758271.1250\n",
      "Epoch 18/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1601400.7500\n",
      "Epoch 19/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1634851.0000\n",
      "Epoch 20/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1780603.6250\n",
      "Epoch 21/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1543404.0000\n",
      "Epoch 22/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1656589.5000\n",
      "Epoch 23/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 1634803.3750\n",
      "Epoch 24/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.0000e+00 - loss: 1721184.0000\n",
      "Epoch 25/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 1645148.6250\n",
      "Epoch 26/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 1657901.8750\n",
      "Epoch 27/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.0000e+00 - loss: 1510997.3750\n",
      "Epoch 28/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1561448.2500\n",
      "Epoch 29/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1672689.7500\n",
      "Epoch 30/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1583340.5000\n",
      "Epoch 31/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1648790.8750\n",
      "Epoch 32/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1707828.6250\n",
      "Epoch 33/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1726389.3750\n",
      "Epoch 34/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1697431.5000\n",
      "Epoch 35/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1646773.8750\n",
      "Epoch 36/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1669238.8750\n",
      "Epoch 37/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1600776.7500\n",
      "Epoch 38/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1680639.3750\n",
      "Epoch 39/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1592601.3750\n",
      "Epoch 40/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1646424.3750\n",
      "Epoch 41/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1560918.2500\n",
      "Epoch 42/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1712232.1250\n",
      "Epoch 43/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1522728.6250\n",
      "Epoch 44/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1679369.3750\n",
      "Epoch 45/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1570005.5000\n",
      "Epoch 46/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1578501.7500\n",
      "Epoch 47/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1487772.6250\n",
      "Epoch 48/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.0000e+00 - loss: 1765213.8750\n",
      "Epoch 49/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1524785.5000\n",
      "Epoch 50/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1512184.6250\n",
      "Epoch 51/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1598834.0000\n",
      "Epoch 52/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1484567.0000\n",
      "Epoch 53/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1556840.3750\n",
      "Epoch 54/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 1702640.7500\n",
      "Epoch 55/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1675934.0000\n",
      "Epoch 56/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1651588.5000\n",
      "Epoch 57/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1667477.0000\n",
      "Epoch 58/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1481372.2500\n",
      "Epoch 59/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1611177.1250\n",
      "Epoch 60/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1583493.6250\n",
      "Epoch 61/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1586243.3750\n",
      "Epoch 62/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1660696.2500\n",
      "Epoch 63/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1576014.8750\n",
      "Epoch 64/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1615374.1250\n",
      "Epoch 65/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1619703.2500\n",
      "Epoch 66/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1535655.0000\n",
      "Epoch 67/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1626719.5000\n",
      "Epoch 68/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1546926.5000\n",
      "Epoch 69/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1588497.3750\n",
      "Epoch 70/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1672100.6250\n",
      "Epoch 71/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1498773.2500\n",
      "Epoch 72/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1641746.7500\n",
      "Epoch 73/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1461585.5000\n",
      "Epoch 74/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1508717.5000\n",
      "Epoch 75/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1549068.6250\n",
      "Epoch 76/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1544466.2500\n",
      "Epoch 77/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1559993.5000\n",
      "Epoch 78/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1563704.3750\n",
      "Epoch 79/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1582220.1250\n",
      "Epoch 80/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1587085.6250\n",
      "Epoch 81/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1561387.7500\n",
      "Epoch 82/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1500671.1250\n",
      "Epoch 83/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1515898.7500\n",
      "Epoch 84/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1566332.7500\n",
      "Epoch 85/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1506836.8750\n",
      "Epoch 86/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1616686.7500\n",
      "Epoch 87/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1596601.1250\n",
      "Epoch 88/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1682470.7500\n",
      "Epoch 89/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1595605.0000\n",
      "Epoch 90/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1602531.5000\n",
      "Epoch 91/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1610383.5000\n",
      "Epoch 92/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1675975.1250\n",
      "Epoch 93/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1543074.7500\n",
      "Epoch 94/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1538818.5000\n",
      "Epoch 95/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1422058.3750\n",
      "Epoch 96/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1603008.2500\n",
      "Epoch 97/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1527102.0000\n",
      "Epoch 98/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1508494.2500\n",
      "Epoch 99/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1542391.6250\n",
      "Epoch 100/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1479775.8750\n",
      "Epoch 101/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1526946.3750\n",
      "Epoch 102/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1625448.1250\n",
      "Epoch 103/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1593443.8750\n",
      "Epoch 104/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1487483.1250\n",
      "Epoch 105/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1447236.1250\n",
      "Epoch 106/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1513321.0000\n",
      "Epoch 107/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1478206.0000\n",
      "Epoch 108/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1526317.5000\n",
      "Epoch 109/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1573859.1250\n",
      "Epoch 110/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1533948.3750\n",
      "Epoch 111/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1481755.1250\n",
      "Epoch 112/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1546035.2500\n",
      "Epoch 113/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1592511.5000\n",
      "Epoch 114/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1498004.7500\n",
      "Epoch 115/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1474254.7500\n",
      "Epoch 116/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1529361.1250\n",
      "Epoch 117/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1500722.0000\n",
      "Epoch 118/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1512909.0000\n",
      "Epoch 119/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1568783.0000\n",
      "Epoch 120/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1512684.3750\n",
      "Epoch 121/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1519160.1250\n",
      "Epoch 122/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1460670.7500\n",
      "Epoch 123/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1487046.2500\n",
      "Epoch 124/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1489406.1250\n",
      "Epoch 125/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1527510.7500\n",
      "Epoch 126/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1431919.5000\n",
      "Epoch 127/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1529447.7500\n",
      "Epoch 128/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1449987.5000\n",
      "Epoch 129/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1368321.7500\n",
      "Epoch 130/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1441702.1250\n",
      "Epoch 131/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1514837.1250\n",
      "Epoch 132/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1536304.1250\n",
      "Epoch 133/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1419732.1250\n",
      "Epoch 134/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1601978.7500\n",
      "Epoch 135/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1470265.8750\n",
      "Epoch 136/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1404885.1250\n",
      "Epoch 137/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1411318.2500\n",
      "Epoch 138/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1551305.2500\n",
      "Epoch 139/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1490824.1250\n",
      "Epoch 140/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1367617.6250\n",
      "Epoch 141/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1438174.6250\n",
      "Epoch 142/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1489128.0000\n",
      "Epoch 143/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1529851.8750\n",
      "Epoch 144/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1379967.6250\n",
      "Epoch 145/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1476192.2500\n",
      "Epoch 146/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1521622.5000\n",
      "Epoch 147/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1425877.6250\n",
      "Epoch 148/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1398795.3750\n",
      "Epoch 149/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1441258.0000\n",
      "Epoch 150/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1402679.1250\n",
      "Epoch 151/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1407160.8750\n",
      "Epoch 152/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1460550.7500\n",
      "Epoch 153/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1369941.7500\n",
      "Epoch 154/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1571154.3750\n",
      "Epoch 155/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1401006.3750\n",
      "Epoch 156/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1473790.0000\n",
      "Epoch 157/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1419809.0000\n",
      "Epoch 158/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1433588.1250\n",
      "Epoch 159/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1428257.7500\n",
      "Epoch 160/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1344683.2500\n",
      "Epoch 161/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1456021.0000\n",
      "Epoch 162/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1424177.8750\n",
      "Epoch 163/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1377698.8750\n",
      "Epoch 164/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1392470.8750\n",
      "Epoch 165/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1351526.5000\n",
      "Epoch 166/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1382401.7500\n",
      "Epoch 167/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1334031.8750\n",
      "Epoch 168/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1418799.7500\n",
      "Epoch 169/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1369337.2500\n",
      "Epoch 170/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1374465.0000\n",
      "Epoch 171/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1323749.6250\n",
      "Epoch 172/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1391672.2500\n",
      "Epoch 173/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1382577.5000\n",
      "Epoch 174/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1341587.1250\n",
      "Epoch 175/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1454763.1250\n",
      "Epoch 176/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1308990.1250\n",
      "Epoch 177/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1463972.2500\n",
      "Epoch 178/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1374124.7500\n",
      "Epoch 179/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1398978.5000\n",
      "Epoch 180/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1402852.7500\n",
      "Epoch 181/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1319774.5000\n",
      "Epoch 182/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1367762.0000\n",
      "Epoch 183/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1411325.3750\n",
      "Epoch 184/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1218698.8750\n",
      "Epoch 185/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1377676.3750\n",
      "Epoch 186/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1295104.0000\n",
      "Epoch 187/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1328949.7500\n",
      "Epoch 188/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1270940.5000\n",
      "Epoch 189/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1467170.5000\n",
      "Epoch 190/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1255120.5000\n",
      "Epoch 191/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1355331.3750\n",
      "Epoch 192/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1313045.1250\n",
      "Epoch 193/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1434047.2500\n",
      "Epoch 194/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1275367.0000\n",
      "Epoch 195/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1311196.2500\n",
      "Epoch 196/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1313682.5000\n",
      "Epoch 197/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1275851.6250\n",
      "Epoch 198/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1258674.2500\n",
      "Epoch 199/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1439738.6250\n",
      "Epoch 200/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1390332.5000\n",
      "Training completed in 143.92 seconds\n",
      "Generating random walks...\n",
      "Random walks generation completed.\n",
      "Starting model training...\n",
      "Epoch 1/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.0013 - loss: 2358493.2500\n",
      "Epoch 2/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 2355900.5000\n",
      "Epoch 3/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 2255146.7500\n",
      "Epoch 4/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 2233573.7500\n",
      "Epoch 5/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 2463426.2500\n",
      "Epoch 6/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 2175879.0000\n",
      "Epoch 7/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 2133571.7500\n",
      "Epoch 8/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 2157277.2500\n",
      "Epoch 9/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 2141318.5000\n",
      "Epoch 10/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 2054794.5000\n",
      "Epoch 11/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 2110187.0000\n",
      "Epoch 12/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1897886.8750\n",
      "Epoch 13/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1771343.8750\n",
      "Epoch 14/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1782565.5000\n",
      "Epoch 15/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1602201.0000\n",
      "Epoch 16/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1644941.2500\n",
      "Epoch 17/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1719043.6250\n",
      "Epoch 18/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1627979.2500\n",
      "Epoch 19/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1579441.0000\n",
      "Epoch 20/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.0000e+00 - loss: 1719540.2500\n",
      "Epoch 21/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1709885.7500\n",
      "Epoch 22/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1604579.5000\n",
      "Epoch 23/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1660655.2500\n",
      "Epoch 24/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1685489.8750\n",
      "Epoch 25/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1605635.8750\n",
      "Epoch 26/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1629238.8750\n",
      "Epoch 27/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1638578.1250\n",
      "Epoch 28/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1646971.0000\n",
      "Epoch 29/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1593412.8750\n",
      "Epoch 30/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1650004.6250\n",
      "Epoch 31/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1529585.6250\n",
      "Epoch 32/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1611331.1250\n",
      "Epoch 33/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1653637.3750\n",
      "Epoch 34/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1622508.0000\n",
      "Epoch 35/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1588933.2500\n",
      "Epoch 36/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 1710534.5000\n",
      "Epoch 37/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1559101.8750\n",
      "Epoch 38/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 1651096.6250\n",
      "Epoch 39/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1671498.0000\n",
      "Epoch 40/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1733347.6250\n",
      "Epoch 41/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1581910.0000\n",
      "Epoch 42/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1647652.2500\n",
      "Epoch 43/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1640332.5000\n",
      "Epoch 44/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1584679.2500\n",
      "Epoch 45/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1554645.8750\n",
      "Epoch 46/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1730859.0000\n",
      "Epoch 47/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1516067.1250\n",
      "Epoch 48/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1562049.3750\n",
      "Epoch 49/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1686464.6250\n",
      "Epoch 50/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1478475.5000\n",
      "Epoch 51/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1621154.5000\n",
      "Epoch 52/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1613187.6250\n",
      "Epoch 53/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1469073.2500\n",
      "Epoch 54/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1593109.6250\n",
      "Epoch 55/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1510855.5000\n",
      "Epoch 56/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1560995.7500\n",
      "Epoch 57/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1734054.3750\n",
      "Epoch 58/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1604182.0000\n",
      "Epoch 59/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1433409.3750\n",
      "Epoch 60/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1554023.0000\n",
      "Epoch 61/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1483649.7500\n",
      "Epoch 62/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1582978.8750\n",
      "Epoch 63/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1564199.5000\n",
      "Epoch 64/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1517310.8750\n",
      "Epoch 65/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1676348.6250\n",
      "Epoch 66/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1626293.1250\n",
      "Epoch 67/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1608360.6250\n",
      "Epoch 68/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1620836.2500\n",
      "Epoch 69/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1531217.7500\n",
      "Epoch 70/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1536810.0000\n",
      "Epoch 71/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1576297.8750\n",
      "Epoch 72/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1641160.2500\n",
      "Epoch 73/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1558640.0000\n",
      "Epoch 74/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1571338.1250\n",
      "Epoch 75/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1543259.1250\n",
      "Epoch 76/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1491870.1250\n",
      "Epoch 77/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1669227.0000\n",
      "Epoch 78/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1553047.5000\n",
      "Epoch 79/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1716202.6250\n",
      "Epoch 80/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1496384.0000\n",
      "Epoch 81/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1476075.5000\n",
      "Epoch 82/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1594782.6250\n",
      "Epoch 83/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1587940.7500\n",
      "Epoch 84/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1549115.7500\n",
      "Epoch 85/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1549896.1250\n",
      "Epoch 86/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1422375.2500\n",
      "Epoch 87/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1584402.3750\n",
      "Epoch 88/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1589724.3750\n",
      "Epoch 89/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1553900.7500\n",
      "Epoch 90/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1550133.2500\n",
      "Epoch 91/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1522407.6250\n",
      "Epoch 92/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1596891.0000\n",
      "Epoch 93/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1435774.1250\n",
      "Epoch 94/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1571508.8750\n",
      "Epoch 95/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1480770.7500\n",
      "Epoch 96/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1534643.6250\n",
      "Epoch 97/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1691730.6250\n",
      "Epoch 98/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1652859.1250\n",
      "Epoch 99/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1446260.6250\n",
      "Epoch 100/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1594633.0000\n",
      "Epoch 101/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1654556.0000\n",
      "Epoch 102/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1402443.6250\n",
      "Epoch 103/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1528437.6250\n",
      "Epoch 104/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1422167.2500\n",
      "Epoch 105/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1455997.6250\n",
      "Epoch 106/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1521363.5000\n",
      "Epoch 107/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1539954.2500\n",
      "Epoch 108/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1569124.0000\n",
      "Epoch 109/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1454481.0000\n",
      "Epoch 110/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1533353.3750\n",
      "Epoch 111/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1487383.7500\n",
      "Epoch 112/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1496377.2500\n",
      "Epoch 113/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1550169.1250\n",
      "Epoch 114/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1547848.2500\n",
      "Epoch 115/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1464815.7500\n",
      "Epoch 116/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1385384.0000\n",
      "Epoch 117/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1465802.5000\n",
      "Epoch 118/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1406758.7500\n",
      "Epoch 119/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1560930.2500\n",
      "Epoch 120/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1547023.1250\n",
      "Epoch 121/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1417654.2500\n",
      "Epoch 122/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1532123.7500\n",
      "Epoch 123/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1417772.6250\n",
      "Epoch 124/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1455159.8750\n",
      "Epoch 125/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1502587.3750\n",
      "Epoch 126/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1548442.1250\n",
      "Epoch 127/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1451348.6250\n",
      "Epoch 128/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1469835.7500\n",
      "Epoch 129/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1388068.3750\n",
      "Epoch 130/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1514697.1250\n",
      "Epoch 131/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1528298.5000\n",
      "Epoch 132/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1393949.6250\n",
      "Epoch 133/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1443897.8750\n",
      "Epoch 134/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1384543.2500\n",
      "Epoch 135/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1515241.0000\n",
      "Epoch 136/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1556769.2500\n",
      "Epoch 137/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1405143.1250\n",
      "Epoch 138/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1537030.3750\n",
      "Epoch 139/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1548166.5000\n",
      "Epoch 140/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1534936.6250\n",
      "Epoch 141/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1394959.3750\n",
      "Epoch 142/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1577606.1250\n",
      "Epoch 143/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1402480.3750\n",
      "Epoch 144/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1506901.2500\n",
      "Epoch 145/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1483199.2500\n",
      "Epoch 146/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1462268.6250\n",
      "Epoch 147/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1407924.7500\n",
      "Epoch 148/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1455131.2500\n",
      "Epoch 149/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1440972.1250\n",
      "Epoch 150/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1385913.1250\n",
      "Epoch 151/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1479996.6250\n",
      "Epoch 152/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1463168.6250\n",
      "Epoch 153/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1411738.0000\n",
      "Epoch 154/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1352445.3750\n",
      "Epoch 155/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1393191.6250\n",
      "Epoch 156/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1383889.2500\n",
      "Epoch 157/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1434248.6250\n",
      "Epoch 158/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1332430.0000\n",
      "Epoch 159/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1368409.8750\n",
      "Epoch 160/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1445735.8750\n",
      "Epoch 161/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1251921.0000\n",
      "Epoch 162/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1442640.5000\n",
      "Epoch 163/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1425246.1250\n",
      "Epoch 164/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1352496.5000\n",
      "Epoch 165/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1364415.0000\n",
      "Epoch 166/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1306191.0000\n",
      "Epoch 167/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1269494.5000\n",
      "Epoch 168/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1366785.7500\n",
      "Epoch 169/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1372738.8750\n",
      "Epoch 170/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1403419.7500\n",
      "Epoch 171/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1418993.1250\n",
      "Epoch 172/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1296967.6250\n",
      "Epoch 173/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1333690.0000\n",
      "Epoch 174/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1358288.0000\n",
      "Epoch 175/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1271850.8750\n",
      "Epoch 176/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1393986.5000\n",
      "Epoch 177/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1387346.0000\n",
      "Epoch 178/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1414137.2500\n",
      "Epoch 179/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1326972.6250\n",
      "Epoch 180/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1431960.7500\n",
      "Epoch 181/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1317173.1250\n",
      "Epoch 182/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1357755.5000\n",
      "Epoch 183/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1305718.5000\n",
      "Epoch 184/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1361415.1250\n",
      "Epoch 185/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1335512.0000\n",
      "Epoch 186/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1327748.7500\n",
      "Epoch 187/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1323074.8750\n",
      "Epoch 188/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1352098.1250\n",
      "Epoch 189/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1374680.8750\n",
      "Epoch 190/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1285035.1250\n",
      "Epoch 191/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1297979.3750\n",
      "Epoch 192/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1391627.0000\n",
      "Epoch 193/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1294747.0000\n",
      "Epoch 194/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1306322.7500\n",
      "Epoch 195/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1360236.0000\n",
      "Epoch 196/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1256625.5000\n",
      "Epoch 197/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1369267.2500\n",
      "Epoch 198/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 1237842.3750\n",
      "Epoch 199/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1314196.1250\n",
      "Epoch 200/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1339845.7500\n",
      "Training completed in 150.03 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/js5nvmg90d37xtyx33clr3th0000gn/T/ipykernel_17688/2019959246.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['user_idx'] = train['userId'].map(user_mapping)\n",
      "/var/folders/dr/js5nvmg90d37xtyx33clr3th0000gn/T/ipykernel_17688/2019959246.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['movie_idx'] = train['movieId'].map(movie_mapping)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating random walks...\n",
      "Random walks generation completed.\n",
      "Starting model training...\n",
      "Epoch 1/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.0024 - loss: 2329312.2500\n",
      "Epoch 2/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 2253533.0000\n",
      "Epoch 3/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 2202216.5000\n",
      "Epoch 4/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 2297614.7500\n",
      "Epoch 5/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 2299053.7500\n",
      "Epoch 6/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 2255951.2500\n",
      "Epoch 7/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 2140327.7500\n",
      "Epoch 8/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 2017897.7500\n",
      "Epoch 9/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 2446595.0000\n",
      "Epoch 10/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 2026124.1250\n",
      "Epoch 11/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1938552.5000\n",
      "Epoch 12/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1847020.2500\n",
      "Epoch 13/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1784965.8750\n",
      "Epoch 14/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1891906.0000\n",
      "Epoch 15/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1614968.0000\n",
      "Epoch 16/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1605848.1250\n",
      "Epoch 17/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1572227.3750\n",
      "Epoch 18/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1742869.3750\n",
      "Epoch 19/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1784254.0000\n",
      "Epoch 20/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1718071.8750\n",
      "Epoch 21/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1809087.0000\n",
      "Epoch 22/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1524374.6250\n",
      "Epoch 23/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1698171.5000\n",
      "Epoch 24/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1688417.3750\n",
      "Epoch 25/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1493573.0000\n",
      "Epoch 26/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1716985.0000\n",
      "Epoch 27/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1563342.5000\n",
      "Epoch 28/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1791210.6250\n",
      "Epoch 29/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1621935.7500\n",
      "Epoch 30/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1640155.7500\n",
      "Epoch 31/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1701166.0000\n",
      "Epoch 32/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1617580.0000\n",
      "Epoch 33/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1727961.8750\n",
      "Epoch 34/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1626224.0000\n",
      "Epoch 35/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1739739.0000\n",
      "Epoch 36/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1638136.8750\n",
      "Epoch 37/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1592002.8750\n",
      "Epoch 38/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1623977.6250\n",
      "Epoch 39/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1551866.3750\n",
      "Epoch 40/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1659225.2500\n",
      "Epoch 41/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1727360.1250\n",
      "Epoch 42/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1604137.0000\n",
      "Epoch 43/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1548157.0000\n",
      "Epoch 44/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1708773.6250\n",
      "Epoch 45/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1606776.5000\n",
      "Epoch 46/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1651942.0000\n",
      "Epoch 47/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1568312.1250\n",
      "Epoch 48/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1666621.1250\n",
      "Epoch 49/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1638474.7500\n",
      "Epoch 50/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1594848.3750\n",
      "Epoch 51/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 1686632.8750\n",
      "Epoch 52/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1608913.3750\n",
      "Epoch 53/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1697248.2500\n",
      "Epoch 54/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1502745.7500\n",
      "Epoch 55/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1710954.2500\n",
      "Epoch 56/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1531459.5000\n",
      "Epoch 57/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1682294.1250\n",
      "Epoch 58/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1437848.2500\n",
      "Epoch 59/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1864560.5000\n",
      "Epoch 60/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1600208.7500\n",
      "Epoch 61/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1675488.5000\n",
      "Epoch 62/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1607716.7500\n",
      "Epoch 63/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1594533.6250\n",
      "Epoch 64/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1567270.7500\n",
      "Epoch 65/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1513715.0000\n",
      "Epoch 66/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1620753.3750\n",
      "Epoch 67/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1591612.8750\n",
      "Epoch 68/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1476215.3750\n",
      "Epoch 69/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1533554.5000\n",
      "Epoch 70/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1463970.5000\n",
      "Epoch 71/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1482222.5000\n",
      "Epoch 72/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1835696.8750\n",
      "Epoch 73/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1625460.2500\n",
      "Epoch 74/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1583949.6250\n",
      "Epoch 75/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1598677.8750\n",
      "Epoch 76/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1562557.8750\n",
      "Epoch 77/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1491912.3750\n",
      "Epoch 78/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1532187.8750\n",
      "Epoch 79/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1593534.1250\n",
      "Epoch 80/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1593711.0000\n",
      "Epoch 81/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1531927.5000\n",
      "Epoch 82/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1488477.8750\n",
      "Epoch 83/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1588575.3750\n",
      "Epoch 84/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1612872.5000\n",
      "Epoch 85/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1533980.3750\n",
      "Epoch 86/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1514776.5000\n",
      "Epoch 87/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1632531.7500\n",
      "Epoch 88/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1449820.3750\n",
      "Epoch 89/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1464126.8750\n",
      "Epoch 90/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1498648.3750\n",
      "Epoch 91/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1497603.2500\n",
      "Epoch 92/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1545433.3750\n",
      "Epoch 93/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1464492.6250\n",
      "Epoch 94/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1643718.6250\n",
      "Epoch 95/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1456762.6250\n",
      "Epoch 96/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1430283.0000\n",
      "Epoch 97/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1632144.5000\n",
      "Epoch 98/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: 1436179.6250\n",
      "Epoch 99/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1504719.3750\n",
      "Epoch 100/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1508589.6250\n",
      "Epoch 101/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1439650.5000\n",
      "Epoch 102/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1373613.5000\n",
      "Epoch 103/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1584279.8750\n",
      "Epoch 104/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1394576.2500\n",
      "Epoch 105/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1434499.1250\n",
      "Epoch 106/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1580768.3750\n",
      "Epoch 107/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1462075.8750\n",
      "Epoch 108/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1527111.1250\n",
      "Epoch 109/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1499514.6250\n",
      "Epoch 110/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1516944.2500\n",
      "Epoch 111/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1480050.7500\n",
      "Epoch 112/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1471361.7500\n",
      "Epoch 113/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1592790.1250\n",
      "Epoch 114/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1535037.0000\n",
      "Epoch 115/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1388823.1250\n",
      "Epoch 116/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1451434.8750\n",
      "Epoch 117/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1512893.0000\n",
      "Epoch 118/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1445958.3750\n",
      "Epoch 119/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1572532.5000\n",
      "Epoch 120/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1529171.0000\n",
      "Epoch 121/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1514258.1250\n",
      "Epoch 122/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1469474.5000\n",
      "Epoch 123/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1453692.1250\n",
      "Epoch 124/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1518660.8750\n",
      "Epoch 125/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 1424635.2500\n",
      "Epoch 126/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1519219.5000\n",
      "Epoch 127/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1568119.8750\n",
      "Epoch 128/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1571040.3750\n",
      "Epoch 129/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1396121.3750\n",
      "Epoch 130/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1431935.8750\n",
      "Epoch 131/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1375791.7500\n",
      "Epoch 132/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 1445014.2500\n",
      "Epoch 133/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 1531181.0000\n",
      "Epoch 134/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 1467993.7500\n",
      "Epoch 135/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.0000e+00 - loss: 1401951.3750\n",
      "Epoch 136/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1519153.6250\n",
      "Epoch 137/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1488161.2500\n",
      "Epoch 138/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1498227.2500\n",
      "Epoch 139/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1626760.3750\n",
      "Epoch 140/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1346450.3750\n",
      "Epoch 141/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1556014.5000\n",
      "Epoch 142/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1415058.6250\n",
      "Epoch 143/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1348454.0000\n",
      "Epoch 144/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1453389.0000\n",
      "Epoch 145/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1518811.3750\n",
      "Epoch 146/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1410209.1250\n",
      "Epoch 147/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1464541.8750\n",
      "Epoch 148/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1436914.6250\n",
      "Epoch 149/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1375850.0000\n",
      "Epoch 150/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1439167.7500\n",
      "Epoch 151/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1484129.8750\n",
      "Epoch 152/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1498423.7500\n",
      "Epoch 153/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1408971.5000\n",
      "Epoch 154/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1483883.1250\n",
      "Epoch 155/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1393376.2500\n",
      "Epoch 156/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1552731.2500\n",
      "Epoch 157/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1435171.0000\n",
      "Epoch 158/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1249043.8750\n",
      "Epoch 159/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1480904.0000\n",
      "Epoch 160/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1548623.7500\n",
      "Epoch 161/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1536063.5000\n",
      "Epoch 162/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1434577.6250\n",
      "Epoch 163/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1477122.8750\n",
      "Epoch 164/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1412910.8750\n",
      "Epoch 165/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1379305.3750\n",
      "Epoch 166/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1375069.8750\n",
      "Epoch 167/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1481938.6250\n",
      "Epoch 168/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1411391.7500\n",
      "Epoch 169/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1394277.5000\n",
      "Epoch 170/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1355794.2500\n",
      "Epoch 171/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1373583.7500\n",
      "Epoch 172/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1452474.0000\n",
      "Epoch 173/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1484871.2500\n",
      "Epoch 174/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1373144.3750\n",
      "Epoch 175/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1355448.8750\n",
      "Epoch 176/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1425210.1250\n",
      "Epoch 177/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1339776.3750\n",
      "Epoch 178/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1282984.2500\n",
      "Epoch 179/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1470814.1250\n",
      "Epoch 180/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1250803.0000\n",
      "Epoch 181/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1464382.3750\n",
      "Epoch 182/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1369717.7500\n",
      "Epoch 183/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1350743.1250\n",
      "Epoch 184/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1315539.1250\n",
      "Epoch 185/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1300155.1250\n",
      "Epoch 186/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1282899.1250\n",
      "Epoch 187/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1192495.7500\n",
      "Epoch 188/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1567275.3750\n",
      "Epoch 189/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: 1210186.3750\n",
      "Epoch 190/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1327756.5000\n",
      "Epoch 191/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.0000e+00 - loss: 1386037.1250\n",
      "Epoch 192/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1221573.5000\n",
      "Epoch 193/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1279155.0000\n",
      "Epoch 194/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1300728.8750\n",
      "Epoch 195/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1312545.8750\n",
      "Epoch 196/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 1248278.2500\n",
      "Epoch 197/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.0000e+00 - loss: 1317605.2500\n",
      "Epoch 198/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 1337236.0000\n",
      "Epoch 199/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: 1320429.3750\n",
      "Epoch 200/200\n",
      "\u001b[1m43/43\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.0000e+00 - loss: 1214372.6250\n",
      "Training completed in 144.78 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import hypernetx as hnx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from collections import defaultdict\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Node2Vec(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.embedding = layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim,\n",
    "                                          embeddings_initializer=tf.keras.initializers.RandomNormal(stddev=1.0),\n",
    "                                          embeddings_regularizer=tf.keras.regularizers.l2(1e-6))\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.batch_norm = layers.BatchNormalization()\n",
    "        self.dense1 = layers.Dense(256, activation='relu')\n",
    "        self.dense2 = layers.Dense(128, activation='relu')\n",
    "        self.dense3 = layers.Dense(1, activation='linear')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = tf.reduce_mean(x, axis=1)  # Mean pooling\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "def train_node2vec_model(H, train, test, scenario):\n",
    "    user_ids = train['userId'].unique()\n",
    "    movie_ids = train['movieId'].unique()\n",
    "\n",
    "    user_mapping = {user_id: idx for idx, user_id in enumerate(user_ids)}\n",
    "    movie_mapping = {movie_id: idx + len(user_ids) for idx, movie_id in enumerate(movie_ids)}\n",
    "\n",
    "    train['user_idx'] = train['userId'].map(user_mapping)\n",
    "    train['movie_idx'] = train['movieId'].map(movie_mapping)\n",
    "\n",
    "    test['user_idx'] = test['userId'].map(user_mapping)\n",
    "    test['movie_idx'] = test['movieId'].map(movie_mapping)\n",
    "\n",
    "    # Generate random walks from the hypergraph\n",
    "    def random_walk(hypergraph, start_node, walk_length):\n",
    "        walk = [start_node]\n",
    "        while len(walk) < walk_length:\n",
    "            cur = walk[-1]\n",
    "            neighbors = list(hypergraph.neighbors(cur))\n",
    "            if neighbors:\n",
    "                walk.append(np.random.choice(neighbors))\n",
    "            else:\n",
    "                break\n",
    "        return [str(node) for node in walk]\n",
    "\n",
    "    def generate_walks(hypergraph, num_walks, walk_length):\n",
    "        print(\"Generating random walks...\")\n",
    "        nodes = list(hypergraph.nodes)\n",
    "        walks = Parallel(n_jobs=-1)(delayed(random_walk)(hypergraph, np.random.choice(nodes), walk_length) for _ in range(num_walks))\n",
    "        print(\"Random walks generation completed.\")\n",
    "        return walks\n",
    "\n",
    "    num_walks = 150  # Number of walks per node\n",
    "    walk_length = 80  # Length of each walk\n",
    "    dimensions = 128  # Dimension of the embeddings\n",
    "    window_size = 5  # Window size for context-target pairs\n",
    "    epochs = 200  # Number of training epochs\n",
    "    learning_rate = 0.0001  # Adjusted learning rate\n",
    "\n",
    "    walks = generate_walks(H, num_walks, walk_length)\n",
    "\n",
    "    # Convert walks to integer indices\n",
    "    node_to_idx = {node: idx for idx, node in enumerate(H.nodes)}\n",
    "    walks_indices = [[node_to_idx[node] for node in walk if node in node_to_idx] for walk in walks]\n",
    "    vocab_size = len(node_to_idx)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for walk in walks_indices:\n",
    "        if len(walk) > window_size:\n",
    "            for i in range(len(walk) - window_size):\n",
    "                context = walk[i:i + window_size]\n",
    "                target = walk[i + window_size]\n",
    "                X.append(context)\n",
    "                y.append(target)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    if X.size == 0 or y.size == 0:\n",
    "        print(\"No data generated for training. Check the random walk and context-target extraction steps.\")\n",
    "        return pd.DataFrame({\n",
    "            'Scenario': [scenario],\n",
    "            'Algorithm': ['Node2Vec'],\n",
    "            'RMSE': [None],\n",
    "            'MAE': [None],\n",
    "            'Precision@10': [None],\n",
    "            'Recall@10': [None],\n",
    "            'Running Time (s)': [None]\n",
    "        })\n",
    "    else:\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((X, y)).batch(256).shuffle(buffer_size=1024).repeat()\n",
    "        steps_per_epoch = len(X) // 256\n",
    "        if steps_per_epoch == 0:\n",
    "            steps_per_epoch = 1\n",
    "\n",
    "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "            initial_learning_rate=learning_rate,\n",
    "            decay_steps=100000,\n",
    "            decay_rate=0.96,\n",
    "            staircase=True)\n",
    "\n",
    "        model = Node2Vec(vocab_size, dimensions)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule), loss='mean_squared_error', metrics=['accuracy'])\n",
    "        print(\"Starting model training...\")\n",
    "        start_time = time.time()\n",
    "        history = model.fit(dataset, epochs=epochs, steps_per_epoch=steps_per_epoch)\n",
    "        end_time = time.time()\n",
    "        print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "        embeddings = model.embedding.get_weights()[0]\n",
    "\n",
    "    results = evaluate_model(test, embeddings, user_mapping, movie_mapping, scenario, \"Node2Vec\")\n",
    "    results['Running Time (s)'] = end_time - start_time\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate Node2Vec model for different scenarios\n",
    "results_node2vec_normal = train_node2vec_model(H, train, test, \"Normal\")\n",
    "results_node2vec_sparse = train_node2vec_model(H, sparse_data, test, \"Sparse\")\n",
    "results_node2vec_new_user = train_node2vec_model(H, new_user_data, test, \"New User\")\n",
    "\n",
    "# Combine Node2Vec results into a single DataFrame\n",
    "results_node2vec_combined = pd.concat([results_node2vec_normal, results_node2vec_sparse, results_node2vec_new_user], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd766424-df0e-499e-a3a7-3f4d4b585336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scenario</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Precision@10</th>\n",
       "      <th>Recall@10</th>\n",
       "      <th>Running Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>Node2Vec</td>\n",
       "      <td>8.286368</td>\n",
       "      <td>6.071646</td>\n",
       "      <td>0.844083</td>\n",
       "      <td>0.358547</td>\n",
       "      <td>143.922792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sparse</td>\n",
       "      <td>Node2Vec</td>\n",
       "      <td>8.070935</td>\n",
       "      <td>5.747824</td>\n",
       "      <td>0.828152</td>\n",
       "      <td>0.344028</td>\n",
       "      <td>150.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New User</td>\n",
       "      <td>Node2Vec</td>\n",
       "      <td>8.211360</td>\n",
       "      <td>6.095754</td>\n",
       "      <td>0.829264</td>\n",
       "      <td>0.372612</td>\n",
       "      <td>144.782401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Scenario Algorithm      RMSE       MAE  Precision@10  Recall@10  \\\n",
       "0    Normal  Node2Vec  8.286368  6.071646      0.844083   0.358547   \n",
       "1    Sparse  Node2Vec  8.070935  5.747824      0.828152   0.344028   \n",
       "2  New User  Node2Vec  8.211360  6.095754      0.829264   0.372612   \n",
       "\n",
       "   Running Time (s)  \n",
       "0        143.922792  \n",
       "1        150.034234  \n",
       "2        144.782401  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_node2vec_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d06016-f2d5-4901-a73a-4d4a7c8bb2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
